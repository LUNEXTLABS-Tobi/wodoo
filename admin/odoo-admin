#!/usr/bin/python
import pipes
import argh
import types
from argh import arg
import sys
import re
import signal
import os
import logging
import importlib
import humanize
import subprocess
import time
import inspect
import yaml
import shutil
import tempfile
import docker
import shlex
import traceback
import json
from tabulate import tabulate
from inspect import getmembers, isfunction
from retrying import retry
from datetime import datetime
import copy
from threading import Thread
from Queue import Queue
from logging import FileHandler
from optparse import OptionParser
import psycopg2
from subprocess import PIPE
from module_tools.module_tools import get_manifest_path_of_module_path
from module_tools.myconfigparser import MyConfigParser
from module_tools import odoo_config
from module_tools import odoo_versioning as versioning
from module_tools.odoo_parser import update_cache
from module_tools.module_tools import remove_webassets
from module_tools.odoo_config import get_odoo_addons_paths
from module_tools.odoo_config import get_links_dir
from module_tools.module_tools import make_customs as _tools_make_customs
from module_tools.module_tools import make_module as _tools_make_module
from migrate import do_migrate
from tools import __system
from tools import __find_files

try:
    from pudb import set_trace
except Exception:
    set_trace = None
current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))) # script directory
sys.path.append(os.path.join(current_dir, 'python_wait'))
import wait  # NOQA

PLATFORM_OSX = "OSX"
PLATFORM_LINUX = "Linux"
YAML_VERSION = '3.5'
BACKUPDIR = "/host/dumps"
FORCE = any(x == '-f' or x == '--force' for x in sys.argv[1:])
SAFE_KILL = ['postgres', 'redis']
args = sys.argv[1:]

dirs = {
    'admin': 'admin',
    'odoo_home': '',
    'proxy_configs_dir': 'run/proxy',
    'settings.d': 'run/settings.d',
    'host_working_dir': '',
    'run': 'run',
    'run/proxy': 'run/proxy',
    'run/restore': 'run/restore',
    'machines': 'machines',
    'machines/proxy': 'machines/proxy',
    'customs': '',
    'telegrambot': 'config/telegrambat',
}

files = {
    'OCA': 'admin/OCA',
    'docker_compose': 'run/docker-compose.yml',
    'debugging_template': 'config/debugging/template.yml',
    'debugging_composer': 'run/debugging.yml',
    'settings': 'run/settings',
    'odoo_instances': 'run/odoo_instances',
    'config/default_network': 'config/default_network',
    'run/odoo_debug.txt': 'run/odoo_debug.txt',
    'machines/proxy/instance.conf': 'machines/proxy/instance.conf',
    'machines/postgres/turndb2dev.sql': 'machines/postgres/turndb2dev.sql',
}
commands = {
    'dc': ["/usr/local/bin/docker-compose", "-p", "$PROJECT_NAME", "-f",  "$docker_compose_file"],
}


def trace():
    if set_trace:
        set_trace()

def __assert_file_exists(path, isdir=False):
    if not os.path.exists(path):
        raise Exception("{} {} not found!".format(
            'Directory' if isdir else 'File',
            path
        ))

def __cmd_interactive(*params):
    cmd = __get_cmd() + list(params)
    proc = subprocess.Popen(cmd)
    proc.wait()

def __dc(cmd, suppress_out=False, raise_exception=True, wait_finished=True, logger=None):
    c = __get_cmd() + cmd
    out = __system(
        c,
        cwd=dirs['odoo_home'],
        suppress_out=suppress_out,
        raise_exception=raise_exception,
        wait_finished=wait_finished,
        logger=logger,
    )
    return out

def __dcexec(cmd):
    c = __get_cmd()
    c = c + ['exec', '-T'] + cmd
    out = __system(c, cwd=dirs['odoo_home'])
    return out

def __dcrun(cmd, interactive=False, wait_finished=True, raise_exception=True, logger=None):
    cmd2 = [os.path.expandvars(x) for x in cmd]
    cmd = ['run']
    if not interactive:
        cmd += ['-T']
    cmd += ['--rm', '-e ODOO_HOME=/opt/odoo'] + cmd2
    return __dc(cmd, wait_finished=wait_finished, raise_exception=True, logger=logger)

def __do_restore_db_on_postgres(filename, dbname, host, port, user, password):
    dump_file = os.path.join(BACKUPDIR, filename)

    __assert_file_exists(dump_file)

    print("Restoring dump on {}:{} as {}".format(host, port, user))
    os.environ['PGPASSWORD'] = password
    args = ["-h", host, "-p", port, "-U", user]
    PGRESTORE = [
        "pg_restore",
        "--no-owner",
        "--no-privileges",
        "--no-acl",
    ] + args
    PSQL = ["psql"] + args

    __execute_sql("drop database if exists {}".format(dbname), 'template1', notransaction=True)
    __execute_sql("create database {}".format(dbname), 'template1', notransaction=True)

    method = PGRESTORE
    needs_unzip = True

    dump_type = __get_dump_type(dump_file)
    if dump_type == 'plain_text':
        needs_unzip = False
        method = PSQL
    elif dump_type == 'zipped_sql':
        method = PSQL
        needs_unzip = True
    elif dump_type == "zipped_pgdump":
        pass
    elif dump_type == "unzipped_pgdump":
        needs_unzip = False
    else:
        raise Exception("not impl: {}".format(dump_type))

    PREFIX = []
    if needs_unzip:
        PREFIX = ["/bin/gunzip"]
    else:
        PREFIX = []
    started = datetime.now()
    print("Restoring DB...")
    CMD = " " .join(pipes.quote(s) for s in ['pv', dump_file])
    CMD += " | "
    if PREFIX:
        CMD += " ".join(pipes.quote(s) for s in PREFIX)
        CMD += " | "
    CMD += " ".join(pipes.quote(s) for s in method)
    CMD += " "
    CMD += " ".join(pipes.quote(s) for s in [
        '-d',
        dbname,
    ])
    os.system(CMD)
    print "Restore took {} seconds".format((datetime.now() - started).seconds)

def __do_restore_files(filepath):
    # remove the postgres volume and reinit
    if filepath.startswith("/"):
        raise Exception("No absolute path allowed")
    __dcrun(['odoo', '/bin/restore_files.sh', os.path.basename(filepath)])

def __empty_dir(dir):
    if os.path.isdir(dir):
        for f in os.listdir(dir):
            filepath = os.path.join(dir, f)
            if os.path.isdir(filepath):
                __rmtree(filepath)
            else:
                os.unlink(filepath)

def __execute_sql(sql, dbname=None, fetchone=False, fetchall=False, notransaction=False, no_try=False):
    if not dbname:
        dbname = E("DBNAME")
    # try to connecto to postgres; could startup:

    @retry(wait_random_min=500, wait_random_max=800, stop_max_delay=30000)
    def try_connect():
        __execute_sql("SELECT * FROM pg_catalog.pg_tables;", 'template1', no_try=True)
    if not no_try:
        try_connect()

    conn = psycopg2.connect(
        dbname=dbname,
        user=E("DB_USER"),
        password=E("DB_PWD"),
        host=E("DB_HOST"),
        port=E("DB_PORT"),
    )
    conn.autocommit = notransaction
    result = None
    cr = conn.cursor()
    try:
        cr.execute(sql)
        if fetchone:
            result = cr.fetchone()
        elif fetchall:
            result = cr.fetchall()
        conn.commit()
    except Exception:
        conn.rollback()
        raise
    finally:
        cr.close()
        conn.close()
    return result

def __exists_db(dbname):
    dbname = dbname or E("DBNAME")
    sql = "select count(*) from pg_database where datname='{}'".format(dbname)
    record = __execute_sql(sql, fetchone=True, dbname='template1')
    if not record or not record[0]:
        return False
    return True

def __file_default_content(path, default_content):
    if not os.path.exists(path):
        with open(path, 'w') as f:
            f.write(default_content)

def __file_get_lines(path):
    with open(path) as f:
        return f.readlines()

def __get_cmd():
    cmd = commands['dc']
    cmd = [os.path.expandvars(x) for x in cmd]
    return cmd

def __get_dangling_modules():
    rows = __execute_sql(
        "SELECT name, state from ir_module_module where state not in ('installed', 'uninstalled');",
        fetchall=True
    )
    return rows


def __get_docker_compose_run_command():
    """
    Returns bash ready command to call simplebash self by run.

    """
    host_odoo_home = os.environ["ODOO_HOME"]
    local_odoo_home = os.environ['LOCAL_ODOO_HOME']
    cmdline = []
    cmdline.append("/opt/docker/docker")
    cmdline.append("run")
    cmdline.append('-e')
    cmdline.append('ODOO_HOME={}'.format(host_odoo_home))
    envfile = os.path.join(local_odoo_home, 'run/settings')
    if os.path.exists(envfile):
        cmdline.append('--env-file')
        cmdline.append(envfile)
    cmdline.append("--rm")
    cmdline.append('-v')
    cmdline.append("{HOST_ODOO_HOME}:{HOST_ODOO_HOME}".format(HOST_ODOO_HOME=os.environ["ODOO_HOME"]))
    cmdline.append("--workdir")
    cmdline.append(host_odoo_home)
    cmdline.append(__get_docker_image())
    return cmdline

@retry(wait_random_min=500, wait_random_max=800, stop_max_delay=30000)
def __get_docker_image():
    """
    Sometimes this command fails; checked with pudb behind call, hostname matches
    container id; seems to be race condition or so
    """
    hostname = os.environ['HOSTNAME']
    result = [x for x in __system(["/opt/docker/docker", "inspect", hostname], suppress_out=True).split("\n") if "\"Image\"" in x]
    if result:
        result = result[0].split("sha256:")[-1].split('"')[0]
        return result[:12]
    return None

def __get_dump_type(filepath):
    temp = tempfile.mktemp(suffix='.check')
    MARKER = "PostgreSQL database dump"
    FNULL = open(os.devnull, 'w')
    proc = subprocess.Popen(['gunzip', '-c', filepath], stdout=subprocess.PIPE, stderr=FNULL, bufsize=1)

    def reader(proc, pipe):
        try:
            lines = 0
            with pipe:
                for line in iter(pipe.readline, ''):
                    with open(temp, 'a') as f:
                        f.write(line)
                        lines += 1
                        if lines > 20:
                            break
        finally:
            if not proc.returncode:
                proc.kill()

    Thread(target=reader, args=[proc, proc.stdout]).start()
    proc.wait()

    if os.path.exists(temp):
        content = __read_file(temp)
        if MARKER in content:
            return 'zipped_sql'
        if content.startswith("PGDMP"):
            return "zipped_pgdump"
    with open(filepath, 'r') as f:
        for i, line in enumerate(f):
            if i == 0 and line.startswith("PGDMP"):
                return 'pgdump'
            if i > 50:
                break
            if MARKER in line:
                return "plain_text"
    return 'unzipped_pgdump'

def __get_installed_modules():
    rows = __execute_sql(
        "SELECT name, state from ir_module_module where state in ('installed', 'to upgrade');",
        fetchall=True
    )
    return [x[0] for x in rows]

def _get_settings_directories():
    """
    Returns list of paths or files
    """
    customs_dir = odoo_config.customs_dir()
    yield os.path.join(customs_dir, 'settings')
    if os.path.exists('/etc_host/odoo/{}/settings'.format(os.environ['CUSTOMS'])):
        yield '/etc_host/odoo/{}/settings'.format(os.environ['CUSTOMS'])
    if os.path.exists('/etc_host/odoo/settings'):
        yield '/etc_host/odoo/settings'
    yield dirs['settings.d']

def __is_container_running(machine_name):
    container_id = __dc(['ps', '-q', machine_name], raise_exception=False, suppress_out=True).strip()
    if container_id:
        container = filter(lambda container: container.id == container_id, docker.from_env().containers.list())
        if container:
            return container[0].status == 'running'
    return False

def is_up(*machine_name):
    assert len(machine_name) == 1
    print 'Running' if __is_container_running(machine_name[0]) else 'Not Running', machine_name[0]

def __isfloat(x):
    try:
        float(x)
    except Exception:
        return False
    else:
        return True

def __makedirs(path):
    if not os.path.exists(path):
        os.makedirs(path)

def __print_env(vars):
    for x in vars:
        print "{}: {}".format(x, E(x))

def __read_file(path):
    with open(path, 'r') as f:
        return f.read()

def __remove_postgres_connections(DBNAME=None, sql_afterwards=""):
    DBNAME = DBNAME or E("DBNAME")
    print "Removing all current connections from {}".format(DBNAME)
    if __exists_db(DBNAME):
        SQL = """
            SELECT pg_terminate_backend(pg_stat_activity.pid)
            FROM pg_stat_activity
            WHERE pg_stat_activity.datname = '{}'
            AND pid <> pg_backend_pid();
        """.format(DBNAME, sql_afterwards)
        __execute_sql(SQL, 'template1', notransaction=True)
        if sql_afterwards:
            __execute_sql(sql_afterwards, 'template1', notransaction=True)

def __rename_db_drop_target(from_db, to_db):
    if 'to_db' == 'template1':
        raise Exception("Invalid: {}".format(to_db))
    __remove_postgres_connections(from_db)
    __remove_postgres_connections(to_db)
    __execute_sql("drop database if exists {to_db}".format(**locals()), "template1", notransaction=True)
    __execute_sql("alter database {from_db} rename to {to_db};".format(**locals()), "template1", notransaction=True)
    __remove_postgres_connections(to_db)

def __replace_in_file(filepath, text, replacewith):
    with open(filepath, 'r') as f:
        content = f.read()
    content = content.replace(text, replacewith)
    with open(filepath, 'w') as f:
        f.write(content)

def __reset_postgres_container():
    # remove the postgres volume and reinit
    if E("RUN_POSTGRES") == "1":
        kill(machines='postgres', brutal=True)
        if E("RUN_POSTGRES_IN_RAM") == "1":
            pass
        else:
            print "Resettings postgres - killing data - not reversible"
            VOLUMENAME = "{}_postgresdata".format(E("CUSTOMS"))
            docker_client = docker.from_env()

            @retry(wait_random_min=500, wait_random_max=800, stop_max_delay=30000)
            def remove_volume():
                for volume in docker_client.volumes.list():
                    if volume.name == VOLUMENAME:
                        try:
                            kill(brutal=True)
                            __dc(["rm", "-f"]) # set volume free
                            volume.remove()
                        except Exception as e:
                            print e
                            if hasattr(e, 'explanation'):
                                exp = e.explanation

                                if 'volume is in use' in e:
                                    container_id = re.findall(r'\[([^\]]*)\]', exp)[0]
                                    __system(["docker", "rm", container_id])
                            return None
                return True
            remove_volume()
            __dcrun(['-e', 'INIT=1', 'postgres', '/entrypoint2.sh'])
        __start_postgres_and_wait()

def __restore_check(filepath):
    dumpname = os.path.basename(filepath)

    if E("DBNAME") not in dumpname and not FORCE:
        raise Exception("The dump-name \"{}\" should somehow match the current database \"{}\", which isn't.".format(
            dumpname,
            E("DBNAME"),
        ))

def __rm_file_if_exists(path):
    if os.path.exists(path):
        os.unlink(path)

def __rmtree(path):
    if not path or path == '/':
        raise Exception("Not allowed: {}".format(path))
    if not path.startswith("/"):
        raise Exception("Not allowed: {}".format(path))
    if not any(path.startswith(dirs['odoo_home'] + x) for x in ['/tmp', '/run/']):
        if "/tmp" in path:
            pass
        else:
            raise Exception('not allowed')
    shutil.rmtree(path)

def __safeget(array, index, exception_on_missing, file_options=None):
    if file_options:
        if os.path.exists(file_options):
            file_options = '\n' + '\n'.join(os.listdir(file_options))
    file_options = file_options or ''
    if len(array) < index + 1:
        raise Exception(exception_on_missing + file_options)
    return array[index]

def __splitcomma(param):
    if isinstance(param, (str, unicode)):
        if not param:
            return []
        return [x.strip() for x in param.split(',') if x.strip()]
    elif isinstance(param, (tuple, list)):
        return list(param)
    raise Exception("not impl")

def __set_db_ownership():
    # in development environments it is safe to set ownership, so
    # that accidently accessing the db fails
    if E("DEVMODE") == "1":
        if E("RUN_POSTGRES") == "1":
            __start_postgres_and_wait()
        from module_tools.module_tools import set_ownership_exclusive
        set_ownership_exclusive()

def __try_to_set_owner(UID, path, recursive=False):
    if os.path.isdir(path):
        uid = os.stat(path).st_uid
        if str(uid) != str(UID) or recursive:
            print("Trying to set correct permissions on {}".format(path))
            options = ""
            if recursive:
                options += "-R"

            __system([
                'sudo',
                'find',
                '-not',
                '-type',
                'l',
                '-not',
                '-user',
                UID,
                '-exec',
                'chown',
                UID,
                '{}',
                '+'
            ], cwd=path)

def __turn_into_devdb(dbname):
    SQLFILE = files['machines/postgres/turndb2dev.sql']
    sql = __read_file(SQLFILE)

    critical = False
    for line in sql.split("\n"):
        if not line:
            continue
        if line.startswith("--set critical"):
            critical = True
            continue
        elif line.startswith("--set not-critical"):
            critical = False
            continue

        comment = re.findall(r'\/\*[^\*^\/]*\*\/', line)
        if comment:
            for comment in comment[0].split(";"):
                comment = comment[2:-2]
                if 'if-table-exists' in comment:
                    table = comment.split("if-table-exists")[1].strip()
                    res = __execute_sql(
                        "select count(*) from information_schema.tables where table_schema='public' and table_name='{}'".format(table),
                        dbname=dbname,
                        fetchone=True
                    )
                    if not res[0]:
                        continue
        try:
            __execute_sql(line, dbname=dbname)
        except Exception as e:
            if critical:
                raise
            print("failed un-critical sql:", str(e))

    remove_webassets(dbname=dbname)

def __wait_for_port(host, port, timeout=None):
    res = wait.tcp.open(port, host=host, timeout=timeout)
    if not res and timeout:
        raise Exception("Timeout elapsed waiting for {}:{}".format(host, port))

def _askcontinue(msg=None):
    if msg:
        print(msg)
    if FORCE or os.getenv("FORCE_CONTINUE", "0") == "1":
        return
    raw_input("Continue? (Ctrl+C to break)")

def _check_working_dir_customs_mismatch():
    # Checks wether the current working is in a customs directory, but
    # is not matching the correct customs. Avoid creating wrong tickets
    # in the wrong customizations.

    working_dir = dirs['host_working_dir']
    while not os.path.isfile(os.path.join(working_dir, '.customsroot')):
        try:
            working_dir = os.path.dirname(working_dir)
        except Exception:
            break
        if not working_dir.replace("/", ""):
            break

    if os.path.isfile(os.path.join(working_dir, '.customsroot')):
        current_customs = os.path.basename(working_dir)
        if current_customs != os.environ['CUSTOMS']:
            _askcontinue("""Caution: current customs is {} but you are in another customs directory: {}
Continue at your own risk!""".format("$CUSTOMS", "$LOCAL_WORKING_DIR")
                         )

def _cleanup():
    _remove_temp_directories

def _collect_settings_files():
    _files = []
    _files.append(os.path.join(dirs['odoo_home'], 'machines/defaults'))
    # optimize
    for filename in __find_files(dirs['machines'], "-name", "default.settings"):
        _files.append(os.path.join(dirs['machines'], filename))

    for dir in _get_settings_directories():
        if os.path.isfile(dir):
            _files.append(dir)
        elif os.path.isdir(dir):
            for filename in os.listdir(dir):
                _files.append(os.path.join(dir, filename))
    return _files

def _display_machine_tips(machine_name):
    dir = os.path.join(dirs['machines'], machine_name)
    if not os.path.isdir(dir):
        return

    for filename in __find_files(dirs['machines'], '-name', 'tips.txt'):
        filepath = os.path.join(dirs['machines'], filename)
        if os.path.basename(os.path.dirname(filepath)) == machine_name:
            content = __read_file(os.path.join(dirs['machines'], filename))
            print ""
            print "Please note:"
            print "---------------"
            print ""
            print content
            print ""
            print ""

def _export_settings():
    _file2env(files['settings'])

    if not os.path.exists(files['settings']):
        raise Exception("Please call ./odoo compose <CUSTOMS> initially.")

    # get odoo version
    ODOO_VERSION = ""
    if os.getenv("CUSTOMS"):
        ODOO_VERSION = str(odoo_config.get_version_from_customs(os.environ['CUSTOMS']))
    os.environ['ODOO_VERSION'] = ODOO_VERSION
    setting_files = _collect_settings_files()
    _make_settings_file(files['settings'], setting_files)
    config = MyConfigParser(files['settings'])

    if "DBNAME" not in config.keys():
        config['DBNAME'] = config['CUSTOMS']
        config.write()
    if "ODOO_VERSION" not in config or config['ODOO_VERSION'] != ODOO_VERSION:
        config['ODOO_VERSION'] = ODOO_VERSION
        config.write()

    if 'RUN_POSTGRES' in config.keys() and config['RUN_POSTGRES'] == '1':
        default_values = {
            "DB_HOST": "postgres",
            "DB_PORT": "5432",
            "DB_USER": "odoo",
            "DB_PWD": "odoo"
        }
        for k, v in default_values.items():
            if config.get(k, "") != v:
                config[k] = v
                config.write()

    # store the host root folder
    config['HOST_ODOO_HOME'] = E("ODOO_HOME")
    _file2env(files['settings'])

def _file2env(filepath):
    if not os.path.exists(filepath):
        return
    config = MyConfigParser(filepath)
    for k in config.keys():
        os.environ[k] = config[k]

def _get_bash_for_machine(machine):
    if machine == 'postgres':
        return 'bash'
    else:
        return 'bash'

def _get_platform():
    if os.getenv("PLATFORM", "") in ['Darwin', 'OSX', 'macos']:
        return PLATFORM_OSX
    else:
        return PLATFORM_LINUX

def _make_settings_file(outfile, setting_files):
    """
    Puts all settings into one settings file
    """
    c = MyConfigParser(outfile)
    for file in setting_files:
        if not file:
            continue
        c2 = MyConfigParser(file)

        for key in c2.keys():
            value = c2[key]
            if '~' in value:
                value = value.replace('~', os.environ['HOST_HOME'])
                c2[key] = value

        c.apply(c2)
    if _get_platform() == PLATFORM_OSX:
        c['RUN_RSYNCED'] = '1'
    c.write()

def _prepare_docker_compose_files(dest_file, paths):
    local_odoo_home = os.environ['LOCAL_ODOO_HOME']

    temp_files = set()
    tempdir = tempfile.mkdtemp()

    if not dest_file:
        raise Exception('require destination path')

    with open(dest_file, 'w') as f:
        f.write("#Composed {}\n".format(datetime.now().strftime("%Y-%m-%d %H:%M:%S")))
        f.write("version: '{}'\n".format(os.environ['ODOO_COMPOSE_VERSION']))

    def replace_all_envs_in_file(filepath):
        with open(filepath, 'r') as f:
            content = f.read()
        all_params = re.findall(r'\$\{[^\}]*?\}', content)
        for param in all_params:
            name = param
            name = name.replace("${", "")
            name = name.replace("}", "")
            if name in os.environ:
                content = content.replace(param, os.environ[name])
        with open(filepath, 'w') as f:
            f.write(content)

    for path in set(paths):
        filename = os.path.basename(path)

        def use_file():
            if "run_odoo_version.{}.yml".format(E("ODOO_VERSION")) in filename:
                return True
            if 'run_' in filename:
                run = re.findall(r'run_[^\.]*', filename)
                if run:
                    if '!run' in filename:
                        if os.getenv(run[0].upper(), "0") == "0":
                            return True
                    else:
                        if os.getenv(run[0].upper(), "1") == "1":
                            return True
                return False
            else:
                return True

        if not use_file():
            continue

        with open(path, 'r') as f:
            content = f.read()
            # dont matter if written manage-order: or manage-order
            if 'manage-order' not in content:
                order = '99999999'
            else:
                order = content.split("manage-order")[1].split("\n")[0].replace(":", "").strip()
        folder_name = os.path.basename(os.path.dirname(path))
        if os.getenv("RUN_{}".format(folder_name.upper()), "1") == "0":
            continue

        order = str(order)

        # put all files in their order into the temp directory
        counter = 0
        temp_path = ""
        while not temp_path or os.path.exists(temp_path):
            counter += 1
            temp_path = os.path.join(tempdir, '{}-{}'.format(order, str(counter).zfill(5)))

        # add static yaml content to each machine
        with open(files['config/default_network'], 'r') as f:
            default_network = yaml.load(f.read())

        with open(temp_path, 'w') as dest:
            with open(path, 'r') as source:
                j = yaml.load(source.read())
                # TODO complain version - override version
                j['version'] = YAML_VERSION

                # set settings environment and the override settings after that
                for file in ['run/settings']:
                    path = os.path.join(local_odoo_home, file)
                    if os.path.exists(path):
                        if 'services' in j:
                            for service in j['services']:
                                service = j['services'][service]
                                if 'env_file' not in service:
                                    service['env_file'] = []
                                if isinstance(service['env_file'], (str, unicode)):
                                    service['env_file'] = [service['env_file']]

                                if not [x for x in service['env_file'] if x == '$ODOO_HOME/{}'.format(file)]:
                                    service['env_file'].append('$ODOO_HOME/{}'.format(file))
                    j['networks'] = copy.deepcopy(default_network['networks'])

                dest.write(yaml.dump(j, default_flow_style=False))
                dest.write("\n")
        replace_all_envs_in_file(temp_path)
        temp_files.add(os.path.basename(temp_path))
        del temp_path

    def post_process_complete_yaml_config(yml):
        """
        This is after calling docker-compose config, which returns the
        complete configuration.

        Aim is to take the volumes defined in odoo_base and append them
        to all odoo containers.
        """

        with open(os.path.join(local_odoo_home, 'machines/odoo/docker-compose.yml')) as f:
            odoodc = yaml.load(f.read())

        for odoomachine in odoodc['services']:
            if odoomachine == 'odoo_base':
                continue
            machine = yml['services'][odoomachine]
            for k in ['volumes']:
                machine[k] = []
                for x in yml['services']['odoo_base'][k]:
                    machine[k].append(x)
            for k in ['environment']:
                machine.setdefault(k, {})
                for x, v in yml['services']['odoo_base'][k].items():
                    machine[k][x] = v
        yml['services'].pop('odoo_base')

        return yml

    # call docker compose config to get the complete config
    _files = sorted(temp_files, key=lambda x: float(x.split("/")[-1].replace("-", ".")))
    cmdline = __get_docker_compose_run_command()
    cmdline.append("/usr/local/bin/docker-compose")
    for file in _files:
        cmdline.append('-f')
        cmdline.append(os.path.join(os.path.basename(tempdir), file))
    cmdline.append('config')

    # annotation: per symlink all subfiles/folders are linked to a path,
    # that matches the host system path
    shutil.move(tempdir, local_odoo_home)
    tempdir = os.path.join(local_odoo_home, os.path.basename(tempdir))

    attempts = 0
    while True:
        try:
            conf = __system(cmdline, cwd=local_odoo_home, suppress_out=True)
        except Exception:
            # stupid conversion from guid to int, if characters missing
            attempts += 1
            if attempts > 5:
                raise
        else:
            # post-process config config
            conf = post_process_complete_yaml_config(yaml.load(conf))
            conf = yaml.dump(conf, default_flow_style=False)

            with open(dest_file, 'w') as f:
                f.write(conf)
            break
        finally:
            __rmtree(tempdir)

def _prepare_yml_files_from_template_files():
    # replace params in configuration file
    # replace variables in docker-compose;

    if E("ODOO_MANAGER_STARTED_ONCE") != "1":
        for name in ['CUSTOMS', 'DB', 'ODOO_VERSION', 'ODOO_FILES']:
            print("{}: {}".format(name, E(name)))

    # python: find all configuration files from machines folder; extract sort
    # by manage-sort flag and put file into run directory
    # only if RUN_parentpath like RUN_ODOO is <> 0 include the machine
    #
    # - also replace all environment variables
    def find_files(dir):
        for filepath in __find_files(
                dir,
                '-regex',
                '.*\/docker-compose.*.yml'
        ):
            yield filepath
    _files = []
    _files += find_files(dirs['machines'])
    _files += find_files(odoo_config.customs_dir())
    _prepare_docker_compose_files(files['docker_compose'], _files)

def _remember_customs_and_cry_if_changed():
    # if customs changed, then restart is required

    out = __dcexec(['odoo env'])
    out = [x for x in out.split('\n') if "CUSTOMS="]
    if out:
        current_customs = out[0].split("=")[-1]
        if current_customs != os.environ['CUSTOMS']:
            print("Customs changed - you need to restart and/or rebuild!")
            kill()

def _remove_temp_directories():
    for dir in os.listdir(dirs['odoo_home']):
        if dir.startswith("tmp") and len(dir) == len('tmp......'):
            __rmtree(os.path.join(dirs['odoo_home'], dir))

def _reset_proxy_configs():
    __empty_dir(dirs['run/proxy'])

def _prepare_filesystem():
    __makedirs(dirs['settings.d'])
    for subdir in ['config', 'sqlscripts', 'debug', 'proxy']:
        __makedirs(os.path.join(dirs['odoo_home'], 'run', 'subdir'))
    __system(['sudo', '-E', 'chown', "{uid}:{uid}".format(uid=E("UID")), "-R", dirs['run']])

    __file_default_content(files['odoo_instances'], "default default\n")

def _sanity_check():
    if not E("RUN_POSTGRES"):
        raise Exception("Please define RUN_POSTGRES")

    if E("RUN_POSTGRES") == "1" and E("DB_HOST") != "postgres":
        print("You are using the docker postgres container, but you do not have the DB_HOST set to use it.")
        print("Either configure DB_HOST to point to the docker container or turn it off by: ")
        print("RUN_POSTGRES=0")
        sys.exit(1)

    if E("OWNER_UID") == "0":
        print("Advise: you should set OWNER_UID so that dump files are marked as the correct owner")
        time.sleep(3)

    if E("ODOO_FILES") and os.path.isdir(E("ODOO_FILES")):
        # checking directory permissions of session files and filestorage
        __try_to_set_owner(E("OWNER_UID"), E("$ODOO_FILES"))

    # make sure the odoo_debug.txt exists; otherwise directory is created
    __file_default_content(files['run/odoo_debug.txt'], "")

    if not E("ODOO_MODULE_UPDATE_RUN_TESTS"):
        print("Please define wether to run tests on module updates by setting ODOO_MODULE_UPDATE_RUN_TESTS")
        time.sleep(2)


def _setupArgs():
    parser = argh.ArghParser()
    commands = []
    module = sys.modules[__name__]
    for member in getmembers(module, inspect.isfunction):
        name, member = member
        if isinstance(member, types.FunctionType):
            if not name.startswith('_') and (len(name) > 2 or name in ['up', 'rm']):
                commands.append(member)

    parser.add_commands(commands)

    return parser

def _setup_odoo_instances():
    def __add_location_files(config_path, dir):
        lines = []
        for subdir in os.listdir(dir):
            if os.path.isdir(os.path.join(dir, subdir)):
                for file in os.listdir(os.path.join(dir, subdir)):
                    lines.append("\tInclude " + os.path.join("/etc/proxy", os.path.basename(subdir), file))
        __replace_in_file(config_path, "__INCLUDES__", '\n'.join(lines))

    if os.path.exists(files['odoo_instances']):

        if os.path.exists(files['odoo_instances']):
            for line in __file_get_lines(files['odoo_instances']):
                name, domain = line.strip().split(" ")
                config_path = os.path.join(dirs['proxy_configs_dir'], "{}.host".format(name))
                shutil.copy(files['machines/proxy/instance.conf'], config_path)

                if domain == "default":
                    __replace_in_file(config_path, "__DOMAIN__", '*')
                else:
                    if domain:
                        __replace_in_file(config_path, "__DOMAIN__", domain)
                if name != "default":
                    # adapt the one yml file and duplicate the odoo service there;
                    # removing any ports
                    with open(files['docker_compose']) as f:
                        j = yaml.load(f.read())
                    odoo = copy.deepcopy(j['services']['odoo'])
                    if 'ports' in odoo:
                        del odoo['ports']
                    odoo['container_name'] = '_'.join([os.environ['CUSTOMS'], "odoo", name])
                    j['services']['odoo_{}'.format(name)] = odoo
                    with open(files['docker_compose'], 'w') as f:
                        f.write(yaml.dump(j, default_flow_style=False))

    for file in os.listdir(dirs['run/proxy']):
        if not file.endswith('.host'):
            continue
        config_path = os.path.join(dirs['run/proxy'], file)
        __add_location_files(config_path, dirs['run/proxy'])


def _setup_proxy():
    CONFIG_DIR = dirs['run/proxy']
    __empty_dir(dirs['proxy_configs_dir'])

    sys.path.append(dirs['machines/proxy'])
    importlib.import_module("add_upstream")
    from add_upstream import add_upstream as f_add_upstream

    def get_rules():
        for root, _, _filenames in os.walk(dirs['machines']):
            for filename in _filenames:
                if filename == 'upstream.path':
                    filepath = os.path.join(root, filename)
                    machine = None
                    p = filepath
                    while os.path.basename(p) != "machines":
                        machine = os.path.basename(p)
                        p = os.path.dirname(p)
                    del p

                    try:
                        version = float(os.path.basename(os.path.dirname(filepath)))
                    except Exception:
                        version = None
                    else:
                        if str(version) != str(odoo_config.get_version_from_customs(os.environ['CUSTOMS'])):
                            continue
                    with open(filepath, 'r') as f:
                        content = f.readlines()
                        for line in content:
                            LOCATION, UPSTREAM = line.strip().split(" ")
                            if not LOCATION or not UPSTREAM:
                                raise Exception("Invalid rule: {}".format(line))
                            yield filepath, LOCATION, UPSTREAM, machine

    for filepath, LOCATION, UPSTREAM, machine in get_rules():
        __makedirs(os.path.join(CONFIG_DIR, machine))
        location_friendly_name = LOCATION.replace("/", "_")
        filename = "{}.location".format(location_friendly_name)
        CONFIG_PATH = os.path.join(CONFIG_DIR, machine, filename)
        UPSTREAM_INSTANCE = UPSTREAM.replace("default", "odoo")
        f_add_upstream(LOCATION, UPSTREAM_INSTANCE, CONFIG_PATH)

def __start_postgres_and_wait():
    if E("RUN_POSTGRES") == "1":
        __dc(["up", "-d", "postgres"])
        __wait_for_port(E("DB_HOST"), long(E("DB_PORT")), timeout=30)
        __execute_sql("""
        SELECT table_schema,table_name
        FROM information_schema.tables
        ORDER BY table_schema,table_name;
        """, dbname='template1')

def _startup():
    if os.path.isfile(files['settings']):
        _file2env(files['settings'])
    dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))) # script directory
    dir = os.path.dirname(dir)
    dirs['odoo_home'] = dir

    def make_absolute(d):
        for k, v in d.items():
            if not v.startswith('/'):
                d[k] = os.path.join(dir, v)
    make_absolute(dirs)
    try:
        odoo_config.current_customs()
    except Exception:
        pass
    else:
        dirs['customs'] = odoo_config.customs_dir()
    make_absolute(files)
    os.environ['ODOO_MANAGER_STARTED_ONCE'] = '1'
    os.environ['ODOO_COMPOSE_VERSION'] = "3.3"
    os.environ['PGPASSFILE'] = "/tmp/.pgpass" # must match the executing script
    os.environ['PGHOST'] = os.path.expandvars("$DB_HOST")
    os.environ['PGPORT'] = os.path.expandvars("$DB_PORT")
    os.environ['PGUSER'] = os.path.expandvars("$DB_USER")
    os.environ['LOCAL_WORKING_DIR'] = "{}/{}".format(os.getenv("EXTERNAL_ROOT"), os.getenv("WORKING_DIR"))  # the working directory accessible from container of this script.
    dirs['host_working_dir'] = os.environ['LOCAL_WORKING_DIR']
    commands['dc'] = [x.replace("$docker_compose_file", files['docker_compose']) for x in commands['dc']]

def abort_upgrade():
    print "Aborting upgrade..."
    SQL = """
        UPDATE ir_module_module SET state = 'installed' WHERE state = 'to upgrade';
        UPDATE ir_module_module SET state = 'uninstalled' WHERE state = 'to install';
    """
    __execute_sql(SQL)

def E(name):
    if name.startswith("$"):
        name = name[1:]
    return os.getenv(name, "")

def attach(machine):
    """
    attaches to running machine
    """
    _display_machine_tips(machine)
    bash = _get_bash_for_machine(machine)
    __cmd_interactive('exec', machine, bash)

def backup(filename=None):
    """"
    Runs backup-db and backup-files
    """
    t1 = Thread(target=backup_db, args=(filename,))
    t2 = Thread(target=backup_files)
    t1.start()
    t2.start()
    t1.join()
    t2.join()

def backup_calendar(filename=None):
    if E("RUN_CALENDAR") != "1":
        return
    filename = filename or datetime.now().strftime("{}.calendar.%Y%m%d%H%M%S.dump.gz".format(E("CUSTOMS")))
    filepath = os.path.join(BACKUPDIR, filename)
    __backup_postgres(
        filepath,
        dbname=E("CALENDAR_DB_NAME"),
        host=E("CALENDAR_DB_HOST"),
        port=E("CALENDAR_DB_PORT"),
        user=E("CALENDAR_DB_USER"),
        password=E("CALENDAR_DB_PWD"),
    )


def __backup_postgres(filepath, dbname, host, port, user, password):
    os.environ['PGPASSWORD'] = password
    conn = psycopg2.connect(dbname=dbname, host=host, port=long(port), user=user, password=password)
    cr = conn.cursor()
    cr.execute("SELECT (pg_database_size(current_database())) FROM pg_database")
    size = cr.fetchone()[0] * 0.7 # ct
    bytes = str(float(size)).split(".")[0]
    conn.close()
    os.system('pg_dump -h "{host}" -p {port} -U "{user}" -Z0 -Fc {dbname} | pv -s {bytes} | pigz --rsyncable > {filepath}'.format(**locals()))

def backup_db(filename=None):
    filename = filename or datetime.now().strftime("{}.odoo.%Y%m%d%H%M%S.dump.gz".format(E("CUSTOMS")))

    if filename.startswith("/"):
        raise Exception("No slash for backup filename allowed")
    print "Databasename is " + E("DBNAME")
    filepath = os.path.join(BACKUPDIR, filename)
    if os.path.exists(filepath):
        os.unlink(filepath)
    LINKPATH = os.path.join(BACKUPDIR, 'latest_dump')
    __start_postgres_and_wait()

    __backup_postgres(filepath, E("DBNAME"), E("DB_HOST"), E("DB_PORT"), E("DB_USER"), E("DB_PWD"))

    if E("NO_BACKUP_SYMBOLIC_LINK_DUMP") != "1":
        if os.path.islink(LINKPATH) or os.path.exists(LINKPATH):
            os.unlink(LINKPATH)
        __system([
            'ln',
            '-s',
            os.path.basename(filepath),
            os.path.basename(LINKPATH)
        ], cwd=os.path.dirname(filepath))
    print "Dumped to ", filepath
    telegram_send("Database Backup $DBNAME done to $filepath")

def backup_files():
    BACKUP_FILENAME = "{CUSTOMS}.files.tar.gz".format(CUSTOMS=E("CUSTOMS"))

    if os.path.exists(BACKUP_FILENAME):
        second = BACKUP_FILENAME + ".bak"
        if os.path.exists(second):
            os.unlink(second)
        shutil.move(BACKUP_FILENAME, second)
    __dcrun(["odoo", "/backup_files.sh", BACKUP_FILENAME])
    print "Backup files done to {}".format(BACKUP_FILENAME)

def build(machines='', pull=False, nocache=False):
    """
    no parameter all machines, first parameter machine name and passes other params; e.g. ./odoo build asterisk --no-cache"
    """
    options = []
    if pull:
        options += ['--pull']
    if nocache:
        options += ['--no-cache']

    __dc(['build'] + options + __splitcomma(machines))

def commit(*parameters):
    versioning.actions["commit"](*parameters)

def prep(customs='', db='', demo=False):
    return compose(customs=customs, db=db, demo=demo)

def reload():
    """
    After settings change call this def to update all settings.
    """
    config = MyConfigParser(files['settings'])
    compose(customs=config['CUSTOMS'], db=config['DBNAME'], demo=config['ODOO_DEMO'] == "1")

def compose(customs='', db='', demo=False):
    """
    - builds docker compose
    - builds proxy settings
    - setups odoo instances
    """
    def setup_settings_file():
        """
        Cleans run/settings and sets minimal settings;
        Puts default values in settings.d to override any values
        """
        config = MyConfigParser(files['settings'])
        if customs:
            if config.get('CUSTOMS', '') != customs:
                config.clear()
                config['CUSTOMS'] = customs
                config.write()
        vals = {}
        if customs:
            vals['CUSTOMS'] = customs
        if db:
            vals['DBNAME'] = db
        if demo:
            vals['ODOO_DEMO'] = "1" if demo else "0"

        for k, v in vals.items():
            if config.get(k, '') != v:
                config[k] = v
                config.write()
        if not os.path.isdir(dirs['settings.d']):
            os.makedirs(dirs['settings.d'])
        config_compose_minimum = MyConfigParser(os.path.join(dirs['settings.d'], 'compose'))
        config_compose_minimum.clear()
        for k in ['CUSTOMS', 'DBNAME', 'ODOO_DEMO']:
            if k in vals:
                config_compose_minimum[k] = vals[k]
        config_compose_minimum.write()
    setup_settings_file()

    _export_settings()
    _remove_temp_directories()
    _prepare_filesystem()
    _prepare_yml_files_from_template_files()
    _reset_proxy_configs()
    _setup_proxy()
    _setup_odoo_instances()
    # ln path ./src to customs
    SRC_PATH = os.path.join(os.environ['LOCAL_ODOO_HOME'], 'src')
    if os.path.islink(SRC_PATH):
        os.unlink(SRC_PATH)
    os.symlink('data/src/customs/{}'.format(E("CUSTOMS")), SRC_PATH)

    print "Built the docker-compose file."

def current_ticket():
    versioning.actions["current-ticket"]()

def deactivate_old_modules():
    """
    Sets modules to 'uninstalled', that have no module dir anymore.
    """
    print("Analyzing which modules to remove...")
    wait_for_container_postgres()
    mods = sorted(map(lambda x: x[0], __execute_sql("select name from ir_module_module where state in ('installed', 'to install', 'to upgrade') or auto_install = true;", fetchall=True)))
    mods = filter(lambda x: x not in ('base'), mods)
    to_remove = []
    for mod in mods:
        for path in get_odoo_addons_paths() + [get_links_dir()]:
            if get_manifest_path_of_module_path(os.path.join(path, mod)):
                break
        else:
            to_remove.append(mod)
    if not to_remove:
        print("Nothing found to remove")
        sys.exit(0)
    print("Following modules are set to uninstalled:")
    for mod in to_remove:
        print(mod)
    raw_input("Continue? (Ctrl+c otherwise)")
    for mod in to_remove:
        __execute_sql("update ir_module_module set auto_install=false, state = 'uninstalled' where name = '{}'".format(mod))
        print("Set module {} to uninstalled.".format(mod))

def debug(machine_name):
    """
    starts /bin/bash for just that machine and connects to it; if machine is down, it is powered up; if it is up, it is restarted; as command an endless bash loop is set"
    """

    # puts endless loop into container command and then attaches to it;
    # by this, name resolution to the container still works
    __set_db_ownership()
    _askcontinue("Current machine {} is dropped and restartet with service ports in bash. Usually you have to type /debug.sh then.".format(machine_name))
    # shutdown current machine and start via run and port-mappings the replacement machine
    kill(machine_name)
    rm(machine_name)
    shutil.copy(files['debugging_template'], files['debugging_composer'])
    __replace_in_file(files['debugging_composer'], "${CUSTOMS}", E("CUSTOMS"))
    __replace_in_file(files['debugging_composer'], "${NAME}", machine_name)

    # TODO make configurable in machines
    PORT = str({
        'odoo': 8072,
        'odoo_debug': 8072
    }.get(machine_name, 80))
    __replace_in_file(files['debugging_composer'], "{machine_main_port}", PORT)
    commands['dc'] += ['-f', files['debugging_composer']]

    __dc(['up', '-d', machine_name])
    attach(machine_name)

def deploy():
    versioning.action_deploy_ticket()

def dev():
    """
    starts developing in the odoo container
    """
    kill(brutal=True)
    rm()
    build()
    up(daemonized=True)
    attach('odoo')

def dirty():
    versioning.dirty()

def do_command(cmd, *params, **kwparams):
    cmd = cmd.replace('-', '_')
    return globals()[cmd](*params, **kwparams)

def drop_db(dbname, force=False):

    if E("DEVMODE") != "1" and not force:
        print("Either DEVMODE or force required")
        sys.exit(-1)
    __remove_postgres_connections(dbname)
    __execute_sql("drop database {};".format(dbname), dbname='template1', notransaction=True)
    print("Database {} dropped.".format(dbname))

def execute(*parameters):
    __dcexec(*parameters)

def export_i18n(lang, modules):
    __dcrun(['odoo', '/export_i18n.sh', lang, modules])
    # file now is in $DIR/run/i18n/export.po

def fix_permissions():
    if E("ODOO_FILES") and os.path.isdir(E("ODOO_FILES")) and E("OWNER_UID") and E("OWNER_UID") != "0":
        __try_to_set_owner(E("OWNER_UID", E("ODOO_FILES"), recursive=True))
    customs_dir = odoo_config.customs_dir()
    __try_to_set_owner("1000", customs_dir, recursive=True) # so odoo user has access

def force_kill(machine):
    kill(machine, brutal=True)

def get_all_langs():
    langs = [x[0] for x in __execute_sql(
        "select distinct code from res_lang;",
        fetchall=True
    )]
    for lang in langs:
        print(lang)
    return langs

def get_dump_type(filename):
    dump_file = os.path.join(BACKUPDIR, filename)
    dump_type = __get_dump_type(dump_file)
    print dump_type

def kill(machines="", brutal=False):
    """
    kills running machine
    safely shutdowns postgres and redis

    if not brutal it means softly
    """
    machines = __splitcomma(machines)
    if not brutal:
        safe_stop = []
        for machine in SAFE_KILL:
            if not machines or machine in machines:
                if __is_container_running(machine):
                    safe_stop += [machine]

        if safe_stop:
            __dc(["stop", "-t 20"] + safe_stop)  # persist data
    __dc(['stop', '-t 2'] + list(machines))

def image_import(image_filename):
    dump_path = os.path.join(BACKUPDIR, os.path.basename(image_filename))
    __system([
        "docker",
        "load",
        dump_path
    ])

def image_export():
    """
    Exports all images of the customizations to one file.
    Can be imported via image-import.
    """
    dump_path = os.path.join(BACKUPDIR, E("CUSTOMS") + '.docker.images.tar')
    folder = tempfile.mkdtemp()
    image_ids = __dc([
        'images',
        '-q',
    ], suppress_out=True).split("\n")
    filesize = 0
    for image in image_ids:
        if not image:
            continue
        filepath = os.path.join(folder, image)
        print "Storing {} to {}".format(image, filepath)
        __system([
            'docker',
            'save',
            image,
            '-o',
            filepath,
        ], suppress_out=True)
        filesize += os.stat(filepath).st_size
        print "File size currently:", humanize.naturalsize(filesize)
    if not filesize:
        raise Exception("No images found!")
    __system([
        "tar",
        "cfz",
        dump_path,
        '.',
    ], cwd=folder)
    print os.path.basename(dump_path)
    compressed_size = os.stat(dump_path).st_size
    ratio = round(float(compressed_size) / float(filesize) * 100.0, 1)
    print "Compressed:", humanize.naturalsize(compressed_size), "Uncompress:", humanize.naturalsize(filesize), "Ratio:", ratio

def incversions():
    versioning.actions["incversions"]()

def link():
    """
    links all modules into ./links
    """
    os.system("python " + os.path.join(dirs['admin'], 'link_modules'))

def logsn(lines, machine):
    """
    logoutput of machine; use parameter for machine
    """
    __dc(['logs', '--tail=' + lines, '-f', '-t'] + machine)

def logs(machine=None, lines=None):
    lines = 0
    if lines:
        print "Showing last {}lines".format(lines)

    cmd = ['logs', '-f', '-t']
    if lines:
        cmd += ['--tail={}'.format(lines)]
    if machine:
        cmd += [machine]
    __dc(cmd)

def logall(*machines):
    __dc(['logs', '-f', '-t'] + list(machines))

def import_i18n(lang, po_file_path):
    __dcrun(['odoo', '/import_i18n.sh', lang, po_file_path])

def make_customs(customs, version):
    raise Exception("rework - add fetch sha")
    _askcontinue()
    admin_dir = dirs['admin']
    kill()
    _tools_make_customs(
        customs=customs,
        version=version,
    )
    os.environ['CUSTOMS'] = customs
    cwd = os.path.join(dirs['odoo_home'], 'customs', customs)
    checkout_odoo()
    odoo_dir = os.path.join(cwd, 'odoo')
    __system([
        'git', 'checkout', str(version)
    ], cwd=odoo_dir)
    __system([
        'git', 'checkout', str(version)
    ], cwd=admin_dir)
    __system([
        "OCA-all"
    ], cwd=admin_dir)
    __system([
        "odoo-submodule",
        'tools,web_modulesroduct_modules,calendar_ics',
    ], cwd=admin_dir)
    kill()
    compose(customs)
    up()

def OCA(module):
    __system([
        files['OCA'],
        module,
    ], cwd=dirs['admin'])

def migrate(from_version, to_version, no_git_clean=False, debug=False, module='all', pull_latest=False):
    """
    For debugging migration of certain module provide module parameter.
    """
    kill(machines="proxy,odoo", brutal=True)
    git_clean = not no_git_clean
    del no_git_clean
    LOGFILE = os.path.join(odoo_config.customs_dir(), "migration_{}_{}.log".format(E("CUSTOMS"), datetime.now().strftime("%Y-%m-%dT%H%M%S")))
    fix_permissions()
    try:
        do_migrate(
            E("CUSTOMS"),
            LOGFILE,
            from_version,
            to_version,
            do_command,
            SETTINGS_D_FILE=os.path.join(dirs['settings.d'], 'migration'),
            git_clean=git_clean,
            debug=debug,
            module=module,
            pull_latest=pull_latest,
        )
    except Exception:
        import traceback
        msg = traceback.format_exc()
        with open(LOGFILE, 'a') as f:
            f.write("\n")
            f.write(msg)
        print(msg)
        print("Error occurred during migration, suggestions:")
        print("")
        print("1. Run odoo version and startup frontend, use ./odoo checkout odoo -f -v xx.xx to set odoo")
    finally:
        print("Suggestion to run after migration:")
        print("=====================================")
        print("./odoo deactivate-old-modules")
        print("./odoo update -d")
        print("./odoo update -i")
        print("./odoo update")

def new_ticket(ticket_name):
    versioning.actions['new-ticket'](*[ticket_name])

def open_tickets(command_options):
    versioning.actions["open-tickets"]()

def patch(*parameters):
    customs_dir = dirs['customs']
    odoo_dir = os.path.join(customs_dir, 'odoo')
    __assert_file_exists(odoo_dir, isdir=True)
    os.chdir(dirs['odoo_home'])
    os.system(" ".join(pipes.quote(x) for x in [
        'admin/odoo-patch'
    ] + list(parameters)))

def prepare():
    print "All configurations prepared."

def progress():
    for row in __execute_sql("select state, count(*) from ir_module_module group by state;", fetchall=True):
        print "{}: {}".format(row[0], row[1])

def proxy_reload():
    if __is_container_running('proxy'):
        __dcexec(['proxy', '/opt/bin/hot_reload.sh'])

def __get_all_subtrees():
    res = __system([
        'git',
        'log',
    ], cwd=dirs['customs'], suppress_out=True)
    for line in res.split("\n"):
        if 'git-subtree-dir' in line:
            path = line.split(":")[-1].strip()
            yield path # e.g. common/module1

def list_subtrees():
    for x in __get_all_subtrees():
        print(x)

def pull_all():
    for mod in __get_all_subtrees():
        if mod.startswith("common/"):
            path = os.path.join(dirs['customs'], mod)
            if os.path.isdir(path):
                mod = mod[len("common/"):]
                pull(mod)

def push_all():
    for mod in __get_all_subtrees():
        push(mod)

def pull(submodule):
    branch = E("ODOO_VERSION")
    print("Pulling latest version of {} branch {}".format(submodule, branch))
    __assert_file_exists(os.path.join(dirs['customs'], '.git'))
    __system([
        'git',
        'subtree',
        'pull',
        '--message',
        'SUBTREE-PULL {}'.format(submodule),
        '--prefix',
        'common/{}'.format(submodule),
        '--squash',
        'git.mt-software.de:/git/openerp/modules/{}'.format(submodule),
        branch,
    ], cwd=dirs['customs'])

def push(submodule_name):
    __assert_file_exists(os.path.join(dirs['customs'], '.git'))

    __system([
        'git',
        'subtree',
        'push',
        '--prefix=common/{}'.format(submodule_name),
        'git.mt-software.de:/git/odoo/modules/{}'.format(submodule_name),
        E("ODOO_VERSION"),
    ], cwd=dirs['customs'])

def psql(dbname=None, *params):
    if not dbname and len(params) == 1:
        if params[0] in ['template1', E("DBNAME")]:
            dbname = params[0]
            params = []
    if not dbname:
        dbname = E("DBNAME")
    params = " ".join(params)
    os.system("psql {} ".format(dbname) + params)

def rebuild(machines=""):
    compose(E("CUSTOMS"))
    build(machines=machines, nocache=True)

def remove_web_assets():
    """
    if odoo-web interface is broken (css, js) then purging the web-assets helps;
    they are usually recreated when admin login
    """
    _askcontinue()
    remove_webassets()
    if float(E("ODOO_VERSION")) <= 10.0:
        print("Please login as admin, so that assets are recreated.")

def reset_db():
    _askcontinue("Delete database {}".format(E("DBNAME")))
    print "Stopping all services and creating new database"
    if E("RUN_POSTGRES") == "1":
        __reset_postgres_container()
    else:
        __remove_postgres_connections(E("DBNAME"), 'drop database {};'.format(E("DBNAME")))

    print "Database initialized."

def restart(machines=""):
    kill(machines)
    rm(machines)
    __dc(['up', '-d', '--force-recreate'] + __splitcomma(machines))
    proxy_reload()

def rm(machines=''):
    __dc(['rm', '-f'] + __splitcomma(machines))

def restore_dev_db(filename='', force=False, ignore_filename_match_dbname=False):
    if E("ALLOW_RESTORE_DEV") != "1" and not FORCE:
        raise Exception("ALLOW_RESTORE_DEV must be explicitly allowed.")

    print("Restores dump to {DB_HOST} and executes to scripts to adapt user passwords, mailservers and cronjobs".format(
        DB_HOST=E("DB_HOST"),
    ))

    def exec_sql(dbname):
        __turn_into_devdb(dbname)

    restore_db(
        filename,
        exec_before_rename=exec_sql,
        restore_as_dev_db=True,
        ignore_filename_match_dbname=ignore_filename_match_dbname,
    )

def restore_files(dumpfile):
    __do_restore_files(dumpfile)

def restore_db(filename="", exec_before_rename=None, restore_as_dev_db=False, ignore_filename_match_dbname=False):
    for x in ['CUSTOMS', "DBNAME", "DB_HOST", "DB_PORT", "RUN_POSTGRES", "RUN_POSTGRES_IN_RAM"]:
        print("{}: {}".format(x, E(x)))
    if not filename:
        _files = os.listdir(BACKUPDIR)

        def _get_ctime(filepath):
            try:
                return os.path.getctime(os.path.join(BACKUPDIR, filepath))
            except Exception:
                return 0
        rows = []
        for i, file in enumerate(sorted(filter(lambda x: _get_ctime(x), _files), reverse=False, key=_get_ctime)):
            filepath = os.path.join(BACKUPDIR, file)
            delta = datetime.now() - datetime.fromtimestamp(os.path.getmtime(filepath))
            rows.append((
                i + 1,
                file,
                humanize.naturaltime(delta),
                humanize.naturalsize(os.stat(filepath).st_size)
            ))
        print tabulate(rows, ["Nr", 'Filename', 'Age', 'Size'])

        nr = raw_input("Restore which one?")
        if nr:
            nr = int(nr)
            filename = rows[nr - 1][1]
    filename == os.path.join(BACKUPDIR, filename)
    if filename.startswith("/"):
        raise Exception("No path in dump file allowed")
    if not ignore_filename_match_dbname:
        __restore_check(filename)
    if E("DEVMODE") == "1" and not restore_as_dev_db:
        _askcontinue("DEVMODE ist set - really restore as normal db? Not using restore-dev-db?")

    if not FORCE:
        _askcontinue("Deletes database {}!".format(E("DBNAME")))

    DBNAME_RESTORING = E("DBNAME") + "_restoring"
    os.environ['DBNAME'] = DBNAME_RESTORING

    config = MyConfigParser(files['settings'])
    dbname = config['DBNAME']

    reset_db()
    __do_restore_db_on_postgres(filename, DBNAME_RESTORING, E("DB_HOST"), E("DB_PORT"), E("DB_USER"), E("DB_PWD"))
    if exec_before_rename:
        exec_before_rename(DBNAME_RESTORING)
    __rename_db_drop_target(DBNAME_RESTORING, dbname)
    __remove_postgres_connections(dbname)
    __set_db_ownership()
    telegram_send("Database Restore $DBNAME done.")

def rmpyc():
    for root, _, _files in os.walk(dirs['customs']):
        for filename in _files:
            if filename.endswith(".pyc"):
                os.unlink(os.path.join(root, filename))

def run(machine, *params, **kwparams):
    __set_db_ownership()
    params = list(params)
    if params and params[0] == 'bash' and len(params) == 1:
        runbash(machine)
        return
    __dcrun([machine] + params, **kwparams)

def runbash(machine, *args):
    __set_db_ownership()
    _display_machine_tips(machine)
    bash = _get_bash_for_machine(machine)
    cmd = ['run', machine]
    if args:
        cmd += args
    else:
        cmd += [bash]
    __cmd_interactive(*tuple(cmd))

def sanity_check():
    _sanity_check()

def set_db(DBNAME):
    set_settings(DBNAME)

def set_settings(key, value):
    config = MyConfigParser(files['settings'])
    config[key.upper()] = value
    config.write()

def set_db_ownership():
    __set_db_ownership()
    _export_settings()

def setup_startup():
    if os.path.exists("/sbin_host/initctl"):
        raise Exception("Not impl")
    else:
        print "Setting up systemd script for startup"
        servicename = os.path.expandvars("${CUSTOMS}_odoo.service")
        file = os.path.join("/tmp_host, servicename")

        # echo "Setting up upstart script in $file"
        shutil.copy(os.path.join(dirs['odoo_home'], 'config', 'systemd'), file)
        __replace_in_file(file, "${CUSTOMS}", E("CUSTOMS"))
        __replace_in_file(file, "${PATH}", E("HOST_ODOO_HOME"))

        print("Please execute on host now (perhaps as sudo):")
        print("""cp /tmp/{servicename} /etc/systemd/system")
        systemctl stop {servicename}
        systemctl disable {servicename}
        systemctl daemon-reload
        systemctl reset-failed
        systemctl enable {servicename}
        systemctl start {servicename}
        """.format(servicename=servicename)
              )

def shell():
    __cmd_interactive('run', 'odoo', '/bin/bash', '/shell.sh')

def show_install_state(suppress_error=False):
    print("Displaying dangling modules:")
    dangling = __get_dangling_modules()
    for row in dangling:
        print("{}: {}".format(row[0], row[1]))

    if dangling and not suppress_error:
        raise Exception("Dangling modules detected - please fix installation problems and retry!")

def simplebash(*parameters):
    if not parameters:
        os.system("bash --noprofile")
    else:
        os.system("bash --noprofile -c {}".format(" ".join(parameters)))

def springclean():
    os.system("docker system prune")
    print("removing dead containers")
    os.system('docker ps -a -q | while read -r id; do docker rm "$id"; done')

    print("Remove untagged images")
    os.system('docker images | grep "<none>" | awk \'{ print "docker rmi " $3 }\' | bash')

    print("delete unwanted volumes (can pass -dry-run)")
    os.system('docker images -q -f="dangling=true" | while read -r id; do docker rmi "$id"; done')

def stage():
    versioning.action_stage_ticket()

def status():
    __print_env(["CUSTOMS", "DBNAME", "DB_HOST", "RUN_POSTGRES", "RUN_POSTGRES_IN_RAM", "ODOO_VERSION"])
    # print("Configuration files:")
    # for dir in _collect_settings_files():
        # print dir, '(dir)' if os.path.isdir(dir) else ''
    # os.system("df -h")

def stop(machines):
    kill(machines)

def submodule(*submodules):
    if not submodules:
        print("Please provide some modules!")
        sys.exit(-1)
    __assert_file_exists(os.path.join(dirs['customs'], '.git'))
    __assert_file_exists(os.path.join(dirs['customs'], 'common'))

    for submodule in submodules:
        __system([
            'git',
            'subtree',
            'add',
            '--prefix=common/{}'.format(submodule),
            '--squash',
            'git.mt-software.de:/git/openerp/modules/{}'.format(submodule),
            E("ODOO_VERSION"),
        ], cwd=dirs['customs'])

def checkout_odoo(version='', not_use_local_repo=True, commit_changes=False, force=False):
    """
    Can used for migration tests:
     - temporary switch to odoo version

    """
    __assert_file_exists(os.path.join(dirs['customs'], '.version'))

    if os.path.isdir(os.path.join(dirs['customs'], 'odoo')) and not force:
        raise Exception("Odoo already exists")

    if not version:
        version = __read_file(os.path.join(dirs['customs'], '.version')).strip()
    version = float(version)

    __system([
        'git',
        'status',
    ], cwd=dirs['customs'])
    odoo_path = os.path.join(dirs['customs'], 'odoo')
    if os.path.exists(odoo_path):
        shutil.rmtree(odoo_path)
        if commit_changes:
            __system([
                'git',
                'add',
                '.'
            ], cwd=dirs['customs'])
            __system([
                'git',
                'commit',
                '-am "removed current odoo"'
            ], cwd=dirs['customs'])

    if not_use_local_repo:
        url = '/opt/odoo/repos/odoo'
    else:
        url = 'https://github.com/odoo/odoo'
    __system([
        'git',
        'clone',
        url,
        '--branch',
        str(version),
        '--single-branch',
        'odoo',
    ], cwd=dirs['customs'])
    sha = __system([
        'git',
        'rev-parse',
        "HEAD",
    ], cwd=odoo_path).strip()

    shutil.rmtree(os.path.join(dirs['customs'], 'odoo/.git'))
    with open(os.path.join(dirs['customs'], '.version'), 'w') as f:
        f.write(str(version))
    with open(os.path.join(dirs['customs'], 'odoo.commit'), 'w') as f:
        f.write(sha.strip())
    reload() # apply new version
    status()

def switch_ticket(ticket):
    versioning.actions["switch-ticket"](*[ticket])

def telegram_setup():
    """
    helps creating a permanent chatid
    """
    if E("TELEGRAM_ENABLED") == "1":
        os.system("""
cd "{dir}"
docker-compose run -it telegrambat /setup.sh
""".format(dir=dirs['telegrambot']))

def telegram_send(message):
    if E("TELEGRAM_ENABLED") == "1":
        os.system("""
            cd "{dir}"
            docker-compose run telegrambat /send.py "{message}"
        """.format(
            dir=dirs['telegrambot'],
            message=message,
        ))

def test():
    print 'reached the command area'
    print os.path.expandvars("CUSTOMS is: $CUSTOMS")
    print os.path.expandvars("Here is pgpassfile: $PGPASSFILE")
    print "Now calling simple psql"
    __execute_sql("select state, count(*) from ir_module_module group by state;")

def test_make_error():
    print("now throwing exit code")
    sys.exit(123)

def turn_into_dev():
    if E("DEVMODE") != "1":
        raise Exception("""When applying this sql scripts, the database is not usable anymore for production environments.
Please set DEVMODE=1 to allow this""")
    __turn_into_devdb(E("DBNAME"))

def up(machines='', daemonized=False):
    if machines and 'postgres' not in machines:
        __set_db_ownership()
    options = [
    ]
    if daemonized:
        options += ['-d']
    __dc(['up'] + options + __splitcomma(machines))
    proxy_reload()

def update(module="", dangling_modules=False, installed_modules=False, keep_containers=False, non_interactive=False):
    """
    Just custom modules are updated, never the base modules (e.g. prohibits adding old stock-locations)
    Minimal downtime - but there is a downtime, even for phones

    :upgrade_installed_modules: run after migration:
    """
    module = module.split(',')
    __start_postgres_and_wait()
    if any(x[1] == 'uninstallable' for x in __get_dangling_modules()):
        for x in __get_dangling_modules():
            print("{}: {}".format(*x[:2]))
        if raw_input("Uninstallable modules found - shall I set them to 'uninstalled'? [y/N]").lower() == 'y':
            __execute_sql("update ir_module_module set state = 'uninstalled' where state = 'uninstallable';")
    if __get_dangling_modules() and not dangling_modules:
        show_install_state(suppress_error=True)
        raw_input("Abort old upgrade and continue? (Ctrl+c to break)")
        abort_upgrade()
    if installed_modules:
        module += __get_installed_modules()
    if dangling_modules:
        module += [x[0] for x in __get_dangling_modules()]
    module = ','.join(filter(lambda x: x, module))

    print("Run module update")
    if E("ODOO_UPDATE_START_NOTIFICATION_TOUCH_FILE_IN_CONTAINER") == "1":
        with open(E("ODOO_UPDATE_START_NOTIFICATION_TOUCH_FILE_IN_CONTAINER"), 'w') as f:
            f.write(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

    # running duplicate updates is really a problem;
    if not keep_containers:
        kill()
        rm()
        __dc(['up', '--no-start', '--force-recreate'])
        __start_postgres_and_wait()
        kill('proxy')

    try:
        params = ['run', 'odoo_update', '/update_modules.py', module]
        if non_interactive:
            params += ['--non-interactive']
        __cmd_interactive(*params)
    except Exception:
        print(traceback.format_exc())
        show_install_state(suppress_error=True)
        raise Exception("Error at /update_modules.py - aborting update process.")
    show_install_state()

    for i in range(5):
        up(daemonized=True)
        proxy_reload()
        time.sleep(2)

    status()
    if E("ODOO_UPDATE_START_NOTIFICATION_TOUCH_FILE_IN_CONTAINER") == "1":
        with open(E("ODOO_UPDATE_START_NOTIFICATION_TOUCH_FILE_IN_CONTAINER"), 'w') as f:
            f.write("0")
    telegram_send("Update done")

def update_ast():
    if _get_platform() == PLATFORM_OSX:
        print "Update is extreme slow on osx due to share performance. Please use following command natively:"
        print
        print
        print 'time PYTHONPATH=$ODOO_HOME/admin/module_tools python -c "from odoo_parser import update_cache; update_cache()"'
        print
        print
        sys.exit(2)
    started = datetime.now()
    print "Updating ast - can take about one minute; slow on OSX due to share"
    update_cache()
    print "Updated ast - took {} seconds".format((datetime.now() - started).seconds)


def wait_for_container_postgres():
    __start_postgres_and_wait()

def wait_for_port(host, port):
    port = long(port)
    __wait_for_port(host=host, port=port)

def __set_project_config(content):
    path = os.path.expandvars("/opt/external_home/.odoodev/conf.json")
    with open(path, 'w') as f:
        f.write(json.dumps(content))

def __get_project_config():
    path = os.path.expanduser("/opt/external_home/.odoodev/conf.json")
    if not os.path.isdir(os.path.dirname(path)):
        os.makedirs(os.path.dirname(path))
    if not os.path.isfile(path):
        with open(path, 'w') as f:
            f.write("{}")
    with open(path, 'r') as f:
        res = json.loads(f.read())
        res.setdefault('projects', [])
    return res

def project_list():
    projects = __get_project_config()['projects']
    for i, project in enumerate(projects):
        print "{}:".format(i + 1), "{}/{}".format(project['customs'], project['db'])
    print("")

def project():
    project_list()
    print("n: new project")
    print("d: delete project")
    input = raw_input("Type number and enter.")

    def goto_index(index):
        project = __get_project_config()['projects'][index]
        compose(customs=project['customs'], db=project['db'], demo=project['demo'])
        dev()

    config = __get_project_config()
    if input == 'n':
        customs = raw_input("Customs:")
        if not customs:
            return
        db = raw_input("DB[{}]".format(customs))
        demo = not (raw_input("use demo? [Y/n]") == 'n')
        demo = demo in ['1', 'true', 'True', 'y', 'Y']
        config['projects'].append({
            'customs': customs,
            'db': db,
            'demo': demo,
        })
        __set_project_config(config)

        index = len(config['projects']) - 1
        goto_index(index)
    elif input == 'd':
        index = int(raw_input("Which index?")) - 1
        config['projects'].remove(config['projects'][index])
        __set_project_config(config)

    try:
        index = int(input) - 1
    except Exception:
        index = 0
    else:
        goto_index(index)


def make_module(name):
    cwd = E("WORKING_DIR")
    _tools_make_module(
        cwd,
        name,
    )


if __name__ == '__main__':
    parser = _setupArgs()
    _startup()
    _check_working_dir_customs_mismatch
    if args:
        if args[0] == 'tool':
            sys.exit(0)

    _remember_customs_and_cry_if_changed

    try:
        parser.dispatch()
    finally:
        _cleanup()
