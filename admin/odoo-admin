#!/usr/bin/python
import argh
import types
from argh import arg
import sys
import re
import signal
import os
import logging
import importlib
import humanize
import subprocess
import time
import inspect
import yaml
import shutil
import tempfile
import docker
from inspect import getmembers, isfunction
from retrying import retry
from datetime import datetime
import copy
from threading import Thread
from Queue import Queue
from logging import FileHandler
from optparse import OptionParser
import psycopg2
from subprocess import PIPE
from module_tools.myconfigparser import MyConfigParser
from module_tools import odoo_config
from module_tools import odoo_versioning as versioning
from module_tools.odoo_parser import update_cache
from migrate import do_migrate

try:
    from pudb import set_trace
except Exception:
    set_trace = None
current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))) # script directory
sys.path.append(os.path.join(current_dir, 'python_wait'))
import wait  # NOQA

PLATFORM_OSX = "OSX"
PLATFORM_LINUX = "Linux"
YAML_VERSION = '3.3'
BACKUPDIR = "/host/dumps"
FORCE = any(x == '-f' or x == '--force' for x in sys.argv[1:])
SAFE_KILL = ['postgres', 'redis']
args = sys.argv[1:]

dirs = {
    'admin': 'admin',
    'odoo_home': '',
    'proxy_configs_dir': 'run/proxy',
    'settings.d': 'run/settings.d',
    'host_working_dir': '',
    'run': 'run',
    'run/proxy': 'run/proxy',
    'run/restore': 'run/restore',
    'machines': 'machines',
    'machines/proxy': 'machines/proxy',
    'customs': '',
    'telegrambot': 'config/telegrambat',
}

files = {
    'make_customs': 'admin/module_tools/make_customs',
    'OCA': 'admin/OCA',
    'docker_compose': 'run/docker-compose.yml',
    'debugging_template': 'config/debugging/template.yml',
    'debugging_composer': 'run/debugging.yml',
    'settings': 'run/settings',
    'odoo_instances': 'run/odoo_instances',
    'config/default_network': 'config/default_network',
    'run/odoo_debug.txt': 'run/odoo_debug.txt',
    'machines/proxy/instance.conf': 'machines/proxy/instance.conf',
    'machines/postgres/turndb2dev.sql': 'machines/postgres/turndb2dev.sql',
}
commands = {
    'dc': ["/usr/local/bin/docker-compose", "-p", "$PROJECT_NAME", "-f",  "$docker_compose_file"],
}


def trace():
    if set_trace:
        set_trace()

def __assert_file_exists(path, isdir=False):
    if not os.path.exists(path):
        raise Exception("{} {} not found!".format(
            'Directory' if isdir else 'File',
            path
        ))

def __dc(cmd, suppress_out=False, raise_exception=True, wait_finished=True, logger=None):
    c = __get_cmd() + cmd
    out = __system(
        c,
        cwd=dirs['odoo_home'],
        suppress_out=suppress_out,
        raise_exception=raise_exception,
        wait_finished=wait_finished,
        logger=logger,
    )
    return out

def __dcexec(cmd):
    c = __get_cmd()
    c = c + ['exec', '-T'] + cmd
    out = __system(c, cwd=dirs['odoo_home'])
    return out

def __dcrun(cmd, interactive=False, wait_finished=True, raise_exception=True, logger=None):
    cmd = [os.path.expandvars(x) for x in cmd]
    if interactive:
        options = ''
    else:
        options = '-T'
    cmd = ['run', '--rm', options, '-e ODOO_HOME=/opt/odoo'] + cmd
    return __dc(cmd, wait_finished=wait_finished, raise_exception=True, logger=logger)

def __do_restore_db_on_postgres(filename, dbname, host, port, user, password):
    dump_file = os.path.join(BACKUPDIR, filename)

    __assert_file_exists(dump_file)

    print("Restoring dump on {}:{} as {}".format(host, port, user))
    os.environ['PGPASSWORD'] = password
    args = ["-h", host, "-p", port, "-U", user]
    PGRESTORE = [
        "pg_restore",
        "--no-owner",
        "--no-privileges",
        "--no-acl",
    ] + args
    PSQL = ["psql"] + args

    __execute_sql("drop database if exists {}".format(dbname), 'template1', notransaction=True)
    __execute_sql("create database {}".format(dbname), 'template1', notransaction=True)

    method = PGRESTORE
    needs_unzip = True

    dump_type = __get_dump_type(dump_file)
    if dump_type == 'plain_text':
        needs_unzip = False
        method = PSQL
    elif dump_type == 'zipped_sql':
        method = PSQL
        needs_unzip = True
    elif dump_type == "zipped_pgdump":
        pass
    elif dump_type == "unzipped_pgdump":
        needs_unzip = False
    else:
        raise Exception("not impl: {}".format(dump_type))

    if needs_unzip:
        unzipper = subprocess.Popen(["/bin/gunzip", "-c", dump_file], stdout=PIPE)
        stdin = unzipper.stdout
    else:
        catter = subprocess.Popen(["/bin/cat", dump_file], stdout=PIPE)
        stdin = catter.stdout
    started = datetime.now()
    print "Restoring DB..."
    subprocess.check_call(method + [
        '-d',
        dbname,
    ], stdin=stdin),
    print "Restore took {} seconds".format((datetime.now() - started).seconds)

def __do_restore_files(filepath):
    # remove the postgres volume and reinit
    if filepath.startswith("/"):
        raise Exception("No absolute path allowed")
    __dcrun(['odoo', '/bin/restore_files.sh', os.path.basename(filepath)])

def __empty_dir(dir):
    if os.path.isdir(dir):
        for f in os.listdir(dir):
            filepath = os.path.join(dir, f)
            if os.path.isdir(filepath):
                __rmtree(filepath)
            else:
                os.unlink(filepath)

def __execute_sql(sql, dbname=None, fetchone=False, fetchall=False, notransaction=False, no_try=False):
    if not dbname:
        dbname = E("DBNAME")

    # try to connecto to postgres; could startup:
    @retry(wait_random_min=500, wait_random_max=800, stop_max_delay=30000)
    def try_connect():
        __execute_sql("SELECT * FROM pg_catalog.pg_tables;", 'template1', no_try=True)
    if not no_try:
        try_connect()

    conn = psycopg2.connect(
        dbname=dbname,
        user=E("DB_USER"),
        password=E("DB_PWD"),
        host=E("DB_HOST"),
        port=E("DB_PORT"),
    )
    conn.autocommit = notransaction
    result = None
    cr = conn.cursor()
    try:
        cr.execute(sql)
        if fetchone:
            result = cr.fetchone()
        elif fetchall:
            result = cr.fetchall()
        conn.commit()
    except Exception:
        conn.rollback()
        raise
    finally:
        cr.close()
        conn.close()
    return result

def __exists_db(dbname):
    dbname = dbname or E("DBNAME")
    sql = "select count(*) from pg_database where datname='{}'".format(dbname)
    record = __execute_sql(sql, fetchone=True, dbname='template1')
    if not record or not record[0]:
        return False
    return True

def __file_default_content(path, default_content):
    if not os.path.exists(path):
        with open(path, 'w') as f:
            f.write(default_content)

def __file_get_lines(path):
    with open(path) as f:
        return f.readlines()

def __find_files(cwd, *options):
    """
    :param options: ["-name", "default.settings"]
    """
    files = subprocess.check_output(["find"] + list(options), cwd=cwd)
    files = files.split("\n")
    files = [x for x in files if x and not x.endswith('/.')]
    files = [os.path.normpath(os.path.join(cwd, x)) for x in files]
    return files

def __get_docker_compose_run_command():
    """
    Returns bash ready command to call simplebash self by run.

    """
    host_odoo_home = os.environ["ODOO_HOME"]
    local_odoo_home = os.environ['LOCAL_ODOO_HOME']
    cmdline = []
    cmdline.append("/opt/docker/docker")
    cmdline.append("run")
    cmdline.append('-e')
    cmdline.append('ODOO_HOME={}'.format(host_odoo_home))
    envfile = os.path.join(local_odoo_home, 'run/settings')
    if os.path.exists(envfile):
        cmdline.append('--env-file')
        cmdline.append(envfile)
    cmdline.append("--rm")
    cmdline.append('-v')
    cmdline.append("{HOST_ODOO_HOME}:{HOST_ODOO_HOME}".format(HOST_ODOO_HOME=os.environ["ODOO_HOME"]))
    cmdline.append("--workdir")
    cmdline.append(host_odoo_home)
    cmdline.append(__get_docker_image())
    return cmdline

@retry(wait_random_min=500, wait_random_max=800, stop_max_delay=30000)
def __get_docker_image():
    """
    Sometimes this command fails; checked with pudb behind call, hostname matches
    container id; seems to be race condition or so
    """
    hostname = os.environ['HOSTNAME']
    result = [x for x in __system(["/opt/docker/docker", "inspect", hostname], suppress_out=True).split("\n") if "\"Image\"" in x]
    if result:
        result = result[0].split("sha256:")[-1].split('"')[0]
        return result[:12]
    return None

def __get_dump_type(filepath):
    temp = tempfile.mktemp(suffix='.check')
    MARKER = "PostgreSQL database dump"
    FNULL = open(os.devnull, 'w')
    proc = subprocess.Popen(['gunzip', '-c', filepath], stdout=subprocess.PIPE, stderr=FNULL, bufsize=1)

    def reader(proc, pipe):
        try:
            lines = 0
            with pipe:
                for line in iter(pipe.readline, ''):
                    with open(temp, 'a') as f:
                        f.write(line)
                        lines += 1
                        if lines > 20:
                            break
        finally:
            if not proc.returncode:
                proc.kill()

    Thread(target=reader, args=[proc, proc.stdout]).start()
    proc.wait()

    if os.path.exists(temp):
        content = __read_file(temp)
        if MARKER in content:
            return 'zipped_sql'
        if content.startswith("PGDMP"):
            return "zipped_pgdump"
    with open(filepath, 'r') as f:
        for i, line in enumerate(f):
            if i == 0 and line.startswith("PGDMP"):
                return 'pgdump'
            if i > 50:
                break
            if MARKER in line:
                return "plain_text"
    return 'unzipped_pgdump'

def __get_cmd():
    cmd = commands['dc']
    cmd = [os.path.expandvars(x) for x in cmd]
    return cmd

def __is_container_running(machine_name):
    container_id = __dc(['ps', '-q', machine_name], raise_exception=False, suppress_out=True).strip()
    if container_id:
        container = filter(lambda container: container.id == container_id, docker.from_env().containers.list())
        if container:
            return container[0].status == 'running'
    return False

def is_up(*machine_name):
    assert len(machine_name) == 1
    print 'Running' if __is_container_running(machine_name[0]) else 'Not Running', machine_name[0]

def __isfloat(x):
    try:
        float(x)
    except Exception:
        return False
    else:
        return True

def __makedirs(path):
    if not os.path.exists(path):
        os.makedirs(path)

def __print_env(vars):
    for x in vars:
        print "{}: {}".format(x, E(x))

def __read_file(path):
    with open(path, 'r') as f:
        return f.read()

def __remove_postgres_connections(DBNAME=None):
    DBNAME = DBNAME or E("DBNAME")
    print "Removing all current connections"
    if __exists_db(DBNAME):
        SQL = """
            SELECT pg_terminate_backend(pg_stat_activity.pid)
            FROM pg_stat_activity
            WHERE pg_stat_activity.datname = '{}'
            AND pid <> pg_backend_pid();
        """.format(DBNAME)
        __execute_sql(SQL, 'template1', notransaction=True)

def __rename_db_drop_target(from_db, to_db):
    if 'to_db' == 'template1':
        raise Exception("Invalid: {}".format(to_db))
    __remove_postgres_connections(from_db)
    __remove_postgres_connections(to_db)
    __execute_sql("drop database if exists {to_db}".format(**locals()), "template1", notransaction=True)
    __execute_sql("alter database {from_db} rename to {to_db};".format(**locals()), "template1", notransaction=True)
    __remove_postgres_connections(to_db)

def __replace_in_file(filepath, text, replacewith):
    with open(filepath, 'r') as f:
        content = f.read()
    content = content.replace(text, replacewith)
    with open(filepath, 'w') as f:
        f.write(content)

def __reset_postgres_container():
    # remove the postgres volume and reinit
    if E("RUN_POSTGRES") == "1":
        print "Resettings postgres - killing data - not reversible"
        VOLUMENAME = "{}_postgresdata".format(E("CUSTOMS"))
        docker_client = docker.from_env()

        @retry(wait_random_min=500, wait_random_max=800, stop_max_delay=30000)
        def remove_volume():
            for volume in docker_client.volumes.list():
                if volume.name == VOLUMENAME:
                    try:
                        kill(brutal=True)
                        __dc(["rm", "-f"]) # set volume free
                        volume.remove()
                    except Exception as e:
                        print e
                        if hasattr(e, 'explanation'):
                            exp = e.explanation

                            if 'volume is in use' in e:
                                container_id = re.findall(r'\[([^\]]*)\]', exp)[0]
                                __system(["docker", "rm", container_id])
                        return None
            return True
        remove_volume()
        __dcrun(['-e', 'INIT=1', 'postgres', '/entrypoint2.sh'])
        __start_postgres_and_wait()

def __restore_check(filepath):
    dumpname = os.path.basename(filepath)

    if E("DBNAME") not in dumpname and not FORCE:
        raise Exception("The dump-name \"{}\" should somehow match the current database \"{}\", which isn't.".format(
            dumpname,
            E("DBNAME"),
        ))

def __rm_file_if_exists(path):
    if os.path.exists(path):
        os.unlink(path)

def __rmtree(path):
    if not path or path == '/':
        raise Exception("Not allowed: {}".format(path))
    if not path.startswith("/"):
        raise Exception("Not allowed: {}".format(path))
    if not any(path.startswith(dirs['odoo_home'] + x) for x in ['/tmp', '/run/']):
        raise Exception('not allowed')
    shutil.rmtree(path)

def __safeget(array, index, exception_on_missing, file_options=None):
    if file_options:
        if os.path.exists(file_options):
            file_options = '\n' + '\n'.join(os.listdir(file_options))
    file_options = file_options or ''
    if len(array) < index + 1:
        raise Exception(exception_on_missing + file_options)
    return array[index]

def __splitcomma(param):
    if isinstance(param, (str, unicode)):
        if not param:
            return []
        return [x.strip() for x in param.split(',') if x.strip()]
    elif isinstance(param, (tuple, list)):
        return list(param)
    raise Exception("not impl")

def __set_db_ownership():
    # in development environments it is safe to set ownership, so
    # that accidently accessing the db fails
    if E("DEVMODE") == "1":
        if E("RUN_POSTGRES") == "1":
            __start_postgres_and_wait()
        from module_tools.module_tools import set_ownership_exclusive
        set_ownership_exclusive()

def __system(cmd, cwd=None, suppress_out=False, raise_exception=True,
             wait_finished=True, shell=False, logger=None, stdin=None,
             pipeout=None, redirect_std_out_to_file=None,
             progress=False, progress_every_seconds=1,
             ):
    assert isinstance(cmd, list)

    STDPIPE, ERRPIPE, bufsize = subprocess.PIPE, subprocess.PIPE, 1
    if (not wait_finished and pipeout is None) or pipeout is False:
        STDPIPE, ERRPIPE, bufsize = None, None, -1
    if pipeout:
        bufsize = 4096
        suppress_out = True
    proc = subprocess.Popen(cmd, shell=shell, stdout=STDPIPE, stderr=ERRPIPE, bufsize=bufsize, cwd=cwd, stdin=stdin)
    collected_errors = []

    def reader(pipe, q):
        try:
            with pipe:
                for line in iter(pipe.readline, ''):
                    q.put((pipe, line))
        except Exception as e:
            print e
        finally:
            q.put(None)

    data = {
        'size_written': 0,
    }
    size_written = out_file = 0
    if redirect_std_out_to_file:
        out_file = open(redirect_std_out_to_file, 'w')
    out = []

    def heartbeat():
        while proc.returncode is None:
            time.sleep(progress_every_seconds)
            print("{} processed".format(humanize.naturalsize(data['size_written'])))

    def handle_output():
        try:
            err = proc.stderr
            q = Queue()
            Thread(target=reader, args=[proc.stdout, q]).start()
            Thread(target=reader, args=[proc.stderr, q]).start()
            for source, line in iter(q.get, None):
                if source != err:
                    out.append(line)
                else:
                    collected_errors.append(line.strip())
                if source == err or not suppress_out:
                    sys.stdout.write(line)
                    sys.stdout.flush()
                if source != err:
                    data['size_written'] += len(line)
                if redirect_std_out_to_file:
                    if source != err:
                        out_file.write(line)

                if logger:
                    if source == err:
                        logger.error(line.strip())
                    else:
                        logger.info(line.strip())
        except Exception as e:
            print e
    if progress:
        t = Thread(target=heartbeat)
        t.daemonized = True
        t.start()

    if wait_finished or progress or redirect_std_out_to_file:
        t = Thread(target=handle_output)
        t.daemonized = True
        t.start()
        if wait_finished:
            t.join()

    if not wait_finished:
        return proc
    proc.wait()
    if out_file:
        out_file.close()
        print("{} Size: {}".format(redirect_std_out_to_file, humanize.naturalsize(size_written)))

    if proc.returncode and raise_exception:
        print '\n'.join(collected_errors)
        raise Exception("Error executing: {}".format(" ".join(cmd)))
    return "".join(out)

def __try_to_set_owner(UID, path, recursive=False):
    if os.path.isdir(path):
        uid = os.stat(path).st_uid
        if str(uid) != str(UID) or recursive:
            print("Trying to set correct permissions on {}".format(path))
            options = ""
            if recursive:
                options += "-R"

            __system([
                'find',
                '-not',
                '-type',
                'l',
                '-not',
                '-user',
                UID,
                '-exec',
                'chown',
                UID,
                '{}',
                '+'
            ], cwd=path)

def __turn_into_devdb(dbname):
    SQLFILE = files['machines/postgres/turndb2dev.sql']
    sql = __read_file(SQLFILE)
    __execute_sql(sql, dbname=dbname)

def __wait_for_port(host, port, timeout=None):
    res = wait.tcp.open(port, host=host, timeout=timeout)
    if not res and timeout:
        raise Exception("Timeout elapsed waiting for {}:{}".format(host, port))

def _askcontinue(msg=None):
    if msg:
        print(msg)
    if FORCE or os.getenv("FORCE_CONTINUE", "0") == "1":
        return
    raw_input("Continue? (Ctrl+C to break)")

def _check_working_dir_customs_mismatch():
    # Checks wether the current working is in a customs directory, but
    # is not matching the correct customs. Avoid creating wrong tickets
    # in the wrong customizations.

    working_dir = dirs['host_working_dir']
    while not os.path.isfile(os.path.join(working_dir, '.customsroot')):
        try:
            working_dir = os.path.dirname(working_dir)
        except Exception:
            break
        if not working_dir.replace("/", ""):
            break

    if os.path.isfile(os.path.join(working_dir, '.customsroot')):
        current_customs = os.path.basename(working_dir)
        if current_customs != os.environ['CUSTOMS']:
            _askcontinue("""Caution: current customs is {} but you are in another customs directory: {}
Continue at your own risk!""".format("$CUSTOMS", "$LOCAL_WORKING_DIR")
                         )

def _cleanup():
    _remove_temp_directories

def _collect_settings_files():
    _files = []
    _files.append(os.path.join(dirs['odoo_home'], 'machines/defaults'))
    # optimize
    for filename in __find_files(dirs['machines'], "-name", "default.settings"):
        _files.append(os.path.join(dirs['machines'], filename))
    customs_dir = odoo_config.customs_dir()
    if os.path.exists(os.path.join(customs_dir, 'settings')):
        for filename in os.listdir(os.path.join(customs_dir, 'settings')):
            _files.append(os.path.join(customs_dir, 'settings', filename))
    if os.path.exists('/etc_host/odoo/{}/settings'.format(os.environ['CUSTOMS'])):
        _files.append('/etc_host/odoo/{}/settings'.format(os.environ['CUSTOMS']))
    if os.path.exists('/etc_host/odoo/settings'):
        _files.append('/etc_host/odoo/settings')
    if os.path.isdir(dirs['settings.d']):
        for filename in os.listdir(dirs['settings.d']):
            filepath = os.path.join(dirs['settings.d'], filename)
            if os.path.exists(filepath):
                _files.append(filepath)
    return _files

def _display_machine_tips(machine_name):
    dir = os.path.join(dirs['machines'], machine_name)
    if not os.path.isdir(dir):
        return

    for filename in __find_files(dirs['machines'], '-name', 'tips.txt'):
        filepath = os.path.join(dirs['machines'], filename)
        if os.path.basename(os.path.dirname(filepath)) == machine_name:
            content = __read_file(os.path.join(dirs['machines'], filename))
            print ""
            print "Please note:"
            print "---------------"
            print ""
            print content
            print ""
            print ""

def _export_settings():
    if args and args[0] == 'compose':
        if len(args) > 1:
            customs = args[1]
            if os.path.isfile(files['settings']):
                os.unlink(files['settings'])
            config = MyConfigParser(files['settings'])
            config['CUSTOMS'] = customs
            config.write()
    _file2env(files['settings'])

    if not os.path.exists(files['settings']):
        raise Exception("Please call ./odoo compose <CUSTOMS> initially.")

    # get odoo version
    ODOO_VERSION = str(odoo_config.get_version_from_customs(os.environ['CUSTOMS']))
    os.environ['ODOO_VERSION'] = ODOO_VERSION
    setting_files = _collect_settings_files()
    _make_settings_file(files['settings'], setting_files)
    config = MyConfigParser(files['settings'])

    if "DBNAME" not in config.keys():
        config['DBNAME'] = config['CUSTOMS']
        config.write()
    if "ODOO_VERSION" not in config or config['ODOO_VERSION'] != ODOO_VERSION:
        config['ODOO_VERSION'] = ODOO_VERSION
        config.write()

    # store the host root folder
    config['HOST_ODOO_HOME'] = E("ODOO_HOME")
    _file2env(files['settings'])

def _file2env(filepath):
    if not os.path.exists(filepath):
        return
    config = MyConfigParser(filepath)
    for k in config.keys():
        os.environ[k] = config[k]

def _get_bash_for_machine(machine):
    if machine == 'postgres':
        return 'bash'
    else:
        return 'bash'

def _get_platform():
    if os.getenv("PLATFORM", "") in ['Darwin', 'OSX', 'macos']:
        return PLATFORM_OSX
    else:
        return PLATFORM_LINUX

def _make_settings_file(outfile, setting_files):
    """
    Puts all settings into one settings file
    """
    c = MyConfigParser(outfile)
    for file in setting_files:
        if not file:
            continue
        c2 = MyConfigParser(file)

        for key in c2.keys():
            value = c2[key]
            if '~' in value:
                value = value.replace('~', os.environ['HOST_HOME'])
                c2[key] = value

        c.apply(c2)
    if _get_platform() == PLATFORM_OSX:
        c['RUN_RSYNCED'] = '1'
    c.write()

def _prepare_docker_compose_files(dest_file, paths):
    local_odoo_home = os.environ['LOCAL_ODOO_HOME']

    temp_files = set()
    tempdir = tempfile.mkdtemp()

    if not dest_file:
        raise Exception('require destination path')

    with open(dest_file, 'w') as f:
        f.write("#Composed {}\n".format(datetime.now().strftime("%Y-%m-%d %H:%M:%S")))
        f.write("version: '{}'\n".format(os.environ['ODOO_COMPOSE_VERSION']))

    def replace_all_envs_in_file(filepath):
        with open(filepath, 'r') as f:
            content = f.read()
        all_params = re.findall(r'\$\{[^\}]*?\}', content)
        for param in all_params:
            name = param
            name = name.replace("${", "")
            name = name.replace("}", "")
            if name in os.environ:
                content = content.replace(param, os.environ[name])
        with open(filepath, 'w') as f:
            f.write(content)

    for path in set(paths):
        filename = os.path.basename(path)

        def use_file():
            if 'run_' in filename:
                run = re.findall(r'run_[^\.]*', filename)
                if run:
                    if os.getenv(run[0].upper(), "1") == "1":
                        return True
                return False
            else:
                return True

        if not use_file():
            continue

        with open(path, 'r') as f:
            content = f.read()
            # dont matter if written manage-order: or manage-order
            if 'manage-order' not in content:
                order = '99999999'
            else:
                order = content.split("manage-order")[1].split("\n")[0].replace(":", "").strip()
        folder_name = os.path.basename(os.path.dirname(path))
        if os.getenv("RUN_{}".format(folder_name.upper()), "1") == "0":
            continue

        order = str(order)

        # put all files in their order into the temp directory
        counter = 0
        temp_path = ""
        while not temp_path or os.path.exists(temp_path):
            counter += 1
            temp_path = os.path.join(tempdir, '{}-{}'.format(order, str(counter).zfill(5)))

        # add static yaml content to each machine
        with open(files['config/default_network'], 'r') as f:
            default_network = yaml.load(f.read())

        with open(temp_path, 'w') as dest:
            with open(path, 'r') as source:
                j = yaml.load(source.read())
                # TODO complain version - override version
                j['version'] = YAML_VERSION

                # set settings environment and the override settings after that
                for file in ['run/settings']:
                    path = os.path.join(local_odoo_home, file)
                    if os.path.exists(path):
                        if 'services' in j:
                            for service in j['services']:
                                service = j['services'][service]
                                if 'env_file' not in service:
                                    service['env_file'] = []
                                if isinstance(service['env_file'], (str, unicode)):
                                    service['env_file'] = [service['env_file']]

                                if not [x for x in service['env_file'] if x == '$ODOO_HOME/{}'.format(file)]:
                                    service['env_file'].append('$ODOO_HOME/{}'.format(file))
                    j['networks'] = copy.deepcopy(default_network['networks'])

                dest.write(yaml.dump(j, default_flow_style=False))
                dest.write("\n")
        replace_all_envs_in_file(temp_path)
        temp_files.add(os.path.basename(temp_path))
        del temp_path

    def post_process_complete_yaml_config(yml):
        """
        This is after calling docker-compose config, which returns the
        complete configuration.

        Aim is to take the volumes defined in odoo_base and append them
        to all odoo containers.
        """

        with open(os.path.join(local_odoo_home, 'machines/odoo/docker-compose.yml')) as f:
            odoodc = yaml.load(f.read())

        for odoomachine in odoodc['services']:
            if odoomachine == 'odoo_base':
                continue
            machine = yml['services'][odoomachine]
            for k in ['volumes']:
                machine[k] = []
                for x in yml['services']['odoo_base'][k]:
                    machine[k].append(x)
            for k in ['environment']:
                machine.setdefault(k, {})
                for x, v in yml['services']['odoo_base'][k].items():
                    machine[k][x] = v
        yml['services'].pop('odoo_base')

        return yml

    # call docker compose config to get the complete config
    _files = sorted(temp_files, key=lambda x: float(x.split("/")[-1].replace("-", ".")))
    cmdline = __get_docker_compose_run_command()
    cmdline.append("/usr/local/bin/docker-compose")
    for file in _files:
        cmdline.append('-f')
        cmdline.append(os.path.join(os.path.basename(tempdir), file))
    cmdline.append('config')

    # annotation: per symlink all subfiles/folders are linked to a path,
    # that matches the host system path
    shutil.move(tempdir, local_odoo_home)
    tempdir = os.path.join(local_odoo_home, os.path.basename(tempdir))

    try:
        conf = __system(cmdline, cwd=local_odoo_home, suppress_out=True)
    except Exception:
        raise
    else:
        # post-process config config
        conf = post_process_complete_yaml_config(yaml.load(conf))
        conf = yaml.dump(conf, default_flow_style=False)

        with open(dest_file, 'w') as f:
            f.write(conf)
    finally:
        __rmtree(tempdir)

def _prepare_yml_files_from_template_files():
    # replace params in configuration file
    # replace variables in docker-compose;

    if E("ODOO_MANAGER_STARTED_ONCE") != "1":
        for name in ['CUSTOMS', 'DB', 'ODOO_VERSION', 'ODOO_FILES']:
            print("{}: {}".format(name, E(name)))

    # python: find all configuration files from machines folder; extract sort
    # by manage-sort flag and put file into run directory
    # only if RUN_parentpath like RUN_ODOO is <> 0 include the machine
    #
    # - also replace all environment variables
    def find_files(dir):
        for filepath in __find_files(
                dir,
                '-regex',
                '.*\/docker-compose.*.yml'
        ):
            yield filepath
    _files = []
    _files += find_files(dirs['machines'])
    _files += find_files(odoo_config.customs_dir())
    _prepare_docker_compose_files(files['docker_compose'], _files)

def _remember_customs_and_cry_if_changed():
    # if customs changed, then restart is required

    out = __dcexec(['odoo env'])
    out = [x for x in out.split('\n') if "CUSTOMS="]
    if out:
        current_customs = out[0].split("=")[-1]
        if current_customs != os.environ['CUSTOMS']:
            print("Customs changed - you need to restart and/or rebuild!")
            kill()

def _remove_temp_directories():
    for dir in os.listdir(dirs['odoo_home']):
        if dir.startswith("tmp") and len(dir) == len('tmp......'):
            __rmtree(os.path.join(dirs['odoo_home'], dir))

def _reset_proxy_configs():
    __empty_dir(dirs['run/proxy'])

def _prepare_filesystem():
    __makedirs(dirs['settings.d'])
    for subdir in ['config', 'sqlscripts', 'debug', 'proxy']:
        __makedirs(os.path.join(dirs['odoo_home'], 'run', 'subdir'))
    __system(['sudo', '-E', 'chown', "{uid}:{uid}".format(uid=E("UID")), "-R", dirs['run']])

    __file_default_content(files['odoo_instances'], "default default\n")

def _sanity_check():
    if not E("RUN_POSTGRES"):
        raise Exception("Please define RUN_POSTGRES")

    if E("RUN_POSTGRES") == "1" and E("DB_HOST") != "postgres":
        print("You are using the docker postgres container, but you do not have the DB_HOST set to use it.")
        print("Either configure DB_HOST to point to the docker container or turn it off by: ")
        print("RUN_POSTGRES=0")
        sys.exit(1)

    if E("OWNER_UID") == "0":
        print("Advise: you should set OWNER_UID so that dump files are marked as the correct owner")
        time.sleep(3)

    if E("ODOO_FILES") and os.path.isdir(E("ODOO_FILES")):
        # checking directory permissions of session files and filestorage
        __try_to_set_owner(E("OWNER_UID"), E("$ODOO_FILES"))

    # make sure the odoo_debug.txt exists; otherwise directory is created
    __file_default_content(files['run/odoo_debug.txt'], "")

    if not E("ODOO_MODULE_UPDATE_RUN_TESTS"):
        print("Please define wether to run tests on module updates by setting ODOO_MODULE_UPDATE_RUN_TESTS")
        time.sleep(2)


def _setupArgs():
    parser = argh.ArghParser()
    commands = []
    module = sys.modules[__name__]
    for member in getmembers(module, inspect.isfunction):
        name, member = member
        if isinstance(member, types.FunctionType):
            if not name.startswith('_') and (len(name) > 2 or name in ['up']):
                commands.append(member)

    parser.add_commands(commands)

    return parser

def _setup_odoo_instances():
    def __add_location_files(config_path, dir):
        lines = []
        for subdir in os.listdir(dir):
            if os.path.isdir(os.path.join(dir, subdir)):
                for file in os.listdir(os.path.join(dir, subdir)):
                    lines.append("\tInclude " + os.path.join("/etc/proxy", os.path.basename(subdir), file))
        __replace_in_file(config_path, "__INCLUDES__", '\n'.join(lines))

    if os.path.exists(files['odoo_instances']):

        if os.path.exists(files['odoo_instances']):
            for line in __file_get_lines(files['odoo_instances']):
                name, domain = line.strip().split(" ")
                config_path = os.path.join(dirs['proxy_configs_dir'], "{}.host".format(name))
                shutil.copy(files['machines/proxy/instance.conf'], config_path)

                if domain == "default":
                    __replace_in_file(config_path, "__DOMAIN__", '*')
                else:
                    if domain:
                        __replace_in_file(config_path, "__DOMAIN__", domain)
                if name != "default":
                    # adapt the one yml file and duplicate the odoo service there;
                    # removing any ports
                    with open(files['docker_compose_file']) as f:
                        j = yaml.load(f.read())
                    odoo = copy.deepcopy(j['services']['odoo'])
                    if 'ports' in odoo:
                        del odoo['ports']
                    odoo['container_name'] = '_'.join([os.environ['CUSTOMS'], "odoo", name])
                    j['services']['odoo_{}'.format(name)] = odoo
                    with open(files['docker_compose_file'], 'w') as f:
                        f.write(yaml.dump(j, default_flow_style=False))

    for file in os.listdir(dirs['run/proxy']):
        if not file.endswith('.host'):
            continue
        config_path = os.path.join(dirs['run/proxy'], file)
        __add_location_files(config_path, dirs['run/proxy'])


def _setup_proxy():
    CONFIG_DIR = dirs['run/proxy']
    __empty_dir(dirs['proxy_configs_dir'])

    sys.path.append(dirs['machines/proxy'])
    importlib.import_module("add_upstream")
    from add_upstream import add_upstream as f_add_upstream

    def get_rules():
        for root, _, _filenames in os.walk(dirs['machines']):
            for filename in _filenames:
                if filename == 'upstream.path':
                    filepath = os.path.join(root, filename)
                    machine = None
                    p = filepath
                    while os.path.basename(p) != "machines":
                        machine = os.path.basename(p)
                        p = os.path.dirname(p)
                    del p

                    try:
                        version = float(os.path.basename(os.path.dirname(filepath)))
                    except Exception:
                        version = None
                    else:
                        if str(version) != str(odoo_config.get_version_from_customs(os.environ['CUSTOMS'])):
                            continue
                    with open(filepath, 'r') as f:
                        content = f.readlines()
                        for line in content:
                            LOCATION, UPSTREAM = line.strip().split(" ")
                            if not LOCATION or not UPSTREAM:
                                raise Exception("Invalid rule: {}".format(line))
                            yield filepath, LOCATION, UPSTREAM, machine

    for filepath, LOCATION, UPSTREAM, machine in get_rules():
        __makedirs(os.path.join(CONFIG_DIR, machine))
        location_friendly_name = LOCATION.replace("/", "_")
        filename = "{}.location".format(location_friendly_name)
        CONFIG_PATH = os.path.join(CONFIG_DIR, machine, filename)
        UPSTREAM_INSTANCE = UPSTREAM.replace("default", "odoo")
        f_add_upstream(LOCATION, UPSTREAM_INSTANCE, CONFIG_PATH)

def __start_postgres_and_wait():
    if E("RUN_POSTGRES") == "1":
        __dc(["up", "-d", "postgres"])
        __wait_for_port(E("DB_HOST"), long(E("DB_PORT")), timeout=30)
        __execute_sql("""
        SELECT table_schema,table_name
        FROM information_schema.tables
        ORDER BY table_schema,table_name;
        """, dbname='template1')

def _startup():
    if os.path.isfile(files['settings']):
        _file2env(files['settings'])
    dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))) # script directory
    dir = os.path.dirname(dir)
    dirs['odoo_home'] = dir

    def make_absolute(d):
        for k, v in d.items():
            if not v.startswith('/'):
                d[k] = os.path.join(dir, v)
    make_absolute(dirs)
    dirs['customs'] = odoo_config.customs_dir()
    make_absolute(files)
    os.environ['ODOO_MANAGER_STARTED_ONCE'] = '1'
    os.environ['ODOO_COMPOSE_VERSION'] = "3.3"
    os.environ['PGPASSFILE'] = "/tmp/.pgpass" # must match the executing script
    os.environ['PGHOST'] = os.path.expandvars("$DB_HOST")
    os.environ['PGPORT'] = os.path.expandvars("$DB_PORT")
    os.environ['PGUSER'] = os.path.expandvars("$DB_USER")
    os.environ['LOCAL_WORKING_DIR'] = "{}/{}".format(os.getenv("EXTERNAL_ROOT"), os.getenv("WORKING_DIR"))  # the working directory accessible from container of this script.
    dirs['host_working_dir'] = os.environ['LOCAL_WORKING_DIR']
    commands['dc'] = [x.replace("$docker_compose_file", files['docker_compose']) for x in commands['dc']]

def abort_upgrade():
    SQL = """
        UPDATE ir_module_module SET state = 'installed' WHERE state = 'to upgrade';
        UPDATE ir_module_module SET state = 'uninstalled' WHERE state = 'to install';
    """
    __execute_sql(SQL)

def E(name):
    if name.startswith("$"):
        name = name[1:]
    return os.getenv(name, "")

def attach(machine):
    """
    attaches to running machine
    """
    _display_machine_tips(machine)
    bash = _get_bash_for_machine(machine)
    cmd = __get_cmd() + ['exec', machine, bash]

    proc = subprocess.Popen(cmd)
    proc.wait()

def backup(filename=None):
    """"
    Runs backup-db and backup-files
    """
    t1 = Thread(target=backup_db, args=(filename,))
    t2 = Thread(target=backup_files)
    t1.start()
    t2.start()
    t1.join()
    t2.join()

def backup_calendar(filename=None):
    if E("RUN_CALENDAR") != "1":
        return
    filename = filename or datetime.now().strftime("{}.calendar.%Y%m%d%H%M%S.dump.gz".format(E("CUSTOMS")))
    filepath = os.path.join(BACKUPDIR, filename)
    __backup_postgres(
        filepath,
        dbname=E("CALENDAR_DB_NAME"),
        host=E("CALENDAR_DB_HOST"),
        port=E("CALENDAR_DB_PORT"),
        user=E("CALENDAR_DB_USER"),
        password=E("CALENDAR_DB_PWD"),
    )


def __backup_postgres(filepath, dbname, host, port, user, password):
    os.environ['PGPASSWORD'] = password
    conn = psycopg2.connect(dbname=dbname, host=host, port=long(port), user=user, password=password)
    cr = conn.cursor()
    cr.execute("SELECT (pg_database_size(current_database())) FROM pg_database")
    size = cr.fetchone()[0] * 0.7 # ct
    bytes = str(float(size)).split(".")[0]
    conn.close()
    os.system('pg_dump -h "{host}" -p {port} -U "{user}" -Z0 -Fc {dbname} | pv -s {bytes} | pigz --rsyncable > {filepath}'.format(**locals()))

def backup_db(filename=None):
    filename = filename or datetime.now().strftime("{}.odoo.%Y%m%d%H%M%S.dump.gz".format(E("CUSTOMS")))

    if filename.startswith("/"):
        raise Exception("No slash for backup filename allowed")
    print "Databasename is " + E("DBNAME")
    filepath = os.path.join(BACKUPDIR, filename)
    if os.path.exists(filepath):
        os.unlink(filepath)
    LINKPATH = os.path.join(BACKUPDIR, 'latest_dump')
    __start_postgres_and_wait()

    __backup_postgres(filepath, E("DBNAME"), E("DB_HOST"), E("DB_PORT"), E("DB_USER"), E("DB_PWD"))

    if E("NO_BACKUP_SYMBOLIC_LINK_DUMP") != "1":
        if os.path.islink(LINKPATH) or os.path.exists(LINKPATH):
            os.unlink(LINKPATH)
        __system([
            'ln',
            '-s',
            os.path.basename(filepath),
            os.path.basename(LINKPATH)
        ], cwd=os.path.dirname(filepath))
    print "Dumped to ", filepath
    telegram_send("Database Backup $DBNAME done to $filepath")

def backup_files():
    BACKUP_FILENAME = "{CUSTOMS}.files.tar.gz".format(CUSTOMS=E("CUSTOMS"))

    if os.path.exists(BACKUP_FILENAME):
        second = BACKUP_FILENAME + ".bak"
        if os.path.exists(second):
            os.unlink(second)
        shutil.move(BACKUP_FILENAME, second)
    __dcrun(["odoo", "/backup_files.sh", BACKUP_FILENAME])
    print "Backup files done to {}".format(BACKUP_FILENAME)

def build(pull=False, machines='', nocache=False):
    """
    no parameter all machines, first parameter machine name and passes other params; e.g. ./odoo build asterisk --no-cache"
    """
    options = []
    if pull:
        options += ['--pull']
    if nocache:
        options += ['--no-cache']

    __dc(['build'] + options + __splitcomma(machines))

def commit(*parameters):
    versioning.actions["commit"](*parameters)

def compose(customs):
    """
    - builds docker compose
    - builds proxy settings
    - setups odoo instances
    """
    if customs:
        config = MyConfigParser(files['settings'])
        if config['CUSTOMS'] != customs:
            config.clear()
            config['CUSTOMS'] = customs
            config.write()
    _export_settings()
    _remove_temp_directories()
    _prepare_filesystem()
    _prepare_yml_files_from_template_files()
    _reset_proxy_configs()
    _setup_proxy()
    _setup_odoo_instances()
    print "Built the docker-compose file."

def current_ticket():
    versioning.actions["current-ticket"]()

def debug(machine_name):
    """
    starts /bin/bash for just that machine and connects to it; if machine is down, it is powered up; if it is up, it is restarted; as command an endless bash loop is set"
    """

    # puts endless loop into container command and then attaches to it;
    # by this, name resolution to the container still works
    __set_db_ownership()
    _askcontinue("Current machine {} is dropped and restartet with service ports in bash. Usually you have to type /debug.sh then.".format(machine_name))
    # shutdown current machine and start via run and port-mappings the replacement machine
    kill(machine_name)
    rm(machine_name)
    shutil.copy(files['debugging_template'], files['debugging_composer'])
    __replace_in_file(files['debugging_composer'], "${CUSTOMS}", E("CUSTOMS"))
    __replace_in_file(files['debugging_composer'], "${NAME}", machine_name)

    # TODO make configurable in machines
    PORT = str({
        'odoo': 8072,
        'odoo_debug': 8072
    }.get(machine_name, 80))
    __replace_in_file(files['debugging_composer'], "{machine_main_port}", PORT)
    commands['dc'] += ['-f', files['debugging_composer']]

    __dc(['up', '-d', machine_name])
    attach(machine_name)

def deploy():
    versioning.action_deploy_ticket()

def dev(customs):
    """
    starts developing in the odoo container
    """
    if E("CUSTOMS") != customs:
        kill()
        rm()
        compose(customs)
        build()
    up(daemonized=True)
    attach('odoo')

def dirty():
    versioning.dirty()

def do_command(cmd, *params, **kwparams):
    cmd = cmd.replace('-', '_')
    return globals()[cmd](*params, **kwparams)

def execute(*parameters):
    __dcexec(*parameters)

def export_i18n(lang, modules):
    __dcrun(['odoo', '/export_i18n.sh', lang, modules])
    # file now is in $DIR/run/i18n/export.po

def fix_permissions():
    if E("ODOO_FILES") and os.path.isdir(E("ODOO_FILES")) and E("OWNER_UID") and E("OWNER_UID") != "0":
        __try_to_set_owner(E("OWNER_UID", E("ODOO_FILES"), recursive=True))
    customs_dir = odoo_config.customs_dir()
    __try_to_set_owner("1000", customs_dir, recursive=True) # so odoo user has access

def force_kill(machine):
    kill(machine, brutal=True)

def get_all_langs():
    langs = [x[0] for x in __execute_sql(
        "select code from res_lang;",
        fetchall=True
    )]
    for lang in langs:
        print(lang)
    return langs

def get_dump_type(filename):
    dump_file = os.path.join(BACKUPDIR, filename)
    dump_type = __get_dump_type(dump_file)
    print dump_type

def kill(machines="", brutal=False):
    """
    kills running machine
    safely shutdowns postgres and redis

    if not brutal it means softly
    """
    machines = __splitcomma(machines)
    if not brutal:
        safe_stop = []
        for machine in SAFE_KILL:
            if not machines or machine in machines:
                if __is_container_running(machine):
                    safe_stop += [machine]

        if safe_stop:
            __dc(["stop", "-t 20"] + safe_stop)  # persist data

    __dc(['stop', '-t 2'] + list(machines))

def image_import(image_filename):
    dump_path = os.path.join(BACKUPDIR, os.path.basename(image_filename))
    __system([
        "docker",
        "load",
        dump_path
    ])

def image_export():
    """
    Exports all images of the customizations to one file.
    Can be imported via image-import.
    """
    dump_path = os.path.join(BACKUPDIR, E("CUSTOMS") + '.docker.images.tar')
    folder = tempfile.mkdtemp()
    image_ids = __dc([
        'images',
        '-q',
    ], suppress_out=True).split("\n")
    filesize = 0
    for image in image_ids:
        if not image:
            continue
        filepath = os.path.join(folder, image)
        print "Storing {} to {}".format(image, filepath)
        __system([
            'docker',
            'save',
            image,
            '-o',
            filepath,
        ], suppress_out=True)
        filesize += os.stat(filepath).st_size
        print "File size currently:", humanize.naturalsize(filesize)
    if not filesize:
        raise Exception("No images found!")
    __system([
        "tar",
        "cfz",
        dump_path,
        '.',
    ], cwd=folder)
    print os.path.basename(dump_path)
    compressed_size = os.stat(dump_path).st_size
    ratio = round(float(compressed_size) / float(filesize) * 100.0, 1)
    print "Compressed:", humanize.naturalsize(compressed_size), "Uncompress:", humanize.naturalsize(filesize), "Ratio:", ratio

def incversions():
    versioning.actions["incversions"]()

def link():
    """
    links all modules into ./links
    """
    os.system("python " + os.path.join(dirs['admin'], 'link_modules'))

def logsn(lines, machine):
    """
    logoutput of machine; use parameter for machine
    """
    __dc(['logs', '--tail=' + lines, '-f', '-t'] + machine)

def logs(machine=None, lines=None):
    lines = 0
    if lines:
        print "Showing last {}lines".format(lines)

    cmd = ['logs', '-f', '-t']
    if lines:
        cmd += ['--tail={}'.format(lines)]
    if machine:
        cmd += [machine]
    __dc(cmd)

def logall(*machines):
    __dc(['logs', '-f', '-t'] + list(machines))

def import_i18n(lang, po_file_path):
    __dcrun(['odoo', '/import_i18n.sh', lang, po_file_path])

def make_customs(customs, version):
    _askcontinue()
    admin_dir = dirs['admin']
    kill()
    __system([
        files['make_customs'],
        customs,
        version
    ])
    os.environ['CUSTOMS'] = customs
    cwd = os.path.join(dirs['odoo_home'], 'customs', customs)
    __system([
        files['make_customs'],
        "git",
        "submodule",
        "add",
        "https://github.com/odoo/odoo odoo"
    ], cwd=cwd)
    odoo_dir = os.path.join(cwd, 'odoo')
    __system([
        'git', 'checkout', str(version)
    ], cwd=odoo_dir)
    __system([
        'git', 'checkout', str(version)
    ], cwd=admin_dir)
    __system([
        "OCA-all"
    ], cwd=admin_dir)
    __system([
        "odoo-submodule",
        'tools,web_modulesroduct_modules,calendar_ics',
    ], cwd=admin_dir)
    kill()
    compose(customs)
    up()

def OCA(module):
    __system([
        files['OCA'],
        module,
    ], cwd=dirs['admin'])

def migrate(from_version, to_version):
    LOGFILE = os.path.join(odoo_config.customs_dir(), "migration.log")
    fix_permissions()
    do_migrate(
        E("CUSTOMS"),
        LOGFILE,
        from_version,
        to_version,
        do_command,
        SETTINGS_D_FILE=os.path.join(dirs['settings.d'], 'migration'),
    )

def new_ticket(ticket_name):
    versioning.actions['new-ticket'](*[ticket_name])

def open_tickets(command_options):
    versioning.actions["open-tickets"]()

def patch(*parameters):
    customs_dir = dirs['customs']
    odoo_dir = os.path.join(customs_dir, 'odoo')
    __assert_file_exists(odoo_dir, isdir=True)
    __system([
        'admin/odoo-patch'
    ] + list(parameters), cwd=dirs['odoo_home'], raise_exception=bool(parameters))  # otherwise show help

def prepare():
    print "All configurations prepared."

def progress():
    for row in __execute_sql("select state, count(*) from ir_module_module group by state;", fetchall=True):
        print "{}: {}".format(row[0], row[1])

def proxy_reload():
    if __is_container_running('proxy'):
        __dcexec(['proxy', '/opt/bin/hot_reload.sh'])

def pull(submodule):
    __assert_file_exists(os.path.join(dirs['customs'], '.git'))
    __system([
        'git',
        'subtree',
        'pull',
        '--message',
        'SUBTREE-PULL {}'.format(submodule),
        '--prefix',
        'common/{}'.format(submodule),
        '--squash',
        'git.mt-software.de:/git/openerp/modules/{}'.format(submodule),
        'master'
    ], cwd=dirs['customs'])

def pull_all():
    __assert_file_exists(os.path.join(dirs['customs'], '.git'))
    out = __system([
        'git',
        'log',
    ], cwd=dirs['customs'], suppress_out=True).split('\n')
    out = filter(lambda line: 'git-subtree-dir:' in line, out)
    out = map(lambda line: line.strip().split(": ")[1].strip(), out)
    for tree in out:
        if tree.startswith('common/'):
            tree # = tree[len('common/'):]
            __system([
                'git',
                'subtree',
                'pull',
                '-message SUBTREE-PULL {}'.format(tree),
                '--prefix={}'.format(tree),
                '--squash',
                'git.mt-software.de:/git/openerp/modules/{}'.format(os.path.basename(tree)),
                'master',
            ], cwd=dirs['customs'])

def push(submodule_name):
    __assert_file_exists(os.path.join(dirs['customs'], '.git'))

    __system([
        'git',
        'subtree',
        'push',
        '--prefix=common/{}'.format(submodule_name),
        'git.mt-software.de:/git/odoo/modules/{}'.format(submodule_name),
        'master'
    ], cwd=dirs['customs'])

def rebuild(machines=""):
    compose(E("CUSTOMS"))
    build(machines=machines, nocache=True)

def remove_web_assets():
    """
    if odoo-web interface is broken (css, js) then purging the web-assets helps;
    they are usually recreated when admin login
    """
    _askcontinue()
    from module_tools.module_tools import remove_webassets
    remove_webassets()
    if float(E("ODOO_VERSION")) <= 10.0:
        print("Please login as admin, so that assets are recreated.")

def reset_db():
    _askcontinue("Delete database {}".format(E("DBNAME")))
    if E("RUN_POSTGRES") != "1":
        print "Postgres container is disabled; cannot reset external database"
        return
    print "Stopping all services and creating new database"
    print "After creation the database container is stopped. You have to start the system up then."
    kill()
    __reset_postgres_container()
    print "Database initialized."

def restart(machines=""):
    kill(machines)
    rm(machines)
    __dc(['up', '-d', '--force-recreate'] + __splitcomma(machines))
    proxy_reload()

def rm(machines=''):
    __dc(['rm', '-f'] + __splitcomma(machines))

def restore_dev_db(filename):
    if E("ALLOW_RESTORE_DEV") != "1" and not FORCE:
        raise Exception("ALLOW_RESTORE_DEV must be explicitly allowed.")

    print("Restores dump to {DB_HOST} and executes to scripts to adapt user passwords, mailservers and cronjobs".format(
        DB_HOST=E("DB_HOST"),
    ))

    def exec_sql(dbname):
        __turn_into_devdb(dbname)

    restore_db(
        filename,
        exec_before_rename=exec_sql,
        restore_as_dev_db=True
    )

def restore_files(dumpfile):
    __do_restore_files(dumpfile)

def restore_db(dumpfile, exec_before_rename=None, restore_as_dev_db=False):
    for x in ["DB_HOST", "DB_PORT"]:
        print("{}: {}".format(x, E(x)))
    dumpfile == os.path.join(BACKUPDIR, dumpfile)
    if dumpfile.startswith("/"):
        raise Exception("No path in dump file allowed")
    __restore_check(dumpfile)
    if E("DEVMODE") == "1" and not restore_as_dev_db:
        _askcontinue("DEVMODE ist set - really restore as normal db? Not using restore-dev-db?")

    if not FORCE:
        _askcontinue("Deletes database {}!".format(E("DBNAME")))

    DBNAME_RESTORING = E("DBNAME") + "_restoring"
    os.environ['DBNAME'] = DBNAME_RESTORING

    config = MyConfigParser(files['settings'])
    dbname = config['DBNAME']

    reset_db()
    __do_restore_db_on_postgres(dumpfile, DBNAME_RESTORING, E("DB_HOST"), E("DB_PORT"), E("DB_USER"), E("DB_PWD"))
    if exec_before_rename:
        exec_before_rename(DBNAME_RESTORING)
    __rename_db_drop_target(DBNAME_RESTORING, dbname)
    __remove_postgres_connections(dbname)
    __set_db_ownership()
    telegram_send("Database Restore $DBNAME done.")

def rmpyc():
    for root, _, _files in os.walk(dirs['customs']):
        for filename in _files:
            if filename.endswith(".pyc"):
                os.unlink(os.path.join(root, filename))

def run(machine, *params, **kwparams):
    __set_db_ownership()
    params = list(params)
    if params and params[0] == 'bash' and len(params) == 1:
        runbash(machine)
        return
    __dcrun([machine] + params, **kwparams)

def runbash(machine):
    __set_db_ownership()
    _display_machine_tips(machine)
    bash = _get_bash_for_machine(machine)
    cmd = __get_cmd() + ['run', machine, bash]
    proc = subprocess.Popen(cmd)
    proc.wait()

def sanity_check():
    _sanity_check()

def set_db(DBNAME):
    set_settings(DBNAME)

def set_settings(key, value):
    config = MyConfigParser(files['settings'])
    config[key.upper()] = value
    config.write()

def set_db_ownership():
    __set_db_ownership()
    _export_settings()

def setup_startup():
    if os.path.exists("/sbin_host/initctl"):
        raise Exception("Not impl")
    else:
        print "Setting up systemd script for startup"
        servicename = os.path.expandvars("${CUSTOMS}_odoo.service")
        file = os.path.join("/tmp_host, servicename")

        # echo "Setting up upstart script in $file"
        shutil.copy(os.path.join(dirs['odoo_home'], 'config', 'systemd'), file)
        __replace_in_file(file, "${CUSTOMS}", E("CUSTOMS"))
        __replace_in_file(file, "${PATH}", E("HOST_ODOO_HOME"))

        print("Please execute on host now (perhaps as sudo):")
        print("""cp /tmp/{servicename} /etc/systemd/system")
        systemctl stop {servicename}
        systemctl disable {servicename}
        systemctl daemon-reload
        systemctl reset-failed
        systemctl enable {servicename}
        systemctl start {servicename}
        """.format(servicename=servicename)
              )

def shell():
    cmd = __get_cmd() + ['run', 'odoo', '/bin/bash', '/shell.sh']
    proc = subprocess.Popen(cmd)
    proc.wait()

def show_install_state():
    rows = __execute_sql(
        "SELECT name, state from ir_module_module where state not in ('installed', 'uninstalled');",
        fetchall=True
    )
    print("Displaying dangling modules:")
    for row in rows:
        print("{}: {}".format(row[0], row[1]))

    if len(rows):
        raise Exception("Dangling modules detected - please fix installation problems and retry!")

def simplebash(*parameters):
    if not parameters:
        os.system("bash --noprofile")
    else:
        os.system("bash --noprofile -c {}".format(" ".join(parameters)))

def springclean():
    os.system("docker system prune")
    print("removing dead containers")
    os.system('docker ps -a -q | while read -r id; do docker rm "$id"; done')

    print("Remove untagged images")
    os.system('docker images | grep "<none>" | awk \'{ print "docker rmi " $3 }\' | bash')

    print("delete unwanted volumes (can pass -dry-run)")
    os.system('docker images -q -f="dangling=true" | while read -r id; do docker rmi "$id"; done')

def stage():
    versioning.action_stage_ticket()

def status():
    __print_env(["CUSTOMS", "DBNAME", "DB_HOST"])
    os.system("df -h")

def stop(machines):
    kill(machines)

def submodule(*submodules):
    __assert_file_exists(os.path.join(dirs['customs'], '.git'))
    __assert_file_exists(os.path.join(dirs['customs'], 'common'))

    for submodule in submodules:
        __system([
            'git',
            'subtree',
            'add',
            '--prefix=common/{}'.format(submodule),
            '--squash',
            'git.mt-software.de:/git/openerp/modules/{}'.format(submodule),
            'master',
        ], cwd=dirs['customs'])

def subtree_odoo():
    __assert_file_exists(os.path.join(dirs['customs'], '.version'))

    if os.path.isdir(os.path.join(dirs['customs'], 'odoo')):
        raise Exception("Odoo already exists")

    version = __read_file(os.path.join(dirs['customs'], '.version')).strip()

    __system([
        'git',
        'status',
    ], cwd=dirs['customs'])
    __system([
        'git',
        'subtree',
        'add',
        '--prefix=odoo',
        '--squash',
        'https://github.com/odoo/odoo',
        version,
    ], cwd=dirs['customs'])

def switch_ticket(ticket):
    versioning.actions["switch-ticket"](*[ticket])

def telegram_setup():
    """
    helps creating a permanent chatid
    """
    if E("TELEGRAM_ENABLED") == "1":
        os.system("""
cd "{dir}"
docker-compose run -it telegrambat /setup.sh
""".format(dir=dirs['telegrambot']))

def telegram_send(message):
    if E("TELEGRAM_ENABLED") == "1":
        os.system("""
            cd "{dir}"
            docker-compose run telegrambat /send.py "{message}"
        """.format(
            dir=dirs['telegrambot'],
            message=message,
        ))

def test():
    print 'reached the command area'
    print os.path.expandvars("CUSTOMS is: $CUSTOMS")
    print os.path.expandvars("Here is pgpassfile: $PGPASSFILE")
    print "Now calling simple psql"
    __execute_sql("select state, count(*) from ir_module_module group by state;")

def test_make_error():
    print("now throwing exit code")
    sys.exit(123)

def turn_into_dev():
    if E("DEVMODE") != "1":
        raise Exception("""When applying this sql scripts, the database is not usable anymore for production environments.
Please set DEVMODE=1 to allow this""")
    __turn_into_devdb(E("DBNAME"))

def update_ast():
    if _get_platform() == PLATFORM_OSX:
        print "Update is extreme slow on osx due to share performance. Please use following command natively:"
        print
        print
        print 'time PYTHONPATH=$ODOO_HOME/admin/module_tools python -c "from odoo_parser import update_cache; update_cache()"'
        print
        print
        sys.exit(2)
    started = datetime.now()
    print "Updating ast - can take about one minute; slow on OSX due to share"
    update_cache()
    print "Updated ast - took {} seconds".format((datetime.now() - started).seconds)

def up(machines='', daemonized=False):
    __set_db_ownership()
    options = [
    ]
    if daemonized:
        options += ['-d']
    __dc(['up'] + options + __splitcomma(machines))
    proxy_reload()

def update(module=""):
    """
    Just custom modules are updated, never the base modules (e.g. prohibits adding old stock-locations)
    Minimal downtime - but there is a downtime, even for phones
    """
    abort_upgrade()
    print("Run module update")
    if E("ODOO_UPDATE_START_NOTIFICATION_TOUCH_FILE_IN_CONTAINER") == "1":
        with open(E("ODOO_UPDATE_START_NOTIFICATION_TOUCH_FILE_IN_CONTAINER"), 'w') as f:
            f.write(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

    # running duplicate updates is really a problem;
    kill()
    __dc(['rm', '-f'])
    __dc(['create', '--force-recreate'])
    __start_postgres_and_wait()
    kill('proxy')

    try:
        __dcrun(['odoo_update', '/update_modules.py', module])
    except Exception:
        raise Exception("Error at /update_modules.py - aborting update process.")
    show_install_state()

    for i in range(5):
        __dc(['up', '-d'])
        proxy_reload()
        time.sleep(2)

    os.system('df -h /') # case: after update disk / was full
    if E("ODOO_UPDATE_START_NOTIFICATION_TOUCH_FILE_IN_CONTAINER") == "1":
        with open(E("ODOO_UPDATE_START_NOTIFICATION_TOUCH_FILE_IN_CONTAINER"), 'w') as f:
            f.write("0")
    telegram_send("Update done")

def wait_for_container_postgres():
    __start_postgres_and_wait()

def wait_for_port(host, port):
    port = long(port)
    __wait_for_port(host=host, port=port)

# @arg('beta', default='hello world', nargs='*', help='The message')
def psql(dbname=None, *params):
    if not dbname:
        dbname = E("DBNAME")
    params = " ".join(params)
    os.system("psql {} ".format(dbname) + params)


if __name__ == '__main__':
    parser = _setupArgs()
    _startup()
    _check_working_dir_customs_mismatch
    if args:
        if args[0] == 'tool':
            sys.exit(0)

    _remember_customs_and_cry_if_changed

    try:
        parser.dispatch()
    finally:
        _cleanup()
