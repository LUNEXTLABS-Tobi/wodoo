#!/usr/bin/python
import click
from datetime import datetime
import pickle
import base64
import copy
import inquirer
import pipes
import types
import sys
import re
import signal
import os
import logging
import importlib
import humanize
import subprocess
import time
import inspect
import yaml
import shutil
import tempfile
import docker
import shlex
import traceback
import json
from tabulate import tabulate
from inspect import getmembers, isfunction
from retrying import retry
from threading import Thread
from logging import FileHandler
from subprocess import PIPE
from module_tools.myconfigparser import MyConfigParser
from module_tools import odoo_config
from tools import __system
from tools import __find_files
from tools import __read_file
from tools import __write_file
from tools import __append_line
from tools import __safe_filename

def patch_inquirer_to_vim():
    from readchar import key
    key.UP = 'k'
    key.DOWN = 'j'


patch_inquirer_to_vim()

try:
    from pudb import set_trace
except Exception:
    set_trace = None
current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))) # script directory
sys.path.append(os.path.join(current_dir, 'python_wait'))
import wait  # NOQA

PLATFORM_OSX = "OSX"
PLATFORM_LINUX = "Linux"
YAML_VERSION = '3.5'
BACKUPDIR = "/host/dumps"
FORCE = any(x == '-f' or x == '--force' for x in sys.argv[1:])
SAFE_KILL = ['postgres', 'redis']
args = sys.argv[1:]

dirs = {
    'admin': 'admin',
    'odoo_home': '',
    'proxy_configs_dir': 'run/proxy',
    'settings.d': 'run/settings.d',
    'host_working_dir': '',
    'run': 'run',
    'run/proxy': 'run/proxy',
    'run/restore': 'run/restore',
    'machines': 'machines',
    'machines/proxy': 'machines/proxy',
    'customs': '',
    'telegrambot': 'config/telegrambat',
}

files = {
    'OCA': 'admin/OCA',
    'docker_compose': 'run/docker-compose.yml',
    'debugging_template': 'config/debugging/template.yml',
    'debugging_composer': 'run/debugging.yml',
    'settings': 'run/settings',
    'settings_local': 'run/settings.d/local',
    'odoo_instances': 'run/odoo_instances',
    'config/default_network': 'config/default_network',
    'run/odoo_debug.txt': 'run/odoo_debug.txt',
    'machines/proxy/instance.conf': 'machines/proxy/instance.conf',
    'machines/postgres/turndb2dev.sql': 'machines/postgres/turndb2dev.sql',
    'commit': 'odoo.commit',
}
commands = {
    'dc': ["/usr/local/bin/docker-compose", "-p", "$PROJECT_NAME", "-f",  "$docker_compose_file"],
}

class Config(object):
    def __init__(self):
        self.verbose = False
        self.force = False
        self.devmode = False
        self.dbname = ""
        self.customs = False
        self.run_postgres = False
        self.run_postgres_in_ram = False


pass_config = click.make_pass_decorator(Config, ensure=True)

class AliasedGroup(click.Group):
    """
    Uses startswith to match command
    """

    def get_command(self, ctx, cmd_name):
        rv = click.Group.get_command(self, ctx, cmd_name)
        if rv is not None:
            return rv
        matches = [x for x in self.list_commands(ctx)
                   if x.startswith(cmd_name)]
        if not matches:
            # search recursivley
            for _cmd_name in self.list_commands(ctx):
                cmd = click.Group.get_command(self, ctx, _cmd_name)
                if type(cmd) == type(self):
                    filtered = filter(lambda cmd: cmd.startswith(cmd_name), cmd.list_commands(ctx))
                    matches += map(lambda cmd_name: (cmd.get_command(ctx, cmd_name), _cmd_name), filtered)
            if len(matches) > 1:
                # try to reduce to exact match
                try_matches = filter(lambda match: match[0].name == cmd_name, matches)
                if try_matches:
                    matches = try_matches

            if len(matches) == 1:
                return matches[0][0]
            elif len(matches) > 1:
                click.echo("Not unique command: {}\n\n".format('\n\t'.join(x[1] + '/' + x[0].name for x in matches)))
            return None

        if len(matches) == 1:
            return click.Group.get_command(self, ctx, matches[0])
        ctx.fail('Too many matches: %s' % ', '.join(sorted(matches)))

@click.group(cls=AliasedGroup)
@click.option("-f", "--force", is_flag=True)
@click.option("--dev", "--devmode", is_flag=True, default=False)
@pass_config
def cli(config, force, devmode):
    config.force = force
    if E("DEVMODE") == "1":
        devmode = True
    config.devmode = devmode
    config.customs = E("CUSTOMS")
    if ("RUN_POSTGRES") == "0":
        config.run_postgres_in_ram = False
    else:
        config.run_postgres = True
        config.run_postgres_in_ram = E("RUN_POSTGRES_IN_RAM") == "1"
    config.dbname = E("DBNAME")

@cli.group(cls=AliasedGroup)
@pass_config
def admin(config):
    pass

@cli.group(cls=AliasedGroup)
@pass_config
def patch(config):
    """

    Workflow new patch:

      * ../odoo patch prepare

      * <adapt odoo>

      * ../odoo patch preview

      *../odoo patch create <name to describe>

      *./odoo patch apply-all
    """
    config.odoo_local_dir = 'odoo'
    config.odoo_local = os.path.join(dirs['customs'], config.odoo_local_dir)
    config.ignore_file = os.path.join(dirs['customs'], '.gitignore')
    config.odoo_git = os.path.join(E("ODOO_HOME"), 'repos/odoo')
    config.patch_dir = os.path.join(dirs['customs'], 'common/patches')
    config.sub_git = os.path.join(config.odoo_local, '.git')
    odoo_dir = os.path.join(dirs['customs'], 'odoo')
    __assert_file_exists(odoo_dir, isdir=True)

@cli.group(cls=AliasedGroup)
@pass_config
def backup(config):
    pass

@cli.group(cls=AliasedGroup)
@pass_config
def restore(config):
    pass

@cli.group(cls=AliasedGroup)
@pass_config
def setup(config):
    pass

@cli.group(cls=AliasedGroup)
@pass_config
def telegram(config):
    pass

@cli.group(cls=AliasedGroup)
@pass_config
def src(config):
    pass

@cli.group(cls=AliasedGroup)
@pass_config
def project(config):
    pass

@cli.group(cls=AliasedGroup)
@pass_config
def db(config):
    """
    Database related actions.
    """
    click.echo("database-name: {}, in ram: {}".format(config.dbname, config.run_postgres_in_ram))
    pass

@cli.group(cls=AliasedGroup)
@pass_config
def module(config):
    pass

@cli.group(cls=AliasedGroup)
@pass_config
def lang(config):
    pass

@cli.group(cls=AliasedGroup)
@pass_config
def control(config):
    pass

@cli.group(cls=AliasedGroup)
@pass_config
def ticket(config):
    pass

def trace():
    if set_trace:
        set_trace()

def __assert_file_exists(path, isdir=False):
    if not os.path.exists(path):
        raise Exception("{} {} not found!".format(
            'Directory' if isdir else 'File',
            path
        ))

def __cmd_interactive(*params):
    cmd = __get_cmd() + list(params)
    proc = subprocess.Popen(cmd)
    proc.wait()

def __dc(cmd, suppress_out=False, raise_exception=True, wait_finished=True, logger=None):
    c = __get_cmd() + cmd
    out = __system(
        c,
        cwd=dirs['odoo_home'],
        suppress_out=suppress_out,
        raise_exception=raise_exception,
        wait_finished=wait_finished,
        logger=logger,
    )
    return out

def __dcexec(cmd, suppress_out=False):
    c = __get_cmd()
    c = c + ['exec', '-T'] + cmd
    out = __system(c, cwd=dirs['odoo_home'], suppress_out=suppress_out)
    return out

def __dcrun(cmd, interactive=False, wait_finished=True, raise_exception=True, logger=None):
    cmd2 = [os.path.expandvars(x) for x in cmd]
    cmd = ['run']
    if not interactive:
        cmd += ['-T']
    cmd += ['--rm', '-e ODOO_HOME=/opt/odoo'] + cmd2
    return __dc(cmd, wait_finished=wait_finished, raise_exception=True, logger=logger)

def __do_restore_db_on_postgres(filename, dbname, host, port, user, password):
    dump_file = os.path.join(BACKUPDIR, filename)

    __assert_file_exists(dump_file)

    click.echo("Restoring dump on {}:{} as {}".format(host, port, user))
    os.environ['PGPASSWORD'] = password
    args = ["-h", host, "-p", port, "-U", user]
    PGRESTORE = [
        "pg_restore",
        "--no-owner",
        "--no-privileges",
        "--no-acl",
    ] + args
    PSQL = ["psql"] + args

    __execute_sql("drop database if exists {}".format(dbname), 'template1', notransaction=True)
    __execute_sql("create database {}".format(dbname), 'template1', notransaction=True)

    method = PGRESTORE
    needs_unzip = True

    dump_type = __get_dump_type(dump_file)
    if dump_type == 'plain_text':
        needs_unzip = False
        method = PSQL
    elif dump_type == 'zipped_sql':
        method = PSQL
        needs_unzip = True
    elif dump_type == "zipped_pgdump":
        pass
    elif dump_type == "unzipped_pgdump":
        needs_unzip = False
    else:
        raise Exception("not impl: {}".format(dump_type))

    PREFIX = []
    if needs_unzip:
        PREFIX = ["/bin/gunzip"]
    else:
        PREFIX = []
    started = datetime.now()
    print("Restoring DB...")
    CMD = " " .join(pipes.quote(s) for s in ['pv', dump_file])
    CMD += " | "
    if PREFIX:
        CMD += " ".join(pipes.quote(s) for s in PREFIX)
        CMD += " | "
    CMD += " ".join(pipes.quote(s) for s in method)
    CMD += " "
    CMD += " ".join(pipes.quote(s) for s in [
        '-d',
        dbname,
    ])
    os.system(CMD)
    print "Restore took {} seconds".format((datetime.now() - started).seconds)

def __do_restore_files(filepath):
    # remove the postgres volume and reinit
    if filepath.startswith("/"):
        raise Exception("No absolute path allowed")
    __dcrun(['odoo', '/bin/restore_files.sh', os.path.basename(filepath)])

def __empty_dir(dir):
    if os.path.isdir(dir):
        for f in os.listdir(dir):
            filepath = os.path.join(dir, f)
            if os.path.isdir(filepath):
                __rmtree(filepath)
            else:
                os.unlink(filepath)

def __execute_sql(sql, dbname=None, fetchone=False, fetchall=False, notransaction=False, no_try=False):
    if not dbname:
        dbname = E("DBNAME")
    # try to connecto to postgres; could startup:

    @retry(wait_random_min=500, wait_random_max=800, stop_max_delay=30000)
    def try_connect():
        __execute_sql("SELECT * FROM pg_catalog.pg_tables;", 'template1', no_try=True)
    if not no_try:
        try_connect()

    import psycopg2
    conn = psycopg2.connect(
        dbname=dbname,
        user=E("DB_USER"),
        password=E("DB_PWD"),
        host=E("DB_HOST"),
        port=E("DB_PORT"),
    )
    conn.autocommit = notransaction
    result = None
    cr = conn.cursor()
    try:
        cr.execute(sql)
        if fetchone:
            result = cr.fetchone()
        elif fetchall:
            result = cr.fetchall()
        conn.commit()
    except Exception:
        conn.rollback()
        raise
    finally:
        cr.close()
        conn.close()
    return result

def __exists_db(dbname):
    dbname = dbname or E("DBNAME")
    sql = "select count(*) from pg_database where datname='{}'".format(dbname)
    record = __execute_sql(sql, fetchone=True, dbname='template1')
    if not record or not record[0]:
        return False
    return True

def __file_default_content(path, default_content):
    if not os.path.exists(path):
        with open(path, 'w') as f:
            f.write(default_content)

def __file_get_lines(path):
    with open(path) as f:
        return f.readlines()

def __get_cmd():
    cmd = commands['dc']
    cmd = [os.path.expandvars(x) for x in cmd]
    return cmd

def __get_dangling_modules():
    rows = __execute_sql(
        "SELECT name, state from ir_module_module where state not in ('installed', 'uninstalled');",
        fetchall=True
    )
    return rows


def __get_docker_compose_run_command():
    """
    Returns bash ready command to call simplebash self by run.

    """
    host_odoo_home = os.environ["ODOO_HOME"]
    local_odoo_home = os.environ['LOCAL_ODOO_HOME']
    cmdline = []
    cmdline.append("/opt/docker/docker")
    cmdline.append("run")
    cmdline.append('-e')
    cmdline.append('ODOO_HOME={}'.format(host_odoo_home))
    envfile = os.path.join(local_odoo_home, 'run/settings')
    if os.path.exists(envfile):
        cmdline.append('--env-file')
        cmdline.append(envfile)
    cmdline.append("--rm")
    cmdline.append('-v')
    cmdline.append("{HOST_ODOO_HOME}:{HOST_ODOO_HOME}".format(HOST_ODOO_HOME=os.environ["ODOO_HOME"]))
    cmdline.append("--workdir")
    cmdline.append(host_odoo_home)
    cmdline.append(__get_docker_image())
    return cmdline

@retry(wait_random_min=500, wait_random_max=800, stop_max_delay=30000)
def __get_docker_image():
    """
    Sometimes this command fails; checked with pudb behind call, hostname matches
    container id; seems to be race condition or so
    """
    hostname = os.environ['HOSTNAME']
    result = [x for x in __system(["/opt/docker/docker", "inspect", hostname], suppress_out=True).split("\n") if "\"Image\"" in x]
    if result:
        result = result[0].split("sha256:")[-1].split('"')[0]
        return result[:12]
    return None

def __get_dump_type(filepath):
    temp = tempfile.mktemp(suffix='.check')
    MARKER = "PostgreSQL database dump"
    FNULL = open(os.devnull, 'w')
    proc = subprocess.Popen(['gunzip', '-c', filepath], stdout=subprocess.PIPE, stderr=FNULL, bufsize=1)

    def reader(proc, pipe):
        try:
            lines = 0
            with pipe:
                for line in iter(pipe.readline, ''):
                    with open(temp, 'a') as f:
                        f.write(line)
                        lines += 1
                        if lines > 20:
                            break
        finally:
            if not proc.returncode:
                proc.kill()

    Thread(target=reader, args=[proc, proc.stdout]).start()
    proc.wait()

    if os.path.exists(temp):
        content = __read_file(temp)
        if MARKER in content:
            return 'zipped_sql'
        if content.startswith("PGDMP"):
            return "zipped_pgdump"
    with open(filepath, 'r') as f:
        for i, line in enumerate(f):
            if i == 0 and line.startswith("PGDMP"):
                return 'pgdump'
            if i > 50:
                break
            if MARKER in line:
                return "plain_text"
    return 'unzipped_pgdump'

def __get_installed_modules():
    rows = __execute_sql(
        "SELECT name, state from ir_module_module where state in ('installed', 'to upgrade');",
        fetchall=True
    )
    return [x[0] for x in rows]

def _get_settings_directories():
    """
    Returns list of paths or files
    """
    customs_dir = odoo_config.customs_dir()
    yield os.path.join(customs_dir, 'settings')
    if os.path.exists('/etc_host/odoo/{}/settings'.format(os.environ['CUSTOMS'])):
        yield '/etc_host/odoo/{}/settings'.format(os.environ['CUSTOMS'])
    if os.path.exists('/etc_host/odoo/settings'):
        yield '/etc_host/odoo/settings'
    yield dirs['settings.d']

def __is_container_running(machine_name):
    container_id = __dc(['ps', '-q', machine_name], raise_exception=False, suppress_out=True).strip()
    if container_id:
        container = filter(lambda container: container.id == container_id, docker.from_env().containers.list())
        if container:
            return container[0].status == 'running'
    return False

def is_up(*machine_name):
    assert len(machine_name) == 1
    print 'Running' if __is_container_running(machine_name[0]) else 'Not Running', machine_name[0]

def __isfloat(x):
    try:
        float(x)
    except Exception:
        return False
    else:
        return True

def __makedirs(path):
    if not os.path.exists(path):
        os.makedirs(path)

def __print_env(vars):
    for x in vars:
        print "{}: {}".format(x, E(x))

def _patch_gitify(config):
    if config.odoo_local_dir not in __read_file(config.ignore_file):
        __append_line(config.ignore_file, config.odoo_local_dir)

    if os.path.exists(config.sub_git):
        shutil.rmtree(config.sub_git)

    print("Making local git repo... in {}".format(config.odoo_local))
    __system(["git", "init", "."], cwd=config.odoo_local)
    print("Adding files...")
    __system(["git", "add", "."], cwd=config.odoo_local)
    __system(["git", "config", "user.email", os.getenv("USER")], cwd=config.odoo_local)
    __system(["git", "commit", "-qam", "initial"], cwd=config.odoo_local)
    print("Done")

def _patch_gitify_on_need(config):
    if not os.path.exists(config.sub_git):
        _patch_gitify()

def _patch_ungitify(config):
    if os.path.exists(config.sub_git):
        shutil.rmtree(config.sub_git)

def _patch_default_patches(config):
    print("Applying default patches")
    print("-remove module install notfications")

    from module_tools.module_tools import remove_module_install_notifications
    remove_module_install_notifications(dirs['customs'])
    print("Apply default patches DONE")

@patch.command(name='prepare')
@pass_config
@click.pass_context
def patch_prepare(ctx, config):
    """
    makes git repo at odoo and applies default patches like remove install notifications
    """
    ctx.invoke(patch_reset)
    _patch_gitify(config)
    _patch_default_patches(config)

    __system(["git", "add", "."], cwd=config.odoo_local)
    try:
        __system(["git", "commit", "-qam", "removed install notifications"], cwd=config.odoo_local)
    except Exception:
        print("Perhaps no install notifications")
    patches = [x for x in _patch_list(config)]
    for filepath in patches:
        ctx.invoke(patch_apply, filepath=filepath)
    __system(["git", "add", "."], cwd=config.odoo_local)
    if patches:
        __system(["git", "commit", "-qam", "applied all current patches"], cwd=config.odoo_local)
    print("You can now do changes; use odoo patch preview to display your changes.")

@patch.command(name='preview')
@pass_config
def patch_preview(config):
    """
    shows what is patched
    """
    diff = _patch_get_diff()
    filename = tempfile.mktemp(suffix='.')
    with open(filename, 'w') as f:
        f.write(diff)
    os.system('cat "{}" | colordiff'.format(filename))

@patch.command(name='create')
@click.argument('name', required=True)
@pass_config
def patch_create(config, name):
    """
    creates the patch
    """
    if not os.path.exists(config.patch_dir):
        os.makedirs(config.patch_dir)
    PATCHFILE = os.path.join(config.patch_dir, __safe_filename(name) + ".patch")

    diff = _patch_get_diff(config)
    if diff:
        with open(PATCHFILE, 'w') as f:
            f.write(diff)
    _patch_ungitify(config)
    print("Created patch file: " + PATCHFILE)

@patch.command(name='apply')
@click.argument('filepath', required=True)
@pass_config
def patch_apply(config, filepath):
    """
    applies patch-file from parameter 2
    """
    _patch_gitify_on_need(config)
    __system(["git", "apply", filepath], cwd=config.odoo_local)

def _patch_list(absolute_path=True):
    for filename in __find_files(dirs['customs'], "-name", "*.patch"):
        if '/migration/' in filename:
            continue
        if not absolute_path:
            filename = os.path.relpath(filename, dirs['customs'])
        yield filename

@patch.command(name='list')
def patch_list():
    """
    lists all patches
    """
    for filename in _patch_list(absolute_path=False):
        print(filename)

@patch.command(name='apply-all')
@pass_config
@click.pass_context
def apply_all(ctx, config):
    """
    applies all patches; no git repo after-wards
    """
    ctx.invoke(patch_reset)
    _patch_default_patches(config)
    for filepath in _patch_list():
        print "Applying patch " + filepath
        apply(filepath)
    _patch_ungitify(config)
    print("Successfully applied all patches and cleand .git directory.")


def _patch_get_diff(config):
    __system(["git", "add", "--intent-to-add", "."], cwd=config.odoo_local)
    diff = __system(["git", "diff", "--binary"], cwd=config.odoo_local, suppress_out=True)
    return diff

def __remove_postgres_connections(DBNAME=None, sql_afterwards=""):
    DBNAME = DBNAME or E("DBNAME")
    print "Removing all current connections from {}".format(DBNAME)
    if __exists_db(DBNAME):
        SQL = """
            SELECT pg_terminate_backend(pg_stat_activity.pid)
            FROM pg_stat_activity
            WHERE pg_stat_activity.datname = '{}'
            AND pid <> pg_backend_pid();
        """.format(DBNAME, sql_afterwards)
        __execute_sql(SQL, 'template1', notransaction=True)
        if sql_afterwards:
            __execute_sql(sql_afterwards, 'template1', notransaction=True)

def __rename_db_drop_target(from_db, to_db):
    if 'to_db' == 'template1':
        raise Exception("Invalid: {}".format(to_db))
    __remove_postgres_connections(from_db)
    __remove_postgres_connections(to_db)
    __execute_sql("drop database if exists {to_db}".format(**locals()), "template1", notransaction=True)
    __execute_sql("alter database {from_db} rename to {to_db};".format(**locals()), "template1", notransaction=True)
    __remove_postgres_connections(to_db)

def __replace_in_file(filepath, text, replacewith):
    with open(filepath, 'r') as f:
        content = f.read()
    content = content.replace(text, replacewith)
    with open(filepath, 'w') as f:
        f.write(content)

def __reset_postgres_container(config):
    # remove the postgres volume and reinit
    if E("RUN_POSTGRES") == "1":
        kill(machines='postgres', brutal=True)
        if config.run_postgres_in_ram:
            pass
        else:
            print "Resettings postgres - killing data - not reversible"
            VOLUMENAME = "{}_postgresdata".format(config.customs)
            docker_client = docker.from_env()

            @retry(wait_random_min=500, wait_random_max=800, stop_max_delay=30000)
            def remove_volume():
                for volume in docker_client.volumes.list():
                    if volume.name == VOLUMENAME:
                        try:
                            kill(brutal=True)
                            __dc(["rm", "-f"]) # set volume free
                            volume.remove()
                        except Exception as e:
                            print e
                            if hasattr(e, 'explanation'):
                                exp = e.explanation

                                if 'volume is in use' in e:
                                    container_id = re.findall(r'\[([^\]]*)\]', exp)[0]
                                    __system(["docker", "rm", container_id])
                            return None
                return True
            remove_volume()
            __dcrun(['-e', 'INIT=1', 'postgres', '/entrypoint2.sh'])
        __start_postgres_and_wait(config)

def __restore_check(filepath):
    dumpname = os.path.basename(filepath)

    if E("DBNAME") not in dumpname and not FORCE:
        raise Exception("The dump-name \"{}\" should somehow match the current database \"{}\", which isn't.".format(
            dumpname,
            E("DBNAME"),
        ))

def __rm_file_if_exists(path):
    if os.path.exists(path):
        os.unlink(path)

def __rmtree(path):
    if not path or path == '/':
        raise Exception("Not allowed: {}".format(path))
    if not path.startswith("/"):
        raise Exception("Not allowed: {}".format(path))
    if not any(path.startswith(dirs['odoo_home'] + x) for x in ['/tmp', '/run/']):
        if "/tmp" in path:
            pass
        else:
            raise Exception('not allowed')
    shutil.rmtree(path)

def __safeget(array, index, exception_on_missing, file_options=None):
    if file_options:
        if os.path.exists(file_options):
            file_options = '\n' + '\n'.join(os.listdir(file_options))
    file_options = file_options or ''
    if len(array) < index + 1:
        raise Exception(exception_on_missing + file_options)
    return array[index]

def __splitcomma(param):
    if isinstance(param, (str, unicode)):
        if not param:
            return []
        return [x.strip() for x in param.split(',') if x.strip()]
    elif isinstance(param, (tuple, list)):
        return list(param)
    raise Exception("not impl")

def __set_db_ownership(config):
    # in development environments it is safe to set ownership, so
    # that accidently accessing the db fails
    if config.devmode:
        if config.run_postgres:
            __start_postgres_and_wait(config)
        from module_tools.module_tools import set_ownership_exclusive
        set_ownership_exclusive()

def __try_to_set_owner(UID, path, recursive=False):
    if os.path.isdir(path):
        uid = os.stat(path).st_uid
        if str(uid) != str(UID) or recursive:
            print("Trying to set correct permissions on {}".format(path))
            options = ""
            if recursive:
                options += "-R"

            __system([
                'sudo',
                'find',
                '-not',
                '-type',
                'l',
                '-not',
                '-user',
                UID,
                '-exec',
                'chown',
                UID,
                '{}',
                '+'
            ], cwd=path)

def __turn_into_devdb(dbname):
    SQLFILE = files['machines/postgres/turndb2dev.sql']
    sql = __read_file(SQLFILE)

    critical = False
    for line in sql.split("\n"):
        if not line:
            continue
        if line.startswith("--set critical"):
            critical = True
            continue
        elif line.startswith("--set not-critical"):
            critical = False
            continue

        comment = re.findall(r'\/\*[^\*^\/]*\*\/', line)
        if comment:
            for comment in comment[0].split(";"):
                comment = comment[2:-2]
                if 'if-table-exists' in comment:
                    table = comment.split("if-table-exists")[1].strip()
                    res = __execute_sql(
                        "select count(*) from information_schema.tables where table_schema='public' and table_name='{}'".format(table),
                        dbname=dbname,
                        fetchone=True
                    )
                    if not res[0]:
                        continue
        try:
            __execute_sql(line, dbname=dbname)
        except Exception as e:
            if critical:
                raise
            print("failed un-critical sql:", str(e))

    from module_tools.module_tools import remove_webassets
    remove_webassets(dbname=dbname)

def __wait_for_port(host, port, timeout=None):
    res = wait.tcp.open(port, host=host, timeout=timeout)
    if not res and timeout:
        raise Exception("Timeout elapsed waiting for {}:{}".format(host, port))

def _askcontinue(msg=None):
    if msg:
        print(msg)
    if FORCE or os.getenv("FORCE_CONTINUE", "0") == "1":
        return
    raw_input("Continue? (Ctrl+C to break)")

def _check_working_dir_customs_mismatch():
    # Checks wether the current working is in a customs directory, but
    # is not matching the correct customs. Avoid creating wrong tickets
    # in the wrong customizations.

    working_dir = dirs['host_working_dir']
    while not os.path.isfile(os.path.join(working_dir, '.customsroot')):
        try:
            working_dir = os.path.dirname(working_dir)
        except Exception:
            break
        if not working_dir.replace("/", ""):
            break

    if os.path.isfile(os.path.join(working_dir, '.customsroot')):
        current_customs = os.path.basename(working_dir)
        if current_customs != os.environ['CUSTOMS']:
            _askcontinue("""Caution: current customs is {} but you are in another customs directory: {}
Continue at your own risk!""".format("$CUSTOMS", "$LOCAL_WORKING_DIR")
                         )

def _cleanup():
    _remove_temp_directories

def _collect_settings_files():
    _files = []
    _files.append(os.path.join(dirs['odoo_home'], 'machines/defaults'))
    # optimize
    for filename in __find_files(dirs['machines'], "-name", "default.settings"):
        _files.append(os.path.join(dirs['machines'], filename))

    for dir in _get_settings_directories():
        if os.path.isfile(dir):
            _files.append(dir)
        elif os.path.isdir(dir):
            for filename in os.listdir(dir):
                _files.append(os.path.join(dir, filename))
    return _files

def _display_machine_tips(machine_name):
    dir = os.path.join(dirs['machines'], machine_name)
    if not os.path.isdir(dir):
        return

    for filename in __find_files(dirs['machines'], '-name', 'tips.txt'):
        filepath = os.path.join(dirs['machines'], filename)
        if os.path.basename(os.path.dirname(filepath)) == machine_name:
            content = __read_file(os.path.join(dirs['machines'], filename))
            print ""
            print "Please note:"
            print "---------------"
            print ""
            print content
            print ""
            print ""

def __postprocess_config(config):
    """
    keep if xxx in config queries for the toggle command. It sets
    a sub config file which does not contain all keys.
    """

    if "DBNAME" not in config.keys() and "CUSTOMS" in config:
        config['DBNAME'] = config['CUSTOMS']
    if config.get("ODOO_VERSION", "") != E("ODOO_VERSION") and "ODOO_VERSION" in config:
        config['ODOO_VERSION'] = E("ODOO_VERSION")

    if 'RUN_POSTGRES' in config.keys() and config['RUN_POSTGRES'] == '1':
        default_values = {
            "DB_HOST": "postgres",
            "DB_PORT": "5432",
            "DB_USER": "odoo",
            "DB_PWD": "odoo"
        }
        for k, v in default_values.items():
            if config.get(k, "") != v:
                config[k] = v

    if "RUN_POSTGRES" in config.keys() and config.get("RUN_POSTGRES", "") != "1" and config.get("RUN_POSTGRES_IN_RAM", "") == "1":
        config['RUN_POSTGRES_IN_RAM'] = "1"

    if "DEVMODE" in config.keys() and config.get("DEVMODE", "0") == "1":
        config['RUN_ODOODEV'] = "1"
    else:
        config['RUN_ODOODEV'] = "0"

    if "RUN_CALENDAR" in config.keys() and config.get("RUN_CALENDAR", "") == "1":
        config['RUN_CALENDAR_DB'] = "1"

def _export_settings():
    _file2env(files['settings'])

    if not os.path.exists(files['settings']):
        raise Exception("Please call ./odoo compose <CUSTOMS> initially.")

    # get odoo version
    ODOO_VERSION = ""
    if os.getenv("CUSTOMS"):
        ODOO_VERSION = str(odoo_config.get_version_from_customs(os.environ['CUSTOMS']))
    os.environ['ODOO_VERSION'] = ODOO_VERSION
    setting_files = _collect_settings_files()
    _make_settings_file(files['settings'], setting_files)
    config = MyConfigParser(files['settings'])
    if ODOO_VERSION:
        config['ODOO_VERSION'] = ODOO_VERSION

    __postprocess_config(config)
    # store the host root folder
    config['HOST_ODOO_HOME'] = E("ODOO_HOME")
    config.write()

    _file2env(files['settings'])

def _file2env(filepath):
    if not os.path.exists(filepath):
        return
    config = MyConfigParser(filepath)
    for k in config.keys():
        os.environ[k] = config[k]

def _get_bash_for_machine(machine):
    if machine == 'postgres':
        return 'bash'
    else:
        return 'bash'

def _get_machines():
    cmd = commands['dc'] + ['ps', '--services']
    out = __system(cmd, cwd=dirs['odoo_home'], suppress_out=True)
    out = set(filter(lambda x: x, out.split("\n")))
    return list(sorted(out))

def _get_platform():
    if os.getenv("PLATFORM", "") in ['Darwin', 'OSX', 'macos']:
        return PLATFORM_OSX
    else:
        return PLATFORM_LINUX

def _make_settings_file(outfile, setting_files):
    """
    Puts all settings into one settings file
    """
    c = MyConfigParser(outfile)
    for file in setting_files:
        if not file:
            continue
        c2 = MyConfigParser(file)

        for key in c2.keys():
            value = c2[key]
            if '~' in value:
                value = value.replace('~', os.environ['HOST_HOME'])
                c2[key] = value

        c.apply(c2)
    if _get_platform() == PLATFORM_OSX:
        c['RUN_RSYNCED'] = '1'
    c.write()

def _prepare_docker_compose_files(dest_file, paths):
    local_odoo_home = os.environ['LOCAL_ODOO_HOME']

    temp_files = set()
    tempdir = tempfile.mkdtemp()

    if not dest_file:
        raise Exception('require destination path')

    with open(dest_file, 'w') as f:
        f.write("#Composed {}\n".format(datetime.now().strftime("%Y-%m-%d %H:%M:%S")))
        f.write("version: '{}'\n".format(os.environ['ODOO_COMPOSE_VERSION']))

    def replace_all_envs_in_file(filepath):
        with open(filepath, 'r') as f:
            content = f.read()
        all_params = re.findall(r'\$\{[^\}]*?\}', content)
        for param in all_params:
            name = param
            name = name.replace("${", "")
            name = name.replace("}", "")
            if name in os.environ:
                content = content.replace(param, os.environ[name])
        with open(filepath, 'w') as f:
            f.write(content)

    for path in set(paths):
        filename = os.path.basename(path)

        def use_file():
            if "run_odoo_version.{}.yml".format(E("ODOO_VERSION")) in filename:
                return True
            if 'run_' in filename:
                run = re.findall(r'run_[^\.]*', filename)
                if run:
                    if '!run' in filename:
                        if os.getenv(run[0].upper(), "0") == "0":
                            return True
                    else:
                        if os.getenv(run[0].upper(), "1") == "1":
                            return True
                return False
            else:
                return True

        if not use_file():
            continue

        with open(path, 'r') as f:
            content = f.read()
            # dont matter if written manage-order: or manage-order
            if 'manage-order' not in content:
                order = '99999999'
            else:
                order = content.split("manage-order")[1].split("\n")[0].replace(":", "").strip()
        folder_name = os.path.basename(os.path.dirname(path))
        if os.getenv("RUN_{}".format(folder_name.upper()), "1") == "0":
            continue

        order = str(order)

        # put all files in their order into the temp directory
        counter = 0
        temp_path = ""
        while not temp_path or os.path.exists(temp_path):
            counter += 1
            temp_path = os.path.join(tempdir, '{}-{}'.format(order, str(counter).zfill(5)))

        # add static yaml content to each machine
        with open(files['config/default_network'], 'r') as f:
            default_network = yaml.load(f.read())

        with open(temp_path, 'w') as dest:
            with open(path, 'r') as source:
                j = yaml.load(source.read())
                # TODO complain version - override version
                j['version'] = YAML_VERSION

                # set settings environment and the override settings after that
                for file in ['run/settings']:
                    path = os.path.join(local_odoo_home, file)
                    if os.path.exists(path):
                        if 'services' in j:
                            for service in j['services']:
                                service = j['services'][service]
                                if 'env_file' not in service:
                                    service['env_file'] = []
                                if isinstance(service['env_file'], (str, unicode)):
                                    service['env_file'] = [service['env_file']]

                                if not [x for x in service['env_file'] if x == '$ODOO_HOME/{}'.format(file)]:
                                    service['env_file'].append('$ODOO_HOME/{}'.format(file))
                    j['networks'] = copy.deepcopy(default_network['networks'])

                dest.write(yaml.dump(j, default_flow_style=False))
                dest.write("\n")
        replace_all_envs_in_file(temp_path)
        temp_files.add(os.path.basename(temp_path))
        del temp_path

    def post_process_complete_yaml_config(yml):
        """
        This is after calling docker-compose config, which returns the
        complete configuration.

        Aim is to take the volumes defined in odoo_base and append them
        to all odoo containers.
        """

        with open(os.path.join(local_odoo_home, 'machines/odoo/docker-compose.yml')) as f:
            odoodc = yaml.load(f.read())

        for odoomachine in odoodc['services']:
            if odoomachine == 'odoo_base':
                continue
            machine = yml['services'][odoomachine]
            for k in ['volumes']:
                machine[k] = []
                for x in yml['services']['odoo_base'][k]:
                    machine[k].append(x)
            for k in ['environment']:
                machine.setdefault(k, {})
                for x, v in yml['services']['odoo_base'][k].items():
                    machine[k][x] = v
        yml['services'].pop('odoo_base')

        return yml

    # call docker compose config to get the complete config
    _files = sorted(temp_files, key=lambda x: float(x.split("/")[-1].replace("-", ".")))
    cmdline = __get_docker_compose_run_command()
    cmdline.append("/usr/local/bin/docker-compose")
    for file in _files:
        cmdline.append('-f')
        cmdline.append(os.path.join(os.path.basename(tempdir), file))
    cmdline.append('config')

    # annotation: per symlink all subfiles/folders are linked to a path,
    # that matches the host system path
    shutil.move(tempdir, local_odoo_home)
    tempdir = os.path.join(local_odoo_home, os.path.basename(tempdir))

    attempts = 0
    while True:
        try:
            conf = __system(cmdline, cwd=local_odoo_home, suppress_out=True)
        except Exception:
            # stupid conversion from guid to int, if characters missing
            attempts += 1
            if attempts > 5:
                raise
        else:
            # post-process config config
            conf = post_process_complete_yaml_config(yaml.load(conf))
            conf = yaml.dump(conf, default_flow_style=False)

            with open(dest_file, 'w') as f:
                f.write(conf)
            break
        finally:
            __rmtree(tempdir)

def _prepare_yml_files_from_template_files():
    # replace params in configuration file
    # replace variables in docker-compose;

    if E("ODOO_MANAGER_STARTED_ONCE") != "1":
        for name in ['CUSTOMS', 'DB', 'ODOO_VERSION', 'ODOO_FILES']:
            print("{}: {}".format(name, E(name)))

    # python: find all configuration files from machines folder; extract sort
    # by manage-sort flag and put file into run directory
    # only if RUN_parentpath like RUN_ODOO is <> 0 include the machine
    #
    # - also replace all environment variables
    def find_files(dir):
        for filepath in __find_files(
                dir,
                '-regex',
                '.*\/docker-compose.*.yml'
        ):
            yield filepath
    _files = []
    _files += find_files(dirs['machines'])
    _files += find_files(odoo_config.customs_dir())
    _prepare_docker_compose_files(files['docker_compose'], _files)

def _remember_customs_and_cry_if_changed():
    # if customs changed, then restart is required

    if __is_container_running('odoo'):
        out = __dcexec(['odoo', 'env'], suppress_out=True)
        out = [x for x in out.split('\n') if x.startswith("CUSTOMS=")]
        if out:
            current_customs = out[0].split("=")[-1]
            if os.getenv("CUSTOMS"):
                if current_customs != os.getenv('CUSTOMS'):
                    print("Customs changed - you need to restart and/or rebuild!")
                    __dc(['stop', '-t 2'])

def _remove_temp_directories():
    for dir in os.listdir(dirs['odoo_home']):
        if dir.startswith("tmp") and len(dir) == len('tmp......'):
            __rmtree(os.path.join(dirs['odoo_home'], dir))

def _reset_proxy_configs():
    __empty_dir(dirs['run/proxy'])

def _prepare_filesystem():
    __makedirs(dirs['settings.d'])
    for subdir in ['config', 'sqlscripts', 'debug', 'proxy']:
        __makedirs(os.path.join(dirs['odoo_home'], 'run', 'subdir'))
    __system(['sudo', '-E', 'chown', "{uid}:{uid}".format(uid=E("UID")), "-R", dirs['run']])

    __file_default_content(files['odoo_instances'], "default default\n")

def _sanity_check():
    if not E("RUN_POSTGRES"):
        raise Exception("Please define RUN_POSTGRES")

    if E("RUN_POSTGRES") == "1" and E("DB_HOST") != "postgres":
        print("You are using the docker postgres container, but you do not have the DB_HOST set to use it.")
        print("Either configure DB_HOST to point to the docker container or turn it off by: ")
        print("RUN_POSTGRES=0")
        sys.exit(1)

    if E("OWNER_UID") == "0":
        print("Advise: you should set OWNER_UID so that dump files are marked as the correct owner")
        time.sleep(3)

    if E("ODOO_FILES") and os.path.isdir(E("ODOO_FILES")):
        # checking directory permissions of session files and filestorage
        __try_to_set_owner(E("OWNER_UID"), E("$ODOO_FILES"))

    # make sure the odoo_debug.txt exists; otherwise directory is created
    __file_default_content(files['run/odoo_debug.txt'], "")

    if not E("ODOO_MODULE_UPDATE_RUN_TESTS"):
        print("Please define wether to run tests on module updates by setting ODOO_MODULE_UPDATE_RUN_TESTS")
        time.sleep(2)


def _setup_odoo_instances():
    def __add_location_files(config_path, dir):
        lines = []
        for subdir in os.listdir(dir):
            if os.path.isdir(os.path.join(dir, subdir)):
                for file in os.listdir(os.path.join(dir, subdir)):
                    lines.append("\tInclude " + os.path.join("/etc/proxy", os.path.basename(subdir), file))
        __replace_in_file(config_path, "__INCLUDES__", '\n'.join(lines))

    if os.path.exists(files['odoo_instances']):

        if os.path.exists(files['odoo_instances']):
            for line in __file_get_lines(files['odoo_instances']):
                name, domain = line.strip().split(" ")
                config_path = os.path.join(dirs['proxy_configs_dir'], "{}.host".format(name))
                shutil.copy(files['machines/proxy/instance.conf'], config_path)

                if domain == "default":
                    __replace_in_file(config_path, "__DOMAIN__", '*')
                else:
                    if domain:
                        __replace_in_file(config_path, "__DOMAIN__", domain)
                if name != "default":
                    # adapt the one yml file and duplicate the odoo service there;
                    # removing any ports
                    with open(files['docker_compose']) as f:
                        j = yaml.load(f.read())
                    odoo = copy.deepcopy(j['services']['odoo'])
                    if 'ports' in odoo:
                        del odoo['ports']
                    odoo['container_name'] = '_'.join([os.environ['CUSTOMS'], "odoo", name])
                    j['services']['odoo_{}'.format(name)] = odoo
                    with open(files['docker_compose'], 'w') as f:
                        f.write(yaml.dump(j, default_flow_style=False))

    for file in os.listdir(dirs['run/proxy']):
        if not file.endswith('.host'):
            continue
        config_path = os.path.join(dirs['run/proxy'], file)
        __add_location_files(config_path, dirs['run/proxy'])


def _setup_proxy():
    CONFIG_DIR = dirs['run/proxy']
    __empty_dir(dirs['proxy_configs_dir'])

    sys.path.append(dirs['machines/proxy'])
    importlib.import_module("add_upstream")
    from add_upstream import add_upstream as f_add_upstream

    def get_rules():
        for root, _, _filenames in os.walk(dirs['machines']):
            for filename in _filenames:
                if filename == 'upstream.path':
                    filepath = os.path.join(root, filename)
                    machine = None
                    p = filepath
                    while os.path.basename(p) != "machines":
                        machine = os.path.basename(p)
                        p = os.path.dirname(p)
                    del p

                    try:
                        version = float(os.path.basename(os.path.dirname(filepath)))
                    except Exception:
                        version = None
                    else:
                        if str(version) != str(odoo_config.get_version_from_customs(os.environ['CUSTOMS'])):
                            continue
                    with open(filepath, 'r') as f:
                        content = f.readlines()
                        for line in content:
                            LOCATION, UPSTREAM = line.strip().split(" ")
                            if not LOCATION or not UPSTREAM:
                                raise Exception("Invalid rule: {}".format(line))
                            yield filepath, LOCATION, UPSTREAM, machine

    for filepath, LOCATION, UPSTREAM, machine in get_rules():
        __makedirs(os.path.join(CONFIG_DIR, machine))
        location_friendly_name = LOCATION.replace("/", "_")
        filename = "{}.location".format(location_friendly_name)
        CONFIG_PATH = os.path.join(CONFIG_DIR, machine, filename)
        UPSTREAM_INSTANCE = UPSTREAM.replace("default", "odoo")
        f_add_upstream(LOCATION, UPSTREAM_INSTANCE, CONFIG_PATH)

def __start_postgres_and_wait(config):
    if config.run_postgres:
        if config.run_postgres_in_ram and __is_container_running('postgres'):
            # avoid recreate
            pass
        else:
            __dc(["up", "-d", "postgres"])
        __wait_for_port(E("DB_HOST"), long(E("DB_PORT")), timeout=30)
        __execute_sql("""
        SELECT table_schema,table_name
        FROM information_schema.tables
        ORDER BY table_schema,table_name;
        """, dbname='template1')

def _startup():
    if os.path.isfile(files['settings']):
        _file2env(files['settings'])
    dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe()))) # script directory
    dir = os.path.dirname(dir)
    dirs['odoo_home'] = dir

    def make_absolute(d):
        for k, v in d.items():
            if not v.startswith('/'):
                d[k] = os.path.join(dir, v)
    make_absolute(dirs)
    try:
        odoo_config.current_customs()
    except Exception:
        pass
    else:
        dirs['customs'] = odoo_config.customs_dir()
    files['commit'] = os.path.join(dirs['customs'], files['commit'])
    make_absolute(files)
    os.environ['ODOO_MANAGER_STARTED_ONCE'] = '1'
    os.environ['ODOO_COMPOSE_VERSION'] = "3.3"
    os.environ['PGPASSFILE'] = "/tmp/.pgpass" # must match the executing script
    os.environ['PGHOST'] = os.path.expandvars("$DB_HOST")
    os.environ['PGPORT'] = os.path.expandvars("$DB_PORT")
    os.environ['PGUSER'] = os.path.expandvars("$DB_USER")
    os.environ['LOCAL_WORKING_DIR'] = "{}/{}".format(os.getenv("EXTERNAL_ROOT"), os.getenv("WORKING_DIR"))  # the working directory accessible from container of this script.
    dirs['host_working_dir'] = os.environ['LOCAL_WORKING_DIR']
    commands['dc'] = [x.replace("$docker_compose_file", files['docker_compose']) for x in commands['dc']]

@module.command()
def abort_upgrade():
    print "Aborting upgrade..."
    SQL = """
        UPDATE ir_module_module SET state = 'installed' WHERE state = 'to upgrade';
        UPDATE ir_module_module SET state = 'uninstalled' WHERE state = 'to install';
    """
    __execute_sql(SQL)

def E(name):
    if name.startswith("$"):
        name = name[1:]
    return os.getenv(name, "")

@control.command()
@click.argument('machine', required=True)
def attach(machine):
    """
    attaches to running machine
    """
    _display_machine_tips(machine)
    bash = _get_bash_for_machine(machine)
    __cmd_interactive('exec', machine, bash)

@backup.command(name='all')
def backup_all(filename=None):
    """
    Runs backup-db and backup-files
    """
    t1 = Thread(target=backup_db, args=(filename,))
    t2 = Thread(target=backup_files)
    t1.start()
    t2.start()
    t1.join()
    t2.join()

@backup.command(name='calendar')
@pass_config
def backup_calendar(config, filename=None):
    if E("RUN_CALENDAR") != "1":
        return
    filename = filename or datetime.now().strftime("{}.calendar.%Y%m%d%H%M%S.dump.gz".format(config.customs))
    filepath = os.path.join(BACKUPDIR, filename)
    __backup_postgres(
        filepath,
        dbname=E("CALENDAR_DB_NAME"),
        host=E("CALENDAR_DB_HOST"),
        port=E("CALENDAR_DB_PORT"),
        user=E("CALENDAR_DB_USER"),
        password=E("CALENDAR_DB_PWD"),
    )


def __backup_postgres(filepath, dbname, host, port, user, password):
    os.environ['PGPASSWORD'] = password
    import psycopg2
    conn = psycopg2.connect(dbname=dbname, host=host, port=long(port), user=user, password=password)
    cr = conn.cursor()
    cr.execute("SELECT (pg_database_size(current_database())) FROM pg_database")
    size = cr.fetchone()[0] * 0.7 # ct
    bytes = str(float(size)).split(".")[0]
    conn.close()
    os.system('pg_dump -h "{host}" -p {port} -U "{user}" -Z0 -Fc {dbname} | pv -s {bytes} | pigz --rsyncable > {filepath}'.format(**locals()))

def __get_default_backup_filename(config):
    return datetime.now().strftime("{}.odoo.%Y%m%d%H%M%S.dump.gz".format(config.customs))

@backup.command(name='db')
@click.argument('filename', required=False, default='')
@pass_config
@click.pass_context
def backup_db(ctx, config, filename):
    if not filename and config.devmode:
        answer = inquirer.prompt([inquirer.Text('filename', message="Filename", default=__get_default_backup_filename(config))])
        if not answer:
            return
        filename = answer['filename']

    filename = filename or __get_default_backup_filename(config)

    if filename.startswith("/"):
        raise Exception("No slash for backup filename allowed")
    print "Databasename is " + E("DBNAME")
    filepath = os.path.join(BACKUPDIR, filename)
    if os.path.exists(filepath):
        os.unlink(filepath)
    LINKPATH = os.path.join(BACKUPDIR, 'latest_dump')
    __start_postgres_and_wait(config)

    __backup_postgres(filepath, E("DBNAME"), E("DB_HOST"), E("DB_PORT"), E("DB_USER"), E("DB_PWD"))

    if E("NO_BACKUP_SYMBOLIC_LINK_DUMP") != "1":
        if os.path.islink(LINKPATH) or os.path.exists(LINKPATH):
            os.unlink(LINKPATH)
        __system([
            'ln',
            '-s',
            os.path.basename(filepath),
            os.path.basename(LINKPATH)
        ], cwd=os.path.dirname(filepath))
    print "Dumped to ", filepath
    ctx.invoke(telegram_send, "Database Backup {} done to {}".format(config.dbname, filepath))

@backup.command(name='files')
@pass_config
def backup_files(config):
    BACKUP_FILENAME = "{CUSTOMS}.files.tar.gz".format(CUSTOMS=config.customs)

    if os.path.exists(BACKUP_FILENAME):
        second = BACKUP_FILENAME + ".bak"
        if os.path.exists(second):
            os.unlink(second)
        shutil.move(BACKUP_FILENAME, second)
    __dcrun(["odoo", "/backup_files.sh", BACKUP_FILENAME])
    print "Backup files done to {}".format(BACKUP_FILENAME)

@control.command()
@click.argument('machines', nargs=-1)
@click.option('--no-cache', is_flag=True)
@click.option('--pull', is_flag=False)
@pass_config
def build(config, machines, pull=False, no_cache=False):
    """
    no parameter all machines, first parameter machine name and passes other params; e.g. ./odoo build asterisk --no-cache"
    """
    options = []
    if pull:
        options += ['--pull']
    if no_cache:
        options += ['--no-cache']

    __dc(['build'] + options + list(machines))

@ticket.command()
def commit(*parameters):
    from module_tools import odoo_versioning as versioning
    versioning.actions["commit"](*parameters)

@admin.command()
@click.pass_context
def reload(ctx):
    """
    After settings change call this def to update all settings.
    """
    config = MyConfigParser(files['settings'])
    ctx.invoke(compose, customs=config['CUSTOMS'], db=config['DBNAME'], demo=config['ODOO_DEMO'] == "1")

@admin.command()
@click.argument("customs", required=True)
@click.argument("db", required=False)
@click.option("--demo", is_flag=True, help="Enabled demo data.")
@pass_config
def compose(config, customs='', db='', demo=False):
    """
    - builds docker compose
    - builds proxy settings
    - setups odoo instances
    """
    def setup_settings_file():
        """
        Cleans run/settings and sets minimal settings;
        Puts default values in settings.d to override any values
        """
        config = MyConfigParser(files['settings'])
        if customs:
            if config.get('CUSTOMS', '') != customs:
                config.clear()
                config['CUSTOMS'] = customs
                config.write()
        vals = {}
        if customs:
            vals['CUSTOMS'] = customs
        vals['DBNAME'] = db or customs
        if demo:
            vals['ODOO_DEMO'] = "1" if demo else "0"

        for k, v in vals.items():
            if config.get(k, '') != v:
                config[k] = v
                config.write()
        if not os.path.isdir(dirs['settings.d']):
            os.makedirs(dirs['settings.d'])
        config_compose_minimum = MyConfigParser(os.path.join(dirs['settings.d'], 'compose'))
        config_compose_minimum.clear()
        for k in ['CUSTOMS', 'DBNAME', 'ODOO_DEMO']:
            if k in vals:
                config_compose_minimum[k] = vals[k]
        config_compose_minimum.write()
    setup_settings_file()

    _export_settings()
    _remove_temp_directories()
    _prepare_filesystem()
    _prepare_yml_files_from_template_files()
    _reset_proxy_configs()
    _setup_proxy()
    _setup_odoo_instances()
    # ln path ./src to customs
    SRC_PATH = os.path.join(os.environ['LOCAL_ODOO_HOME'], 'src')
    if os.path.islink(SRC_PATH):
        os.unlink(SRC_PATH)
    os.symlink('data/src/customs/{}'.format(config.customs), SRC_PATH)

    print "Built the docker-compose file."

@ticket.command()
def current_ticket():
    from module_tools import odoo_versioning as versioning
    versioning.actions["current-ticket"]()

@module.command(name='remove-old')
@click.option("--ask-confirm", default=True, is_flag=True)
@pass_config
@click.pass_context
def remove_old_modules(ctx, config, ask_confirm=True):
    """
    Sets modules to 'uninstalled', that have no module dir anymore.
    """
    from module_tools.module_tools import get_manifest_path_of_module_path
    from module_tools.odoo_config import get_odoo_addons_paths
    from module_tools.odoo_config import get_links_dir
    print("Analyzing which modules to remove...")
    ctx.invoke(wait_for_container_postgres)
    mods = sorted(map(lambda x: x[0], __execute_sql("select name from ir_module_module where state in ('installed', 'to install', 'to upgrade') or auto_install = true;", fetchall=True)))
    mods = filter(lambda x: x not in ('base'), mods)
    to_remove = []
    for mod in mods:
        for path in get_odoo_addons_paths() + [get_links_dir()]:
            if get_manifest_path_of_module_path(os.path.join(path, mod)):
                break
        else:
            to_remove.append(mod)
    if not to_remove:
        print("Nothing found to remove")
        sys.exit(0)
    print("Following modules are set to uninstalled:")
    for mod in to_remove:
        print(mod)
    if ask_confirm:
        answer = inquirer.prompt([inquirer.Confirm('confirm', message="Continue?", default=True)])
        if not answer or not answer['confirm']:
            return
    for mod in to_remove:
        __execute_sql("update ir_module_module set auto_install=false, state = 'uninstalled' where name = '{}'".format(mod))
        print("Set module {} to uninstalled.".format(mod))

@control.command()
@click.argument('machine', required=True)
@pass_config
@click.pass_context
def debug(ctx, config, machine):
    """
    starts /bin/bash for just that machine and connects to it; if machine is down, it is powered up; if it is up, it is restarted; as command an endless bash loop is set"
    """

    # puts endless loop into container command and then attaches to it;
    # by this, name resolution to the container still works
    __set_db_ownership(config)
    _askcontinue("Current machine {} is dropped and restartet with service ports in bash. Usually you have to type /debug.sh then.".format(machine))
    # shutdown current machine and start via run and port-mappings the replacement machine
    ctx.invoke(kill, machines=[machine])
    ctx.invoke(rm, machines=[machine])
    shutil.copy(files['debugging_template'], files['debugging_composer'])
    __replace_in_file(files['debugging_composer'], "${CUSTOMS}", E("CUSTOMS"))
    __replace_in_file(files['debugging_composer'], "${NAME}", machine)

    # TODO make configurable in machines
    PORT = str({
        'odoo': 8072,
        'odoo_debug': 8072
    }.get(machine, 80))
    __replace_in_file(files['debugging_composer'], "{machine_main_port}", PORT)
    commands['dc'] += ['-f', files['debugging_composer']]

    __dc(['up', '-d', machine])
    ctx.invoke(attach, machine=machine)

@ticket.command()
def deploy():
    from module_tools import odoo_versioning as versioning
    versioning.action_deploy_ticket()

@control.command()
@click.pass_context
def dev(ctx):
    """
    starts developing in the odoo container
    """
    ctx.invoke(kill, brutal=True)
    ctx.invoke(rm)
    ctx.invoke(reload)
    ctx.invoke(build)
    ctx.invoke(up, daemon=True)
    ctx.invoke(attach, machine='odoo')

@ticket.command()
def dirty():
    from module_tools import odoo_versioning as versioning
    versioning.dirty()

def __do_command(cmd, *params, **kwparams):
    cmd = cmd.replace('-', '_')
    return globals()[cmd](*params, **kwparams)

@db.command()
@click.argument('dbname', required=True)
@pass_config
def drop_db(config, dbname):

    if not (config.devmode or config.force):
        print("Either DEVMODE or force required")
        sys.exit(-1)
    __remove_postgres_connections(dbname)
    __execute_sql("drop database {};".format(dbname), dbname='template1', notransaction=True)
    print("Database {} dropped.".format(dbname))

@control.command(name='exec')
@click.argument('machine', required=True)
@click.argument('args', nargs=-1)
def execute(machine, args):
    args = [machine] + list(args)
    __dcexec(args)

@lang.command(name='export')
@click.argument('lang', required=True)
@click.argument('modules', nargs=-1)
def export_i18n(lang, modules):
    modules = ','.join(modules)
    __dcrun(['odoo', '/export_i18n.sh', lang, modules])
    # file now is in $DIR/run/i18n/export.po

@admin.command()
def fix_permissions():
    if E("ODOO_FILES") and os.path.isdir(E("ODOO_FILES")) and E("OWNER_UID") and E("OWNER_UID") != "0":
        __try_to_set_owner(E("OWNER_UID", E("ODOO_FILES"), recursive=True))
    customs_dir = odoo_config.customs_dir()
    __try_to_set_owner("1000", customs_dir, recursive=True) # so odoo user has access

@control.command()
@click.pass_context
def force_kill(ctx, machine):
    ctx.invoke(kill, machine=machine, brutal=True)

@lang.command(name='list')
def get_all_langs():
    langs = [x[0] for x in __execute_sql(
        "select distinct code from res_lang;",
        fetchall=True
    )]
    for lang in langs:
        print(lang)
    return langs

@restore.command('show-dump-type')
def get_dump_type(filename):
    filename = _inquirer_dump_file()
    if filename:
        dump_file = os.path.join(BACKUPDIR, filename)
        dump_type = __get_dump_type(dump_file)
        print dump_type

@control.command()
@click.argument('machines', nargs=-1)
@click.option('-b', '--brutal', is_flag=True, help='dont wait')
@pass_config
@click.pass_context
def kill(ctx, config, machines, brutal=False):
    """
    kills running machine
    safely shutdowns postgres and redis

    if not brutal it means softly
    """
    machines = list(machines)
    if config.run_postgres_in_ram and not machines:
        machines = filter(lambda x: x != 'postgres', _get_machines())
    if not brutal:
        safe_stop = []
        for machine in SAFE_KILL:
            if not machines or machine in machines:
                if __is_container_running(machine):
                    safe_stop += [machine]

        if safe_stop:
            __dc(["stop", "-t 20"] + safe_stop)  # persist data
    __dc(['stop', '-t 2'] + list(machines))

@cli.group()
def image():
    pass

@image.command(name='import')
@click.argument('filename', required=True)
def image_import(filename):
    """
    Imports binary image of machine
    """
    filename = _get_dump_files("Choose image to import")
    if not filename:
        return
    dump_path = os.path.join(BACKUPDIR, os.path.basename(filename))
    __system([
        "docker",
        "load",
        dump_path
    ])

@image.command(name='export')
@click.argument('filename', required=False)
def image_export(filename):
    """
    Exports all images of the customizations to one file.
    Can be imported via image-import.
    """
    dump_path = os.path.join(BACKUPDIR, E("CUSTOMS") + '.docker.images.tar')
    folder = tempfile.mkdtemp()
    image_ids = __dc([
        'images',
        '-q',
    ], suppress_out=True).split("\n")
    filesize = 0
    for image in image_ids:
        if not image:
            continue
        filepath = os.path.join(folder, image)
        print "Storing {} to {}".format(image, filepath)
        __system([
            'docker',
            'save',
            image,
            '-o',
            filepath,
        ], suppress_out=True)
        filesize += os.stat(filepath).st_size
        print "File size currently:", humanize.naturalsize(filesize)
    if not filesize:
        raise Exception("No images found!")
    __system([
        "tar",
        "cfz",
        dump_path,
        '.',
    ], cwd=folder)
    print os.path.basename(dump_path)
    compressed_size = os.stat(dump_path).st_size
    ratio = round(float(compressed_size) / float(filesize) * 100.0, 1)
    print "Compressed:", humanize.naturalsize(compressed_size), "Uncompress:", humanize.naturalsize(filesize), "Ratio:", ratio

@ticket.command(name='inc-version')
def ticket_incversions():
    from module_tools import odoo_versioning as versioning
    versioning.actions["incversions"]()

@module.command(name='unlink')
def module_unlink():
    for file in os.listdir(os.path.join(dirs['customs'], 'links')):
        path = os.path.join(dirs['customs'], file)
        if os.path.islink(path):
            os.unlink(path)

@module.command(name='link')
def module_link():
    """
    links all modules into ./links
    """
    os.system("python " + os.path.join(dirs['admin'], 'link_modules'))

@cli.command(name='log')
@click.argument('machines', nargs=-1)
@click.option('-t', '--tail', required=False, type=int, default=200)
@click.option('-f', '--follow', is_flag=True)
def logall(machines, follow, tail):
    cmd = ['logs']
    if follow:
        cmd += ['-f']
    if tail:
        cmd += ['--tail={}'.format(tail)]
    cmd += list(machines)
    __dc(cmd)

@lang.command(name='import')
def lang_import_i18n(lang, po_file_path):
    __dcrun(['odoo', '/import_i18n.sh', lang, po_file_path])

@src.command(name='make-customs')
@click.pass_context
def src_make_customs(ctx, customs, version):
    raise Exception("rework - add fetch sha")
    _askcontinue()
    admin_dir = dirs['admin']
    ctx.invoke(kill)
    from module_tools.module_tools import make_customs as _tools_make_customs
    _tools_make_customs(
        customs=customs,
        version=version,
    )
    os.environ['CUSTOMS'] = customs
    cwd = os.path.join(dirs['odoo_home'], 'customs', customs)
    ctx.invoke(checkout_odoo)
    odoo_dir = os.path.join(cwd, 'odoo')
    __system([
        'git', 'checkout', str(version)
    ], cwd=odoo_dir)
    __system([
        'git', 'checkout', str(version)
    ], cwd=admin_dir)
    __system([
        "OCA-all"
    ], cwd=admin_dir)
    __system([
        "odoo-submodule",
        'tools,web_modulesroduct_modules,calendar_ics',
    ], cwd=admin_dir)
    ctx.invoke(kill)
    ctx.invoke(compose, customs=customs)
    ctx.invoke(up)

@module.command(name='OCA')
def OCA(module):
    """
    Adds module from OCA - provide the repository name like 'web_modules'
    """
    __system([
        files['OCA'],
        module,
    ], cwd=dirs['admin'])


def _migrate(ctx, config, log_file, from_version, to_version, SETTINGS_D_FILE, no_auto_backup=False, git_clean=True, debug=False, module='all', pull_latest=False):
    """

    Migration Script

    For Debugging OCA Migration script walk into /repos/Openupgrade and edit code.
    Provide parameter --no-git-clean then, otherwise traces/changes are removed.


    """
    CONFIG_FILE = '/home/odoo/config_migration'
    BASE_PATH = "/opt/odoo_home/repos/OpenUpgrade/" # must match in container

    def prepareCommand(cmd, module):
        def repl(s):
            s = s.format(
                configfile=CONFIG_FILE,
                db=os.environ['DBNAME'],
                module=module,
            )
            return s
        cmd = [repl(x) for x in cmd]
        cmd = pickle.dumps(cmd)
        cmd = base64.b64encode(cmd)
        return cmd

    def connect_db():
        import psycopg2
        return psycopg2.connect(
            dbname=os.environ['DBNAME'],
            user=os.environ['DB_USER'],
            host=os.environ['DB_HOST'],
            port=long(os.environ['DB_PORT']),
            password=os.environ['DB_PWD'],
        )

    def __check_for_dangling_modules():
        conn = connect_db()
        cr = conn.cursor()
        cr.execute("select count(*) from ir_module_module where state like 'to install'")  # to upgrade seems to be ok
        if cr.fetchone()[0]:
            ctx.invoke(progress)
            raise Exception("Found dangling modules!")
        conn.close()

    def __run_before_after(type, version, debug, module, logger):
        print("Running {} processes {}".format(type, version))
        cmd = (
            "/usr/bin/python",
            "/run_migration.py",
            type,
        )
        if module == 'all' and not debug:
            ctx.invoke(run, machine='odoo', args=cmd, logger=logger)
        elif debug:
            answer = raw_input("Run {} sql/py? [Y/n]".format(type))
            if not answer or answer in ['Y', 'y']:
                ctx.invoke(runbash, *cmd, logger=logger)

    def __run_migration(migrations, git_clean, version, debug, module, logger, pull_latest):
        print("Starting Openupgrade Migration to {}".format(version))
        cmd = (
            "/usr/bin/python",
            "/opt/migrate.sh",
            migrations[version]['branch'],
            prepareCommand(migrations[version]['cmd'], module=module),
            ','.join(os.path.join(BASE_PATH, x) for x in migrations[version]['addons_paths']),
            version,
            '1' if git_clean else '0',
            '1' if pull_latest else '0',
        )
        if debug:
            ctx.invoke(runbash, machine='odoo', args=cmd)
        else:
            ctx.invoke(run, machine='odoo', args=cmd, logger=logger, interactive=False)

    """

    :param pull_latest: if true, then git pull is done in OpenUpgrade

    """
    from_version = str(float(from_version))
    to_version = str(float(to_version))

    # Make sure that RUN_MIGRATION is temporarily set to 1
    settings = MyConfigParser(SETTINGS_D_FILE)
    settings.clear()
    settings['RUN_MIGRATION'] = '1'
    settings.write()

    FORMAT = '[%(levelname)s] %(asctime)s\t%(message)s'
    logging.basicConfig(filename="/dev/stdout", format=FORMAT)
    logging.getLogger().setLevel(logging.DEBUG)
    logger = logging.getLogger('')  # root handler
    formatter = logging.Formatter(FORMAT)

    if os.path.exists(log_file):
        os.unlink(log_file)
    rh = FileHandler(filename=log_file)
    rh.setFormatter(formatter)
    rh.setLevel(logging.DEBUG)
    logger.addHandler(rh)

    migrations = {
        '11.0': {
            'branch': '11.0',
            'addons_paths': [
                'odoo/addons',
                'addons',
            ],
            'cmd': [
                './odoo-bin',
                '--update={module}',
                '--database={db}',
                '--config={configfile}',
                '--stop-after-init',
                '--no-xmlrpc'
            ],
        },
        '10.0': {
            'branch': '10.0',
            'addons_paths': [
                'odoo/addons',
                'addons',
            ],
            'cmd': [
                './odoo-bin',
                '--update={module}',
                '--database={db}',
                '--config={configfile}',
                '--stop-after-init',
                '--no-xmlrpc',
            ],
        },
        '9.0': {
            'branch': '9.0',
            'addons_paths': [
                'openerp/addons',
                'addons',
            ],
            'cmd': [
                './openerp-server',
                '--update={module}',
                '--database={db}',
                '--config={configfile}',
                '--stop-after-init',
                '--no-xmlrpc',
            ],
        },
        '8.0': {
            'branch': '8.0',
            'addons_paths': [
                'openerp/addons',
                'addons',
            ],
            'cmd': [
                './openerp-server',
                '--update={module}',
                '--database={db}',
                '--config={configfile}',
                '--stop-after-init',
                '--no-xmlrpc',
            ],
        },
        '7.0': {
            'branch': '7.0',
            'cmd': [
                './openerp-server',
                '--update={module}',
                '--database={db}',
                '--config={configfile}',
                '--stop-after-init',
                '--no-xmlrpc',
                '--no-netrpc',
            ]
        },
    }

    if from_version not in migrations:
        print "Invalid from version: {}".format(from_version)

    for version in sorted(filter(lambda v: float(v) > float(from_version) and float(v) <= float(to_version), migrations), key=lambda x: float(x)):
        with open(os.path.join(dirs['customs'], '.version'), 'w') as f:
            f.write(version)
        logger.info("""\n========================================================================
Migration to Version {}
========================================================================""".format(version)
                    )

        if module == 'all':
            ctx.invoke(compose, customs=config.customs)
            ctx.invoke(build, machines=['odoo'])
        ctx.invoke(wait_for_container_postgres)

        __run_before_after('before', version, debug, module, logger)
        __run_migration(migrations, git_clean, version, debug, module, logger, pull_latest)
        __run_before_after('after', version, debug, module, logger)
        __check_for_dangling_modules()

        if not no_auto_backup:
            print "Backup of database Version {}".format(version)
            ctx.invoke(backup_db, filename="{dbname}_{version}".format(version=version, dbname=os.environ['DBNAME']))

    with open(os.path.join(dirs['customs'], '.version'), 'w') as f:
        f.write(to_version)

    os.unlink(SETTINGS_D_FILE)
    ctx.invoke(build)
    print("Migration process finished - reached end without external exception.")

@cli.command()
@click.argument('from-version', required=True)
@click.argument('to-version', required=True)
@click.option('--module', help="At debugging: to update only the provided module", default='all')
@click.option("-d", "--debug", help="Interactive mode: stops at breakpoints", default=False)
@click.option("-p", "--pull", help="Pulls odoo repository before to get latest odoo, otherwise SHA from previous runs are used.", default=False)
@click.option('-n', '--no-git-clean', help="If true, then the git repo is not touch and you can set break points.")
@pass_config
@click.pass_context
def migrate(ctx, config, from_version, to_version, no_git_clean, debug, module, pull):
    """
    For debugging migration of certain module provide module parameter.
    """
    assert float(to_version) > float(from_version)
    ctx.invoke(kill, machines=["proxy", "odoo"], brutal=True)
    ctx.invoke(kill, brutal=True)
    git_clean = not no_git_clean
    del no_git_clean
    LOGFILE = os.path.join(odoo_config.customs_dir(), "migration_{}_{}.log".format(E("CUSTOMS"), datetime.now().strftime("%Y-%m-%dT%H%M%S")))
    ctx.invoke(fix_permissions)
    try:
        _migrate(
            ctx,
            config,
            LOGFILE,
            from_version,
            to_version,
            SETTINGS_D_FILE=os.path.join(dirs['settings.d'], 'migration'),
            git_clean=git_clean,
            debug=debug,
            module=module,
            pull_latest=pull,
        )

    except Exception:
        msg = traceback.format_exc()
        with open(LOGFILE, 'a') as f:
            f.write("\n")
            f.write(msg)
        print(msg)
        print("Error occurred during migration, suggestions:")
        print("")
        print("1. Run odoo version and startup frontend, use ./odoo checkout-odoo -f -v xx.xx to set odoo")
    else:
        click.echo("Running migration after processes (basically module update)")
        ctx.invoke(remove_old_modules, ask_confirm=False)
        ctx.invoke(update, module=[], dangling_modules=True, installed_modules=True, no_dangling_check=True, check_install_state=False, no_restart_machines=True)
        ctx.invoke(update, module=['base'], check_install_state=False, no_restart_machines=True, no_dangling_check=True)
        ctx.invoke(update, module=[], no_restart_machines=True, no_dangling_check=True)
        ctx.invoke(show_install_state, suppress_error=True)

    finally:
        print("To debug an intermediate version, run:")
        print("=====================================")
        print("./odoo unlink [to remove links folder of modules]")
        print("./odoo module remove-old")
        print("./odoo update --no-update-module-list -m base")
        print("./odoo checkout-odoo -f -v xx.xx")
        print("./odoo dev")

@ticket.command()
def new_ticket(ticket_name):
    from module_tools import odoo_versioning as versioning
    versioning.actions['new-ticket'](*[ticket_name])

@ticket.command()
def open_tickets(command_options):
    from module_tools import odoo_versioning as versioning
    versioning.actions["open-tickets"]()

def __exists_odoo_commit():
    if not os.path.exists(files['commit']):
        print("Commit file {} not found!".format(files['commit']))
        sys.exit(1)

def __get_odoo_commit():
    with open(files['commit'], 'r') as f:
        content = f.read()
    return content.strip()

@patch.command(name='reset')
@pass_config
def patch_reset(config):
    """
    resets odoo to commit version
    """
    __exists_odoo_commit()
    print("Setting repo to commit {}".format(__get_odoo_commit()))
    __system([
        "git",
        "checkout",
        "-f",
        __get_odoo_commit()
    ], cwd=config.odoo_git)
    print("Cleaning odoo repo...")
    __system([
        "git",
        "clean",
        "-xdff",
    ], cwd=config.odoo_git)
    print("Rsyncing odoo-repo...")
    __system([
        "rsync",
        config.odoo_git + "/",
        config.odoo_local + "/",
        '-ar',
        '--delete-after',
    ], cwd=config.odoo_git, suppress_out=False)
    print("CHOWN odoo-repo...")
    __system([
        'chown',
        '-R',
        os.getenv("OWNER_UID"),
        config.odoo_local,
    ], cwd=config.odoo_git)
    print("Cutting off local git")
    __system([
        'rm',
        '-Rf',
        config.sub_git,
    ], cwd=config.odoo_local)


@module.command()
def progress():
    """
    Displays installation progress
    """
    for row in __execute_sql("select state, count(*) from ir_module_module group by state;", fetchall=True):
        print "{}: {}".format(row[0], row[1])

@control.command()
def proxy_reload():
    if __is_container_running('proxy'):
        __dcexec(['proxy', '/opt/bin/hot_reload.sh'])

def __get_all_subtrees():
    res = __system([
        'git',
        'log',
    ], cwd=dirs['customs'], suppress_out=True)
    for line in res.split("\n"):
        if 'git-subtree-dir' in line:
            path = line.split(":")[-1].strip()
            yield path # e.g. common/module1

@src.command(name='list-subtrees')
def list_subtrees():
    for x in __get_all_subtrees():
        print(x)

def pull_push_all(ctx, mode):
    if mode == 'pull':
        todo = pull
    else:
        todo = push
    for mod in __get_all_subtrees():
        if mod.startswith("common/"):
            path = os.path.join(dirs['customs'], mod)
            if os.path.isdir(path):
                mod = mod[len("common/"):]
                ctx.invoke(todo, submodule=mod)
    extra_installs = os.path.join(dirs['odoo_home'], 'extra_install', 'module')
    if os.path.exists(extra_installs):
        with open(extra_installs, 'r') as f:
            data = eval(f.read())
        for mod in data.keys():
            ctx.invoke(todo, submodule=mod, is_extra_install=True)

def __get_extra_install_modules():
    path = os.path.join(dirs['odoo_home'], 'extra_install/modules')
    if not os.path.exists(path):
        return {}
    with open(path, 'r') as f:
        return eval(f.read())

def __get_subtree_url(type, submodule):
    assert type in ['common', 'extra_install']
    if type == 'common':
        url = 'git.mt-software.de:/git/openerp/modules/{}'.format(submodule)
    elif type == 'extra_install':
        data = __get_extra_install_modules()
        url = data[submodule]['url']
    else:
        raise Exception("impl")
    return url

@src.command()
@click.argument("submodule", required=False)
@click.pass_context
def pull(ctx, submodule, is_extra_install=False):
    if not submodule:
        pull_push_all(ctx, 'pull')
        return

    extra_modules = __get_extra_install_modules()
    if submodule in extra_modules.keys():
        is_extra_install = True

    if not is_extra_install:
        branch = E("ODOO_VERSION")
        path = 'common/{}'.format(submodule)
        url = __get_subtree_url('common', submodule)

        from module_tools import odoo_versioning as versioning
        if not versioning.dirty():
            # Following https://stackoverflow.com/questions/3623351/git-subtree-pull-says-that-the-working-tree-has-modifications-but-git-status-sa
            try:
                __system(['git', 'commit'], cwd=dirs['customs'], suppress_out=True)
            except Exception: pass
    elif is_extra_install:
        branch = 'master'
        path = os.path.join(dirs['odoo_home'], 'extra_install/{}'.format(submodule))
        url = __get_subtree_url('extra_install', submodule)
    else:
        raise Exception('not impl')
    click.echo("Pulling latest version of {} branch {}".format(submodule, branch))
    __assert_file_exists(os.path.join(dirs['customs'], '.git'))
    try:
        __system([
            'git',
            'subtree',
            'pull',
            '--message',
            'SUBTREE-PULL {}'.format(submodule),
            '--prefix',
            '{}'.format(path),
            '--squash',
            url,
            branch,
        ], cwd=dirs['customs'], suppress_out=False)
    except Exception:
        click.echo("""Following https://stackoverflow.com/questions/3623351/git-subtree-pull-says-that-the-working-tree-has-modifications-but-git-status-sa
an error can occur 'working tree has modifications'

                   Just try: git commmit or git checkout <branch> or git reset --hard
    ctx.invoke(module_link)
    """)

@src.command()
@click.argument("submodule", required=False)
@click.pass_context
def push(ctx, submodule, is_extra_install=True):
    if not submodule:
        pull_push_all(ctx, 'push')
        return
    __assert_file_exists(os.path.join(dirs['customs'], '.git'))

    extra_modules = __get_extra_install_modules()
    if submodule in extra_modules.keys():
        is_extra_install = True

    if not is_extra_install:
        branch = E("ODOO_VERSION")
        path = 'common/{}'.format(submodule)
        url = __get_subtree_url('common', submodule)
    elif is_extra_install:
        branch = 'master'
        path = os.path.join(dirs['odoo_home'], 'extra_install/{}'.format(submodule))
        url = __get_subtree_url('extra_install', submodule)
    else:
        raise Exception('not impl')

    __system([
        'git',
        'subtree',
        'push',
        '--prefix={}'.format(path),
        url,
        branch,
    ], cwd=dirs['customs'])

@db.command()
@click.argument('dbname', required=False)
@click.argument('params', nargs=-1)
def psql(dbname, params):
    if not dbname and len(params) == 1:
        if params[0] in ['template1', E("DBNAME")]:
            dbname = params[0]
            params = []
    if not dbname:
        dbname = E("DBNAME")
    params = " ".join(params)
    os.system("psql {} ".format(dbname) + params)

@control.command()
@click.argument('machines', nargs=-1)
@pass_config
@click.pass_context
def rebuild(ctx, config, machines):
    ctx.invoke(compose, customs=config.customs)
    ctx.invoke(build, machines=machines, no_cache=True)

@control.command()
def remove_web_assets():
    """
    if odoo-web interface is broken (css, js) then purging the web-assets helps;
    they are usually recreated when admin login
    """
    _askcontinue()
    from module_tools.module_tools import remove_webassets
    remove_webassets()
    if float(E("ODOO_VERSION")) <= 10.0:
        print("Please login as admin, so that assets are recreated.")

@db.command(name='reset')
@click.argument('dbname', required=True, default=E("DBNAME"))
@pass_config
def reset_db(config, dbname):
    _reset_db(config, dbname)

def _reset_db(config, dbname):
    __start_postgres_and_wait(config)
    _askcontinue("Delete database {}".format(E("DBNAME")))
    print "Stopping all services and creating new database"
    dbname = dbname or E("DBNAME")
    __remove_postgres_connections(dbname, 'drop database {};'.format(dbname))

    print "Database dropped {}".format(dbname)

@control.command()
@click.argument('machines', nargs=-1)
@pass_config
@click.pass_context
def restart(ctx, config, machines):
    machines = list(machines)
    if not machines and 'postgres' not in machines:
        if config.run_postgres_in_ram:
            machines = filter(lambda x: x != 'postgres', _get_machines())

    ctx.invoke(kill, machines=machines)
    ctx.invoke(rm, machines=machines)
    ctx.invoke(recreate, machines=machines)
    ctx.inoke(proxy_reload)

@control.command()
@click.argument('machines', nargs=-1)
@pass_config
@click.pass_context
def rm(ctx, config, machines):
    machines = list(machines)
    if not machines and 'postgres' not in machines:
        if config.run_postgres_in_ram:
            machines = filter(lambda x: x != 'postgres', _get_machines())
    __dc(['rm', '-f'] + machines)

def _get_dump_files():
    _files = os.listdir(BACKUPDIR)

    def _get_ctime(filepath):
        try:
            return os.path.getctime(os.path.join(BACKUPDIR, filepath))
        except Exception:
            return 0
    rows = []
    for i, file in enumerate(sorted(filter(lambda x: _get_ctime(x), _files), reverse=False, key=_get_ctime)):
        filepath = os.path.join(BACKUPDIR, file)
        delta = datetime.now() - datetime.fromtimestamp(os.path.getmtime(filepath))
        rows.append((
            i + 1,
            file,
            humanize.naturaltime(delta),
            humanize.naturalsize(os.stat(filepath).st_size)
        ))

    return rows

@restore.command(name='list')
def list_dumps():
    rows = _get_dump_files()
    print tabulate(rows, ["Nr", 'Filename', 'Age', 'Size'])

@restore.command(name='files')
def restore_files(dumpfile):
    __do_restore_files(dumpfile)


def _inquirer_dump_file(message):
    __files = _get_dump_files()
    filename = inquirer.prompt([inquirer.List('filename', message, choices=__files)])
    if filename:
        filename = filename['filename'][1]
        return filename

@restore.command(name='odoo-db')
@click.argument('filename', required=False, default='')
@click.option('--dev', '--restore-as-dev-db', is_flag=True, help="If true, then sql clean ups are done, before renaming database to destination", default=E("ALLOW_RESTORE_DEV") == "1")
@pass_config
@click.pass_context
def restore_db(ctx, config, filename, restore_as_dev_db=False, dbname=''):
    for x in ['CUSTOMS', "DBNAME", "DB_HOST", "DB_PORT", "RUN_POSTGRES", "RUN_POSTGRES_IN_RAM"]:
        print("{}: {}".format(x, E(x)))

    if restore_as_dev_db and E("ALLOW_RESTORE_DEV") != "1" and not config.force:
        raise Exception("ALLOW_RESTORE_DEV must be explicitly allowed.")
    if restore_as_dev_db:
        click.echo("Option DEV-DB is set, so cleanup-scripts are run afterwards")

    if not filename:
        filename = _inquirer_dump_file("Choose filename to restore")

    filename == os.path.join(BACKUPDIR, filename)
    if filename.startswith("/"):
        raise Exception("No path in dump file allowed")
    if not config.force:
        __restore_check(filename)
    if E("DEVMODE") == "1" and not restore_as_dev_db:
        _askcontinue("DEVMODE ist set - really restore as normal db? Not using restore-dev-db?")

    if not config.force:
        _askcontinue("Deletes database {}!".format(dbname or E("DBNAME")))

    DBNAME_RESTORING = (dbname or E("DBNAME")) + "_restoring"
    os.environ['DBNAME'] = DBNAME_RESTORING

    dbname = dbname or config.dbname
    if not dbname:
        raise Exception("somehow dbname is missing")

    ctx.invoke(wait_for_container_postgres)
    _reset_db(config=config, dbname=DBNAME_RESTORING)
    __do_restore_db_on_postgres(filename, DBNAME_RESTORING, E("DB_HOST"), E("DB_PORT"), E("DB_USER"), E("DB_PWD"))
    if restore_as_dev_db:
        __turn_into_devdb(DBNAME_RESTORING)
    __rename_db_drop_target(DBNAME_RESTORING, dbname)
    __remove_postgres_connections(dbname)
    if dbname == config.dbname:
        __set_db_ownership(config)
    ctx.invoke(telegram_send, "Database Restore $DBNAME done.")

@src.command()
def rmpyc():
    for root, _, _files in os.walk(dirs['customs']):
        for filename in _files:
            if filename.endswith(".pyc"):
                os.unlink(os.path.join(root, filename))

@cli.command()
@click.argument('machine', required=True)
@click.argument('args', nargs=-1)
@pass_config
@click.pass_context
def run(ctx, config, machine, args, **kwparams):
    __set_db_ownership(config)
    args = list(args)
    if args and args[0] == 'bash' and len(args) == 1:
        ctx.invoke(runbash, machine=machine)
        return
    __dcrun([machine] + args, **kwparams)

@cli.command()
@click.argument('machine', required=True)
@click.argument('args', nargs=-1)
@pass_config
@click.pass_context
def runbash(ctx, config, machine, args):
    __set_db_ownership(config)
    _display_machine_tips(machine)
    bash = _get_bash_for_machine(machine)
    cmd = ['run', machine]
    if args:
        cmd += args
    else:
        cmd += [bash]
    __cmd_interactive(*tuple(cmd))

@setup.command()
def sanity_check():
    _sanity_check()

@db.command(name='setname')
@click.argument("DBNAME", required=True)
@click.pass_context
def set_db_name(ctx, DBNAME):
    ctx.invoke(set_setting, key='DBNAME', value=DBNAME)

@admin.command(name='set-setting')
@click.argument('key', required=True)
@click.argument('value', required=True)
def set_setting(key, value):
    config = MyConfigParser(files['settings'])
    config[key.upper()] = value
    config.write()

@db.command(name='set-ownership')
@pass_config
def set_db_ownership(config):
    __set_db_ownership(config)
    _export_settings()

@setup.command(name='startup')
def setup_startup():
    """
    Installs systemd scripts.
    """
    if os.path.exists("/sbin_host/initctl"):
        raise Exception("Not impl")
    else:
        print "Setting up systemd script for startup"
        servicename = os.path.expandvars("${CUSTOMS}_odoo.service")
        file = os.path.join("/tmp_host, servicename")

        # echo "Setting up upstart script in $file"
        shutil.copy(os.path.join(dirs['odoo_home'], 'config', 'systemd'), file)
        __replace_in_file(file, "${CUSTOMS}", E("CUSTOMS"))
        __replace_in_file(file, "${PATH}", E("HOST_ODOO_HOME"))

        print("Please execute on host now (perhaps as sudo):")
        print("""cp /tmp/{servicename} /etc/systemd/system")
        systemctl stop {servicename}
        systemctl disable {servicename}
        systemctl daemon-reload
        systemctl reset-failed
        systemctl enable {servicename}
        systemctl start {servicename}
        """.format(servicename=servicename)
              )

@admin.command()
def shell():
    __cmd_interactive('run', 'odoo', '/bin/bash', '/shell.sh')

@module.command()
def show_install_state(suppress_error=False):
    print("Displaying dangling modules:")
    dangling = __get_dangling_modules()
    for row in dangling:
        print("{}: {}".format(row[0], row[1]))

    if dangling and not suppress_error:
        raise Exception("Dangling modules detected - please fix installation problems and retry!")

@cli.command(name='bash')
def simplebash(*parameters):
    if not parameters:
        os.system("bash --noprofile")
    else:
        os.system("bash --noprofile -c {}".format(" ".join(parameters)))

@admin.command()
def springclean():
    os.system("docker system prune")
    print("removing dead containers")
    os.system('docker ps -a -q | while read -r id; do docker rm "$id"; done')

    print("Remove untagged images")
    os.system('docker images | grep "<none>" | awk \'{ print "docker rmi " $3 }\' | bash')

    print("delete unwanted volumes (can pass -dry-run)")
    os.system('docker images -q -f="dangling=true" | while read -r id; do docker rmi "$id"; done')

@ticket.command()
def stage():
    from module_tools import odoo_versioning as versioning
    versioning.action_stage_ticket()

@admin.command()
def status():
    __print_env(["CUSTOMS", "DBNAME", "DB_HOST", "RUN_POSTGRES", "RUN_POSTGRES_IN_RAM", "ODOO_VERSION"])

@control.command()
@click.argument('machines', nargs=-1)
@pass_config
@click.pass_context
def stop(machines):
    kill(machines)

@src.command()
@click.argument('modules', nargs=-1, required=True)
def submodule(modules):
    if not modules:
        click.echo("Please provide some modules!")
        sys.exit(-1)
    __assert_file_exists(os.path.join(dirs['customs'], '.git'))
    __assert_file_exists(os.path.join(dirs['customs'], 'common'))

    for submodule in modules:
        __system([
            'git',
            'subtree',
            'add',
            '--prefix=common/{}'.format(submodule),
            '--squash',
            'git.mt-software.de:/git/openerp/modules/{}'.format(submodule),
            E("ODOO_VERSION"),
        ], cwd=dirs['customs'])

@src.command(name='odoo')
def checkout_odoo(version='', not_use_local_repo=True, commit_changes=False, force=False):
    """
    Puts odoo from repos into subfolder 'odoo'.

    Can used for migration tests:
     - temporary switch to odoo version

    """
    __assert_file_exists(os.path.join(dirs['customs'], '.version'))

    if os.path.isdir(os.path.join(dirs['customs'], 'odoo')) and not force:
        raise Exception("Odoo already exists")

    if not version:
        version = __read_file(os.path.join(dirs['customs'], '.version')).strip()
    version = float(version)

    __system([
        'git',
        'status',
    ], cwd=dirs['customs'])
    odoo_path = os.path.join(dirs['customs'], 'odoo')
    if os.path.exists(odoo_path):
        shutil.rmtree(odoo_path)
        if commit_changes:
            __system([
                'git',
                'add',
                '.'
            ], cwd=dirs['customs'])
            __system([
                'git',
                'commit',
                '-am "removed current odoo"'
            ], cwd=dirs['customs'])

    if not_use_local_repo:
        url = '/opt/odoo/repos/odoo'
    else:
        url = 'https://github.com/odoo/odoo'
    __system([
        'git',
        'clone',
        url,
        '--branch',
        str(version),
        '--single-branch',
        'odoo',
    ], cwd=dirs['customs'])
    sha = __system([
        'git',
        'rev-parse',
        "HEAD",
    ], cwd=odoo_path).strip()

    shutil.rmtree(os.path.join(dirs['customs'], 'odoo/.git'))
    with open(os.path.join(dirs['customs'], '.version'), 'w') as f:
        f.write(str(version))
    with open(os.path.join(dirs['customs'], 'odoo.commit'), 'w') as f:
        f.write(sha.strip())
    reload() # apply new version
    status()

@ticket.command(name='switch')
def switch_ticket(ticket):
    from module_tools import odoo_versioning as versioning
    versioning.actions["switch-ticket"](*[ticket])

@telegram.command()
def telegram_setup():
    """
    helps creating a permanent chatid
    """
    if E("TELEGRAM_ENABLED") == "1":
        os.system("""
cd "{dir}"
docker-compose run -it telegrambat /setup.sh
""".format(dir=dirs['telegrambot']))

@telegram.command(name='send')
def telegram_send(message):
    if E("TELEGRAM_ENABLED") == "1":
        os.system("""
            cd "{dir}"
            docker-compose run telegrambat /send.py "{message}"
        """.format(
            dir=dirs['telegrambot'],
            message=message,
        ))

@db.command()
def turn_into_dev():
    if E("DEVMODE") != "1":
        raise Exception("""When applying this sql scripts, the database is not usable anymore for production environments.
Please set DEVMODE=1 to allow this""")
    __turn_into_devdb(E("DBNAME"))

@control.command()
@click.argument('machines', nargs=-1)
@click.option('-d', '--daemon', is_flag=True)
@pass_config
@click.pass_context
def up(ctx, config, machines, daemon):
    machines = list(machines)
    if machines and 'postgres' not in machines:
        __set_db_ownership(config)

    if not machines and 'postgres' not in machines:
        if config.run_postgres_in_ram:
            machines = filter(lambda x: x != 'postgres', _get_machines())

    options = [
    ]
    if daemon:
        options += ['-d']
    __dc(['up'] + options + machines)
    ctx.invoke(proxy_reload)

@module.command()
@click.argument('module', nargs=-1, required=False)
@click.option('--keep-containers', '-k', default=False, is_flag=True, help="Does not recreate and restart odoo containers")
@click.option('--installed-modules', '-i', default=False, is_flag=True, help="Updates only installed modules")
@click.option('--dangling-modules', '-d', default=False, is_flag=True, help="Updates only dangling modules")
@click.option('--no-update-module-list', '-n', default=False, is_flag=True, help="Does not install/update module list module")
@click.option('--non-interactive', '-I', default=True, is_flag=True, help="Not interactive")
@click.option('--check-install-state', default=True, is_flag=True, help="Check for dangling modules afterwards")
@click.option('--no-restart-machines', default=False, is_flag=True, help="If set, no machines are restarted afterwards")
@click.option('--no-dangling-check', default=False, is_flag=True, help="Not checking for dangling modules")
@pass_config
@click.pass_context
def update(ctx, config, module, dangling_modules, installed_modules, keep_containers, non_interactive, no_update_module_list, no_dangling_check=False, check_install_state=True, no_restart_machines=True):
    """
    Just custom modules are updated, never the base modules (e.g. prohibits adding old stock-locations)
    Minimal downtime;

    To update all (custom) modules set "all" here
    """
    module = list(module)
    __start_postgres_and_wait(config)
    if any(x[1] == 'uninstallable' for x in __get_dangling_modules()):
        for x in __get_dangling_modules():
            print("{}: {}".format(*x[:2]))
        if raw_input("Uninstallable modules found - shall I set them to 'uninstalled'? [y/N]").lower() == 'y':
            __execute_sql("update ir_module_module set state = 'uninstalled' where state = 'uninstallable';")
    if __get_dangling_modules() and not dangling_modules:
        if not no_dangling_check:
            ctx.invoke(show_install_state, suppress_error=True)
            raw_input("Abort old upgrade and continue? (Ctrl+c to break)")
            ctx.invoke(abort_upgrade)
    if installed_modules:
        module += __get_installed_modules()
    if dangling_modules:
        module += [x[0] for x in __get_dangling_modules()]
    module = filter(lambda x: x, module)

    print("Run module update")
    if E("ODOO_UPDATE_START_NOTIFICATION_TOUCH_FILE_IN_CONTAINER") == "1":
        with open(E("ODOO_UPDATE_START_NOTIFICATION_TOUCH_FILE_IN_CONTAINER"), 'w') as f:
            f.write(datetime.now().strftime("%Y-%m-%d %H:%M:%S"))

    # running duplicate updates is really a problem;
    if not keep_containers:
        ctx.invoke(kill)
        ctx.invoke(rm)
        ctx.invoke(recreate)
        __start_postgres_and_wait(config)
        ctx.invoke(kill, machines=['proxy'])

    try:
        params = ['run', 'odoo_update', '/update_modules.py', ','.join(module)]
        if non_interactive:
            params += ['--non-interactive']
        if not no_update_module_list:
            params += ['--no-update-modulelist']
        if no_dangling_check:
            params += ['no-dangling-check']
        __cmd_interactive(*params)
    except Exception:
        print(traceback.format_exc())
        ctx.invoke(show_install_state, suppress_error=True)
        raise Exception("Error at /update_modules.py - aborting update process.")

    if check_install_state:
        ctx.invoke(show_install_state)

    if not no_restart_machines:
        for i in range(5):
            ctx.invoke(up, daemon=True)
            ctx.invoke(proxy_reload)
            time.sleep(2)

    ctx.invoke(status)
    if E("ODOO_UPDATE_START_NOTIFICATION_TOUCH_FILE_IN_CONTAINER") == "1":
        with open(E("ODOO_UPDATE_START_NOTIFICATION_TOUCH_FILE_IN_CONTAINER"), 'w') as f:
            f.write("0")
    ctx.invoke(telegram_send, "Update done")

@control.command()
@click.argument('machines', nargs=-1)
@pass_config
@click.pass_context
def recreate(ctx, config, machines):
    machines = list(machines)
    if not machines and 'postgres' not in machines:
        if config.run_postgres_in_ram:
            machines = filter(lambda x: x != 'postgres', _get_machines())

    if machines:
        __dc(['up', '--no-start', '--force-recreate'] + machines)
    else:
        __dc(['up', '--no-start', '--force-recreate'])

@src.command(name='update-ast')
def update_ast():
    from module_tools.odoo_parser import update_cache
    if _get_platform() == PLATFORM_OSX:
        print "Update is extreme slow on osx due to share performance. Please use following command natively:"
        print
        print
        print 'time PYTHONPATH=$ODOO_HOME/admin/module_tools python -c "from odoo_parser import update_cache; update_cache()"'
        print
        print
        sys.exit(2)
    started = datetime.now()
    print "Updating ast - can take about one minute; slow on OSX due to share"
    update_cache()
    print "Updated ast - took {} seconds".format((datetime.now() - started).seconds)

@control.command()
@pass_config
def wait_for_container_postgres(config):
    __start_postgres_and_wait(config)

@control.command()
def wait_for_port(host, port):
    port = long(port)
    __wait_for_port(host=host, port=port)

def __set_project_config(content):
    path = os.path.expandvars("/opt/external_home/.odoodev/conf.json")
    with open(path, 'w') as f:
        f.write(json.dumps(content))

def __get_project_config():
    path = os.path.expanduser("/opt/external_home/.odoodev/conf.json")
    if not os.path.isdir(os.path.dirname(path)):
        os.makedirs(os.path.dirname(path))
    if not os.path.isfile(path):
        with open(path, 'w') as f:
            f.write("{}")
    with open(path, 'r') as f:
        res = json.loads(f.read())
        res.setdefault('projects', [])
    return res

@project.command(name='list')
def project_list():
    projects = __get_project_config()['projects']
    for i, project in enumerate(projects):
        print "{}:".format(i + 1), "{}/{}".format(project['customs'], project['db'])

def project_activate(ctx, config, project):
    ctx.invoke(
        compose,
        customs=project['customs'],
        db=project['db'],
        demo=project['demo'],
    )
    if config.run_postgres:
        answer = inquirer.prompt([inquirer.Confirm('in_ram', message="Use In-RAM postgres?", default=config.run_postgres_in_ram)])
        if not answer:
            return
        if answer['in_ram'] != config.run_postgres_in_ram:
            ctx.invoke(set_setting, key="RUN_POSTGRES_IN_RAM", value="1" if answer['in_ram'] else "0")
        if answer['in_ram']:
            ctx.invoke(restore_db)

    ctx.invoke(dev)

@project.command(name='new')
@pass_config
@click.pass_context
def project_new(ctx, config):
    ans = inquirer.prompt([
        inquirer.Text('customs', message="Customs"),
        inquirer.Text('db', message="DB (if empty same as customs then)", ),
        inquirer.Confirm('demo', message="Activate demo data?"),
    ])
    if not ans:
        return
    pconfig = __get_project_config()
    project = {
        'customs': ans['customs'],
        'db': ans['db'],
        'demo': ans['demo'],
    }
    pconfig['projects'].append(project)
    __set_project_config(pconfig)
    project_activate(ctx, config, project=project)

@project.command(name='delete')
def project_delete():
    choices = map(lambda p: "/".join([p['customs'], p['db']]))
    answer = inquirer.prompt([inquirer.List("project", "Choose a project", choices=choices)])
    if not answer:
        return
    customs, db = answer['project'].split("/")
    config = __get_project_config()
    project = filter(lambda x: x['customs'] == customs and x['db'] == db, config['projects'])[0]
    config['projects'].remove(project)
    __set_project_config(config)

@project.command(name='switch')
@pass_config
@click.pass_context
def project(ctx, config):
    projects = __get_project_config()['projects']
    choices = map(lambda p: "/".join([p['customs'], p['db']]), projects)
    answer = inquirer.prompt([inquirer.List("project", "Choose a project", choices=choices)])
    if not answer:
        return

    customs, db = answer['project'].split("/")
    project = filter(lambda x: x['customs'] == customs and x['db'] == db, projects)[0]
    project_activate(ctx, config, project)

@src.command()
def make_module(name):
    cwd = E("WORKING_DIR")
    from module_tools.module_tools import make_module as _tools_make_module
    _tools_make_module(
        cwd,
        name,
    )

@db.command()
def pgactivity():
    if E("RUN_POSTGRES") == "1":
        __dcexec(["postgres", 'pg_activity'])

@admin.command(name='toggle-settings')
@click.pass_context
def toggle_settings(ctx):
    config = MyConfigParser(files['settings'])
    config_local = MyConfigParser(files['settings_local'])

    choices = [
        "DEVMODE",
    ]
    default = []

    for key in sorted(config.keys()):
        if key.startswith("RUN_"):
            choices.append(key)

    for choice in choices:
        if config[choice] == '1':
            default.append(choice)

    questions = [
        inquirer.Checkbox(
            'run',
            message="What services to run? {}/{}".format(E("CUSTOMS"), E("DBNAME")),
            choices=choices,
            default=default,
        )
    ]
    answers = inquirer.prompt(questions)

    if not answers:
        return
    for option in choices:
        config_local[option] = '1' if option in answers['run'] else '0'
    __postprocess_config(config_local)
    config_local.write()
    ctx.invoke(reload)


if __name__ == '__main__':
    _startup()
    _check_working_dir_customs_mismatch()
    if args:
        if args[0] == 'tool':
            sys.exit(0)

    _remember_customs_and_cry_if_changed()

    try:
        cli()
    finally:
        _cleanup()
